{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Pre-processing and Modeling</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic modeling is an unsupervised machine learning technique used to detect words and phrases within documents                                                                                                                                                    and automatically cluster groups of words and similar expressions that best characterize a set of documents.\n",
    "\n",
    "This NLP technique is useful for tasks including text classification, extracting themes from documents, and building a recommender systems to recommend other text such as an article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topic modeling technique that will be used is LDA, Latent Dirichlet Analysis. This model assigns each word to a random topic. Then iteratively, the algorithm then reassigns the word to a new topic and considers a few things. First, what is the probability of the word belonging to a topic and the probability of the document to be generated by a topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import Packages</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table, select\n",
    "\n",
    "engine = create_engine(\"sqlite:///joblist.sqlite\")\n",
    "metadata = MetaData()\n",
    "data = Table('data', metadata, autoload=True, autoload_with=engine)\n",
    "stmt = select([data.columns.jobdescription, data.columns.label])\n",
    "connection = engine.connect()\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "df_data = pd.DataFrame(results)\n",
    "df_data.columns = results[0].keys()\n",
    "df_data['jobdescription'] = df_data['jobdescription'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobdescription</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Position Title:Pricing Analyst Position Type: ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Title: Senior Data Analyst - Telephony Manager...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We are looking for a talented Fuel Cell Data E...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAREER OPPORTUNITY SENIOR METER DATA ANALYST L...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Data Engineer reports directly to the Dire...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      jobdescription  label\n",
       "0  Position Title:Pricing Analyst Position Type: ...      0\n",
       "1  Title: Senior Data Analyst - Telephony Manager...      0\n",
       "2  We are looking for a talented Fuel Cell Data E...      0\n",
       "3  CAREER OPPORTUNITY SENIOR METER DATA ANALYST L...      0\n",
       "4  The Data Engineer reports directly to the Dire...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobdescription</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>625</td>\n",
       "      <td>625.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>553</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Our student and new graduate programs offer a ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.449359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           jobdescription       label\n",
       "count                                                 625  625.000000\n",
       "unique                                                553         NaN\n",
       "top     Our student and new graduate programs offer a ...         NaN\n",
       "freq                                                    5         NaN\n",
       "mean                                                  NaN    0.280000\n",
       "std                                                   NaN    0.449359\n",
       "min                                                   NaN    0.000000\n",
       "25%                                                   NaN    0.000000\n",
       "50%                                                   NaN    0.000000\n",
       "75%                                                   NaN    1.000000\n",
       "max                                                   NaN    1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Count Vectorizer + Topic Modeling</h2>\n",
    "\n",
    "The topic modeling technique LDA uses the text pre-processed via CountVectorizer function as an input. CountVectorizer returns an encoded vector with an integer count for each word.\n",
    "\n",
    "Here, we will tokenize, use the built-in stop words list, and keep only tokens that appear in at least 4 dfs (document frequencies)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Remove english and french stopwords\n",
    "\n",
    "#import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "combined_stopwords = ENGLISH_STOP_WORDS.union(stopwords.words('french'))\n",
    "\n",
    "cv = CountVectorizer(analyzer='word',  \n",
    "                     stop_words = combined_stopwords,\n",
    "                     lowercase = True, \n",
    "                     min_df=4,\n",
    "                     max_df = 0.99,\n",
    "                     ngram_range=(1,2))\n",
    "count_vector = cv.fit_transform(df_data['jobdescription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: data | analytics | work | td | business | wattpad | experience | insights | team | marketing\n",
      "Topic 1: data | business | experience | work | skills | reporting | analysis | business intelligence | intelligence | bi\n",
      "Topic 2: data | business | experience | analytics | analysis | work | management | clients | solutions | skills\n",
      "Topic 3: data | experience | business | requirements | quality | skills | project | work | years | knowledge\n",
      "Topic 4: data | learning | experience | machine | machine learning | work | science | team | business | data science\n",
      "Topic 5: data | business | team | work | experience | skills | sales | analysis | ability | strong\n",
      "Topic 6: data | business | experience | work | management | team | skills | support | ability | knowledge\n",
      "Topic 7: data | business | bmo | support | depth | management | experience | stakeholders | skills | group\n",
      "Topic 8: experience | business | team | data | project | development | support | ability | solutions | customer\n",
      "Topic 9: data | business | experience | management | team | operations | skills | environment | global | solutions\n",
      "CPU times: user 40.4 s, sys: 5.74 s, total: 46.1 s\n",
      "Wall time: 6.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initialize LDA model with 10 topics\n",
    "lda_model = LatentDirichletAllocation(n_components=10,\n",
    "                                      random_state=42)\n",
    "\n",
    "# Fit it to our CountVectorizer Transformation\n",
    "X_topics = lda_model.fit_transform(count_vector)\n",
    "\n",
    "# Define variables\n",
    "n_top_words = 10\n",
    "topic_summaries = []\n",
    "\n",
    "# Get the topic words\n",
    "topic_word = lda_model.components_\n",
    "\n",
    "# Get the vocabulary from the text features\n",
    "vocab = cv.get_feature_names()\n",
    "\n",
    "# Display the Topic Models\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    topic_summaries.append(' '.join(topic_words))\n",
    "    print('Topic {}: {}'.format(i, ' | '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To better understand the LDA model, the ELI5 package can be used.\n",
    "\n",
    "ELI5 helps to debug machine learning classifiers and to explain their predictions. It can also understand text and can highlight data appropriately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import eli5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create Train-Test Sets</h3>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create a training and testing data sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_data['jobdescription'],\n",
    "                                                    df_data['label'],\n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=123, \n",
    "                                                    stratify=df_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df_data,\n",
    "                               test_size=0.20, \n",
    "                               random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['label'].values\n",
    "y_test = test_data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Analyzing Job Descriptions: Baseline Model with Log Reg</h2>\n",
    "\n",
    "With machine learning, use TF-IDF to extract features before fitting the classifer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Initialize TFIDF Vectorizer\n",
    "tvec = TfidfVectorizer(analyzer = 'word',  \n",
    "                       stop_words = ENGLISH_STOP_WORDS.union(stopwords.words('french')), \n",
    "                       lowercase= True, \n",
    "                       min_df=4, \n",
    "                       #max_df = 0.95,\n",
    "                       ngram_range = (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<500x12920 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 191658 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit text data\n",
    "tvec.fit_transform(train_data['jobdescription'].values) #add .values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from x_train and x_test using TF-IDF\n",
    "x_train_tfidf = tvec.transform(train_data['jobdescription'].values)\n",
    "x_test_tfidf = tvec.transform(test_data['jobdescription'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<125x12920 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 45824 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<500x12920 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 191658 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init log reg model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = logreg.fit(x_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cross-Validation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "The mean of cross validation is:  0.8300000000000001\n",
      "74.6 ms ± 1.42 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Apply 10-fold cross-validation\n",
    "clf_result = cross_val_score(model, x_train_tfidf, y_train, cv=10, scoring='accuracy')\n",
    "print(\"The mean of cross validation is: \", clf_result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluation Metrics of Test data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "Precision: 0.895, \n",
      "Recall: 0.5, \n",
      "F-score: 0.642, \n",
      "Accuracy: 0.848\n"
     ]
    }
   ],
   "source": [
    "# Predict y values using x test values\n",
    "y_pred = model.predict(x_test_tfidf)\n",
    "precision, recall, fscore, support = score(y_test, \n",
    "                                            y_pred, \n",
    "                                            pos_label=1, \n",
    "                                            average ='binary')\n",
    "\n",
    "print(\"Classification Report: \\nPrecision: {}, \\nRecall: {}, \\nF-score: {}, \\nAccuracy: {}\".format(round(precision,3),round(recall,3),round(fscore,3),round((y_pred==y_test).sum()/len(y_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[89,  2],\n",
       "       [17, 17]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict_proba(x_test_tfidf)\n",
    "# Returns the probability of the sample for each class in the model, where classes are ordered as they are in self.classes_.\n",
    "\n",
    "# Sort for top 5 predictions\n",
    "top5 = np.argsort(y_pred_proba, axis=1)[:,-5:]\n",
    "\n",
    "# Retrieve category of predictions\n",
    "top5_cat = [[model.classes_[predicted_cat] for predicted_cat in prediction] for prediction in top5]\n",
    "top5_cat = [item[::-1] for item in top5_cat]\n",
    "print(top5[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('dataenv': conda)",
   "language": "python",
   "name": "python385jvsc74a57bd013f2b1e521b8f6e58ac5f308ce6e9ec48daaa5d3d12011623b022ddafac4d33a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
