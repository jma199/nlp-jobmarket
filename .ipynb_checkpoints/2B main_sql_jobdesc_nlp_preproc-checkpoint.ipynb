{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Part 2 : Pre-Processing of Job Description Text</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Import Packages</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# If you haven't already done so, execute:\n",
    "#import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Load data from sqlite database</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data']\n",
      "['jobtitle', 'company', 'location', 'salary', 'jobdescription', 'label']\n",
      "Table('data', MetaData(bind=None), Column('jobtitle', VARCHAR(length=100), table=<data>), Column('company', VARCHAR(length=100), table=<data>), Column('location', VARCHAR(length=25), table=<data>), Column('salary', INTEGER(), table=<data>), Column('jobdescription', TEXT(), table=<data>), Column('label', INTEGER(), table=<data>), schema=None)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table\n",
    "\n",
    "# Query SQL db to get analyst job descriptions first\n",
    "\n",
    "# Create connection to db\n",
    "engine = create_engine(\"sqlite:///joblist.sqlite\")\n",
    "print(engine.table_names())\n",
    "\n",
    "# Load in data table\n",
    "metadata = MetaData()\n",
    "\n",
    "data = Table('data', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "print(data.columns.keys())\n",
    "print(repr(metadata.tables['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jobdescription', 'label']\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import select\n",
    "\n",
    "# Build query\n",
    "stmt = select([data.columns.jobdescription, data.columns.label])\n",
    "stmt = stmt.where(data.columns.label == '0') # 0 = analysts\n",
    "\n",
    "# Create connection to engine\n",
    "connection = engine.connect()\n",
    "\n",
    "# Execute query\n",
    "results = connection.execute(stmt).fetchall()\n",
    "print(results[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import func\n",
    "\n",
    "stmt_count = select([func.count(data.columns.jobdescription)])\n",
    "results_count = connection.execute(stmt_count).scalar()\n",
    "print(results_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      jobdescription  label\n",
      "0  Position Title:Pricing Analyst Position Type: ...      0\n",
      "1  Title: Senior Data Analyst - Telephony Manager...      0\n",
      "2  We are looking for a talented Fuel Cell Data E...      0\n",
      "3  CAREER OPPORTUNITY SENIOR METER DATA ANALYST L...      0\n",
      "4  The Data Engineer reports directly to the Dire...      0\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe from SQLAlchemy ResultSet\n",
    "df_data = pd.DataFrame(results)\n",
    "\n",
    "# Give columns proper heading\n",
    "df_data.columns = results[0].keys()\n",
    "print(df_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 450 entries, 0 to 449\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   jobdescription  450 non-null    object\n",
      " 1   label           450 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 450 entries, 0 to 449\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   jobdescription  450 non-null    string\n",
      " 1   label           450 non-null    int64 \n",
      "dtypes: int64(1), string(1)\n",
      "memory usage: 7.2 KB\n"
     ]
    }
   ],
   "source": [
    "df_data['jobdescription'] = df_data['jobdescription'].astype('string')\n",
    "df_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Text Analysis of Job Description</h2>\n",
    "\n",
    "<h3>Pre-processing Pipeline</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Canadian Orthodontic Partners has an exciting new opportunity, looking for a talented new Analyst to join our Standards team! Reporting to the National Manager of COP Standards, the Business Analyst will gather and interpret data to develop actionable steps to improve processes, optimizing operational performance and acquisition due diligence and transitions.What We Offer: Competitive Annual Salary + Quarterly BonusComprehensive Benefits Package including : Medical, Dental, Vision, and Orthodontic Coverage for employees and their families.Paid Vacation Time.Educational Reimbursement Program.Real Career Growth Opportunities.Key Responsibilities: Lead the collection of acquisition due diligence data.Collect all required initial DD information from selling doctor based on standard question listEnsure information is complete and prepared for decisions making by the team, highlighting risks or issues to expedite the decision making.Complete a first pass of the DD analysis.As the project coordinator, coordinate all DD tasks to make sure they are completed on timeFollow up with responsible parties in a timely mannerEnsure standard process is followedProject Coordinator for DD and Transition. Coordinate all DD tasks to ensure appropriate planning delivers DD and Transition outcomes on time and with visibility to risks.Follow up with all responsible parties in a timey manner to ensure tasks are completed or visibility to missing the deliverables is achieved.Produce consistent, regular performance reports for DD and Transition Performance.Lead a consistent approach that allows others to know what to expect.Maintain and manage scorecards and decision support tools for clinic network operations.Regularly (monthly or quarterly) pull data from our practice management systems to produce performance scorecards, planning workbooks and decision tools.Analyze the data to support efficient decision making and action planning.Present completed tools and findings and recommended steps take to the operational leadership or executive team.Maintain tracking sheets, workbooks and tools (google sheet/ excel) that leaders use daily for data analysis, project performance, audit results etc.Requirements: Minimum 2 years working as a Standards Analyst or in a similar field/capacity.Excellent communication skills both verbal and written.Ability to build and maintain strong working relationships with internal and external teams.Strong organizational skills, with the ability to manage multiple projects at once .Proficient in MS Excel or Google Sheets, Word, Visio, Power Point, and able to learn new technologies quickly.Very detail oriented.Ability to manipulate and analyze dataFamiliarity with project management methodology or project coordination work.Job Types: Full-time, PermanentBenefits:Dental careDisability insuranceEmployee assistance programExtended health careLife insurancePaid time offTuition reimbursementVision careWork from homeSchedule:8 hour shiftMonday to FridayExperience:Business Analyst: 2 years (Preferred)Work remotely:Temporarily due to COVID-19COVID-19 precaution(s):Remote interview processPersonal protective equipment provided or requiredPlastic shield at work stationsSocial distancing guidelines in placeVirtual meetingsSanitizing, disinfecting, or cleaning procedures in place'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select an example job description from df_data\n",
    "\n",
    "text = df_data['jobdescription'][7]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471\n"
     ]
    }
   ],
   "source": [
    "# Tokenize example text\n",
    "# Maybe add len(token) to dataframe and plot\n",
    "\n",
    "text_token = word_tokenize(str(text))\n",
    "print(len(text_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['provided', 'or', 'requiredPlastic', 'shield', 'at', 'work', 'stationsSocial', 'distancing', 'guidelines', 'in', 'placeVirtual', 'meetingsSanitizing', ',', 'disinfecting', ',', 'or', 'cleaning', 'procedures', 'in', 'place']\n"
     ]
    }
   ],
   "source": [
    "print(text_token[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Text Pre-processing Pipeline</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the job postings currently available will be considered the \"test\" set and will not be split. Any predictions will be made on new postings scraped at a later date.\n",
    "\n",
    "Here, we will try 2 different vectorizers: CountVectorizer and TF-IDF.\n",
    "\n",
    "The pre-processing pipeline will include the following steps:\n",
    "\n",
    "- Tokenization\n",
    "- Stopword removal\n",
    "- Lower casing\n",
    "- Stemming\n",
    "- Apply transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Count Vectorizer</h2>\n",
    "\n",
    "CountVectorizer returns an encoded vector with integer count for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '000026rp', '000ft', '000m3', '0090', '00am', '00pm', '01', '012', '013job', '0159', '01expected', '01job', '02', '0272', '02job', '03', '03job', '04']\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(analyzer='word', stop_words = 'english', lowercase = True)\n",
    "cv_token = cv.fit_transform(df_data['jobdescription'])\n",
    "\n",
    "print(cv.get_feature_names()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [2 2 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(cv_token.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 10256)\n"
     ]
    }
   ],
   "source": [
    "print(cv_token.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2 = CountVectorizer(analyzer='word', n_gram=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>TFIDF Vectorizer</h2>\n",
    "\n",
    "TFIDF converts the job description text into a matrix of TF-IDF features. The TF-IDF Vectorizer function from the sklearn.feature_extraction module performs multiple steps including tokenization, stopword removal, and lower casing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>1. Text Normalization: Stemming Words</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1f8f9c86c8a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mporter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jobdescription'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jobdescription'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "porter = PorterStemmer()\n",
    "df_data['jobdescription'][7] = df_data['jobdescription'][7].apply(porter.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'canadian orthodontic partners has an exciting new opportunity, looking for a talented new analyst to join our standards team! reporting to the national manager of cop standards, the business analyst will gather and interpret data to develop actionable steps to improve processes, optimizing operational performance and acquisition due diligence and transitions.what we offer: competitive annual salary + quarterly bonuscomprehensive benefits package including : medical, dental, vision, and orthodontic coverage for employees and their families.paid vacation time.educational reimbursement program.real career growth opportunities.key responsibilities: lead the collection of acquisition due diligence data.collect all required initial dd information from selling doctor based on standard question listensure information is complete and prepared for decisions making by the team, highlighting risks or issues to expedite the decision making.complete a first pass of the dd analysis.as the project coordinator, coordinate all dd tasks to make sure they are completed on timefollow up with responsible parties in a timely mannerensure standard process is followedproject coordinator for dd and transition. coordinate all dd tasks to ensure appropriate planning delivers dd and transition outcomes on time and with visibility to risks.follow up with all responsible parties in a timey manner to ensure tasks are completed or visibility to missing the deliverables is achieved.produce consistent, regular performance reports for dd and transition performance.lead a consistent approach that allows others to know what to expect.maintain and manage scorecards and decision support tools for clinic network operations.regularly (monthly or quarterly) pull data from our practice management systems to produce performance scorecards, planning workbooks and decision tools.analyze the data to support efficient decision making and action planning.present completed tools and findings and recommended steps take to the operational leadership or executive team.maintain tracking sheets, workbooks and tools (google sheet/ excel) that leaders use daily for data analysis, project performance, audit results etc.requirements: minimum 2 years working as a standards analyst or in a similar field/capacity.excellent communication skills both verbal and written.ability to build and maintain strong working relationships with internal and external teams.strong organizational skills, with the ability to manage multiple projects at once .proficient in ms excel or google sheets, word, visio, power point, and able to learn new technologies quickly.very detail oriented.ability to manipulate and analyze datafamiliarity with project management methodology or project coordination work.job types: full-time, permanentbenefits:dental caredisability insuranceemployee assistance programextended health carelife insurancepaid time offtuition reimbursementvision carework from homeschedule:8 hour shiftmonday to fridayexperience:business analyst: 2 years (preferred)work remotely:temporarily due to covid-19covid-19 precaution(s):remote interview processpersonal protective equipment provided or requiredplastic shield at work stationssocial distancing guidelines in placevirtual meetingssanitizing, disinfecting, or cleaning procedures in plac'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['jobdescription'][7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2. Initialize Stopword Removal & Lowercasing</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TFIDF Vectorizer\n",
    "tvec = TfidfVectorizer(analyzer = 'word', stop_words = 'english', lowercase= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3. Apply TF-IDF</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns matrix of tf-idf features\n",
    "tvec_token = tvec.fit_transform(df_data['jobdescription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '000026rp',\n",
       " '000ft',\n",
       " '000m3',\n",
       " '0090',\n",
       " '00am',\n",
       " '00pm',\n",
       " '01',\n",
       " '012',\n",
       " '013job',\n",
       " '0159',\n",
       " '01expected',\n",
       " '01job',\n",
       " '02',\n",
       " '0272',\n",
       " '02job',\n",
       " '03',\n",
       " '03job',\n",
       " '04',\n",
       " '04job',\n",
       " '05',\n",
       " '055',\n",
       " '0553',\n",
       " '05job',\n",
       " '06',\n",
       " '0661',\n",
       " '078',\n",
       " '08',\n",
       " '0815',\n",
       " '082',\n",
       " '083',\n",
       " '08expected',\n",
       " '09',\n",
       " '0g7',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '100ft',\n",
       " '100mm',\n",
       " '100s',\n",
       " '10112323contract',\n",
       " '104',\n",
       " '1045',\n",
       " '1075',\n",
       " '1090',\n",
       " '10b',\n",
       " '10mb',\n",
       " '11',\n",
       " '110',\n",
       " '112',\n",
       " '113886',\n",
       " '114',\n",
       " '1145',\n",
       " '115',\n",
       " '116',\n",
       " '11685job',\n",
       " '119',\n",
       " '12',\n",
       " '120',\n",
       " '1200',\n",
       " '1236',\n",
       " '126',\n",
       " '128',\n",
       " '12th',\n",
       " '13',\n",
       " '130',\n",
       " '1300',\n",
       " '13021',\n",
       " '137',\n",
       " '13th',\n",
       " '14',\n",
       " '14001',\n",
       " '144',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '153',\n",
       " '154',\n",
       " '155',\n",
       " '15611job',\n",
       " '1563',\n",
       " '15724',\n",
       " '15725contract',\n",
       " '15775contract',\n",
       " '15job',\n",
       " '16',\n",
       " '160367',\n",
       " '161182',\n",
       " '161615',\n",
       " '1654',\n",
       " '16607',\n",
       " '16764',\n",
       " '16job',\n",
       " '17',\n",
       " '170',\n",
       " '172',\n",
       " '173',\n",
       " '176',\n",
       " '178',\n",
       " '18',\n",
       " '180',\n",
       " '1830s',\n",
       " '1846',\n",
       " '1871',\n",
       " '1881',\n",
       " '189',\n",
       " '19',\n",
       " '1914',\n",
       " '1918',\n",
       " '194',\n",
       " '1950',\n",
       " '1953',\n",
       " '1954',\n",
       " '1960',\n",
       " '1970',\n",
       " '1974',\n",
       " '1978',\n",
       " '1985',\n",
       " '1986',\n",
       " '1994',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '19covid',\n",
       " '19education',\n",
       " '19expected',\n",
       " '1a',\n",
       " '1publish',\n",
       " '1st',\n",
       " '1w5',\n",
       " '1x',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2001',\n",
       " '20022',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2008',\n",
       " '2011',\n",
       " '2012',\n",
       " '2014',\n",
       " '2015',\n",
       " '2016',\n",
       " '2017',\n",
       " '2018',\n",
       " '2019',\n",
       " '2020',\n",
       " '2021',\n",
       " '2021we',\n",
       " '2022',\n",
       " '2035',\n",
       " '205',\n",
       " '207',\n",
       " '20th',\n",
       " '21',\n",
       " '210068',\n",
       " '210085',\n",
       " '2105902884w',\n",
       " '2105903113w',\n",
       " '2105904277w',\n",
       " '210781',\n",
       " '213043',\n",
       " '213703',\n",
       " '213872',\n",
       " '214444',\n",
       " '214708',\n",
       " '217514',\n",
       " '21st',\n",
       " '22',\n",
       " '23',\n",
       " '231',\n",
       " '234',\n",
       " '238',\n",
       " '239',\n",
       " '23job',\n",
       " '24',\n",
       " '243',\n",
       " '24job',\n",
       " '25',\n",
       " '250',\n",
       " '26',\n",
       " '268',\n",
       " '270',\n",
       " '2700',\n",
       " '275',\n",
       " '276151',\n",
       " '277191',\n",
       " '277656',\n",
       " '277772',\n",
       " '28',\n",
       " '28941',\n",
       " '28b',\n",
       " '2h7job',\n",
       " '2m',\n",
       " '2v9',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '303',\n",
       " '308',\n",
       " '30am',\n",
       " '30pm',\n",
       " '31',\n",
       " '31st',\n",
       " '32',\n",
       " '320',\n",
       " '326556',\n",
       " '33',\n",
       " '330056',\n",
       " '332217',\n",
       " '333',\n",
       " '34401',\n",
       " '35',\n",
       " '350',\n",
       " '36',\n",
       " '364',\n",
       " '365',\n",
       " '37',\n",
       " '38',\n",
       " '381',\n",
       " '3c4',\n",
       " '3e',\n",
       " '3mf',\n",
       " '3pl',\n",
       " '3rd',\n",
       " '40',\n",
       " '400',\n",
       " '4000',\n",
       " '401',\n",
       " '401k',\n",
       " '409',\n",
       " '41',\n",
       " '41442',\n",
       " '416',\n",
       " '42',\n",
       " '4331',\n",
       " '438',\n",
       " '44',\n",
       " '4429',\n",
       " '45',\n",
       " '450',\n",
       " '450h',\n",
       " '466',\n",
       " '467',\n",
       " '47',\n",
       " '4747',\n",
       " '476',\n",
       " '4778',\n",
       " '49',\n",
       " '490',\n",
       " '4hana',\n",
       " '4p8',\n",
       " '4th',\n",
       " '4w8',\n",
       " '50',\n",
       " '500',\n",
       " '50mm',\n",
       " '52',\n",
       " '520',\n",
       " '5255',\n",
       " '5300',\n",
       " '5330',\n",
       " '55',\n",
       " '550',\n",
       " '55000',\n",
       " '554',\n",
       " '5559',\n",
       " '56',\n",
       " '5700',\n",
       " '58',\n",
       " '5837',\n",
       " '59',\n",
       " '590',\n",
       " '59pm',\n",
       " '5b',\n",
       " '5l7',\n",
       " '5reimbursement',\n",
       " '60',\n",
       " '600',\n",
       " '61',\n",
       " '62',\n",
       " '622',\n",
       " '63',\n",
       " '634',\n",
       " '65',\n",
       " '650',\n",
       " '66',\n",
       " '661',\n",
       " '67',\n",
       " '68',\n",
       " '69',\n",
       " '6ft',\n",
       " '6th',\n",
       " '70',\n",
       " '700',\n",
       " '7120',\n",
       " '730',\n",
       " '7304',\n",
       " '75',\n",
       " '750',\n",
       " '76',\n",
       " '7695',\n",
       " '77',\n",
       " '7710',\n",
       " '777',\n",
       " '78',\n",
       " '79',\n",
       " '7th',\n",
       " '80',\n",
       " '800',\n",
       " '8002',\n",
       " '80190525',\n",
       " '805',\n",
       " '81',\n",
       " '82',\n",
       " '85',\n",
       " '86',\n",
       " '866',\n",
       " '867',\n",
       " '87',\n",
       " '871966',\n",
       " '872',\n",
       " '872687',\n",
       " '888',\n",
       " '89',\n",
       " '8th',\n",
       " '90',\n",
       " '900',\n",
       " '905',\n",
       " '92145',\n",
       " '94',\n",
       " '943',\n",
       " '945',\n",
       " '9501',\n",
       " '952',\n",
       " '958',\n",
       " '96',\n",
       " '96272',\n",
       " '96898',\n",
       " '96905',\n",
       " '97',\n",
       " '97205',\n",
       " '97584',\n",
       " '97603',\n",
       " '97604',\n",
       " '97894',\n",
       " '979',\n",
       " '98',\n",
       " '99',\n",
       " '9bn',\n",
       " '________________________________________________________________________postmedia',\n",
       " '_requisition',\n",
       " 'aa',\n",
       " 'ab',\n",
       " 'abide',\n",
       " 'abilene',\n",
       " 'abilities',\n",
       " 'abilitiesexcellent',\n",
       " 'ability',\n",
       " 'abilityexperience',\n",
       " 'abinbev',\n",
       " 'able',\n",
       " 'abnormal',\n",
       " 'aboriginal',\n",
       " 'aboriginals',\n",
       " 'abreast',\n",
       " 'abroad',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'abstract',\n",
       " 'abundance',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'academic',\n",
       " 'accelerant',\n",
       " 'accelerate',\n",
       " 'accelerated',\n",
       " 'accelerating',\n",
       " 'acceleration',\n",
       " 'accelerator',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accesses',\n",
       " 'accessexceptional',\n",
       " 'accessexperience',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accessiblecareers',\n",
       " 'accessing',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accolades',\n",
       " 'accommodate',\n",
       " 'accommodating',\n",
       " 'accommodation',\n",
       " 'accommodations',\n",
       " 'accommodement',\n",
       " 'accommodements',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'accomplishing',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accordance',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accords',\n",
       " 'account',\n",
       " 'accountabilities',\n",
       " 'accountabilitieswork',\n",
       " 'accountability',\n",
       " 'accountable',\n",
       " 'accountant',\n",
       " 'accounting',\n",
       " 'accounts',\n",
       " 'accreditations',\n",
       " 'accredited',\n",
       " 'accruals',\n",
       " 'accruent',\n",
       " 'accumulation',\n",
       " 'accuracy',\n",
       " 'accuracya',\n",
       " 'accuracyanalyze',\n",
       " 'accuracydevelop',\n",
       " 'accuracydrive',\n",
       " 'accuracygenerates',\n",
       " 'accuracystrong',\n",
       " 'accuracywe',\n",
       " 'accurate',\n",
       " 'accurateaudit',\n",
       " 'accurately',\n",
       " 'accès',\n",
       " 'ach',\n",
       " 'achat',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achievers',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'acii',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledgement',\n",
       " 'acknowledges',\n",
       " 'acl',\n",
       " 'acl123',\n",
       " 'acne',\n",
       " 'acquerrez',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquiring',\n",
       " 'acquisition',\n",
       " 'acquisitions',\n",
       " 'acquérir',\n",
       " 'acritas',\n",
       " 'acss',\n",
       " 'act',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actionable',\n",
       " 'actioned',\n",
       " 'actionedi',\n",
       " 'actionprovides',\n",
       " 'actions',\n",
       " 'activate',\n",
       " 'activation',\n",
       " 'activations',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activities',\n",
       " 'activitiesportfolio',\n",
       " 'activity',\n",
       " 'activityupdate',\n",
       " 'activités',\n",
       " 'activitésparticiper',\n",
       " 'actors',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actualizing',\n",
       " 'actuals',\n",
       " 'actuarial',\n",
       " 'actuelle',\n",
       " 'acumen',\n",
       " 'acumenapplication',\n",
       " 'acute',\n",
       " 'ad',\n",
       " 'ad1',\n",
       " 'adam',\n",
       " 'adapt',\n",
       " 'adaptability',\n",
       " 'adaptable',\n",
       " 'adaptation',\n",
       " 'adapting',\n",
       " 'adapts',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addendum',\n",
       " 'addiction',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additions',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'adept',\n",
       " 'adequacy',\n",
       " 'adequate',\n",
       " 'adesa',\n",
       " 'adf',\n",
       " 'adhere',\n",
       " 'adhered',\n",
       " 'adherence',\n",
       " 'adheres',\n",
       " 'adhering',\n",
       " 'adhesives',\n",
       " 'adhoc',\n",
       " 'adhésifs',\n",
       " 'adjacent',\n",
       " 'adjust',\n",
       " 'adjusted',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'admin',\n",
       " 'administer',\n",
       " 'administered',\n",
       " 'administering',\n",
       " 'administers',\n",
       " 'administration',\n",
       " 'administrative',\n",
       " 'administrator',\n",
       " 'administrators',\n",
       " 'admiral',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admission',\n",
       " 'adobe',\n",
       " 'adopt',\n",
       " 'adopter',\n",
       " 'adopting',\n",
       " 'adoption',\n",
       " 'adp',\n",
       " 'adresse',\n",
       " 'ads',\n",
       " 'adsp',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancement',\n",
       " 'advances',\n",
       " 'advancing',\n",
       " 'advantag',\n",
       " 'advantage',\n",
       " 'advantaged',\n",
       " 'advantagedatabase',\n",
       " 'advantageous',\n",
       " 'advantages',\n",
       " 'advent',\n",
       " 'adverse',\n",
       " 'advert',\n",
       " 'advertiser',\n",
       " 'advertisers',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'advising',\n",
       " 'advisor',\n",
       " 'advisors',\n",
       " 'advisory',\n",
       " 'advocate',\n",
       " 'advocates',\n",
       " 'advocating',\n",
       " 'adwords',\n",
       " 'ae',\n",
       " 'aecon',\n",
       " 'aeconone',\n",
       " 'aerospace',\n",
       " 'aerotek',\n",
       " 'af1',\n",
       " 'affaire',\n",
       " 'affaires',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affects',\n",
       " 'affiliate',\n",
       " 'affiliated',\n",
       " 'affiliates',\n",
       " 'affiliation',\n",
       " 'affiliés',\n",
       " 'affirmative',\n",
       " 'affordable',\n",
       " 'afin',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'aft',\n",
       " 'agcs',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agencies',\n",
       " 'agency',\n",
       " 'agencyconduct',\n",
       " 'agenda',\n",
       " 'agendas',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'aggqc',\n",
       " 'aggregate',\n",
       " 'aggregated',\n",
       " 'aggregates',\n",
       " 'aggregation',\n",
       " 'agile',\n",
       " 'agility',\n",
       " 'agir',\n",
       " 'agissant',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'agreements',\n",
       " 'agricultural',\n",
       " 'agriculture',\n",
       " 'agréé',\n",
       " 'ahead',\n",
       " 'ai',\n",
       " 'aic',\n",
       " 'aid',\n",
       " 'aider',\n",
       " 'aiderons',\n",
       " 'aidez',\n",
       " 'aiding',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aimez',\n",
       " 'ainsi',\n",
       " 'air',\n",
       " 'airb',\n",
       " 'aircraft',\n",
       " 'aires',\n",
       " 'airline',\n",
       " 'airports',\n",
       " 'ais',\n",
       " 'ajax',\n",
       " 'ajgb4doo5f',\n",
       " 'ajout',\n",
       " 'al',\n",
       " 'alation',\n",
       " 'alberta',\n",
       " 'alc',\n",
       " 'alchemer',\n",
       " 'alectra',\n",
       " 'alert',\n",
       " 'alertdriving',\n",
       " 'alerts',\n",
       " 'algorithm',\n",
       " 'algorithmes',\n",
       " 'algorithms',\n",
       " 'align',\n",
       " 'aligned',\n",
       " 'aligning',\n",
       " 'alignment',\n",
       " 'aligns',\n",
       " 'alike',\n",
       " 'alimentaire',\n",
       " 'alimentaires',\n",
       " 'aliments',\n",
       " 'alithya',\n",
       " 'allcantrust',\n",
       " 'allegations',\n",
       " 'allegis',\n",
       " 'allianz',\n",
       " 'allinforequity',\n",
       " 'allocate',\n",
       " 'allocated',\n",
       " 'allocating',\n",
       " 'allocation',\n",
       " 'allocationresponsable',\n",
       " 'allocationresponsible',\n",
       " 'allocations',\n",
       " 'allow',\n",
       " 'allowance',\n",
       " 'allowances',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'allstate',\n",
       " 'alm',\n",
       " 'alocation',\n",
       " 'alongside',\n",
       " 'alr',\n",
       " 'alsafa',\n",
       " 'alternate',\n",
       " 'alternative',\n",
       " 'alternatives',\n",
       " 'alteryx',\n",
       " 'alumni',\n",
       " 'alzheimer',\n",
       " 'amazing',\n",
       " 'amazon',\n",
       " 'ambassador',\n",
       " 'ambiance',\n",
       " 'ambiguities',\n",
       " 'ambiguity',\n",
       " 'ambiguous',\n",
       " 'ambit',\n",
       " 'ambition',\n",
       " 'ambitions',\n",
       " 'ambitious',\n",
       " 'amend',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americas',\n",
       " 'amerisourcebergen',\n",
       " 'amidst',\n",
       " 'aml',\n",
       " 'amounts',\n",
       " 'amplitude',\n",
       " 'amsterdam',\n",
       " 'amélioration',\n",
       " 'améliorer',\n",
       " 'amérique',\n",
       " 'analyse',\n",
       " 'analyser',\n",
       " 'analyses',\n",
       " 'analysi',\n",
       " 'analysing',\n",
       " 'analysis',\n",
       " 'analysis1',\n",
       " 'analysisability',\n",
       " 'analysisapplication',\n",
       " 'analysisexamine',\n",
       " 'analysisexperience',\n",
       " 'analysisextensive',\n",
       " 'analysisit',\n",
       " 'analysisknowledge',\n",
       " 'analysisnice',\n",
       " 'analysisrespond',\n",
       " 'analysisresponsible',\n",
       " 'analysisrun',\n",
       " 'analysisstrong',\n",
       " 'analysisvery',\n",
       " 'analyst',\n",
       " 'analystdapasoft',\n",
       " 'analystduration',\n",
       " 'analyste',\n",
       " 'analystexperience',\n",
       " 'analystexperienced',\n",
       " 'analystgeneral',\n",
       " 'analystlocation',\n",
       " 'analystmicrostrategy',\n",
       " 'analystpermanent',\n",
       " 'analystposition',\n",
       " 'analysts',\n",
       " 'analystshift',\n",
       " 'analyststructure',\n",
       " 'analysttoronto',\n",
       " 'analystwfh',\n",
       " 'analytic',\n",
       " 'analytical',\n",
       " 'analytically',\n",
       " 'analytics',\n",
       " 'analyticsadvance',\n",
       " 'analyticsdemonstrably',\n",
       " 'analyticsresponsibilities',\n",
       " 'analyticssubmitting',\n",
       " 'analytique',\n",
       " 'analytiques',\n",
       " 'analyze',\n",
       " 'analyzed',\n",
       " 'analyzes',\n",
       " 'analyzing',\n",
       " 'ancestries',\n",
       " 'ancestry',\n",
       " 'anchored',\n",
       " 'anchors',\n",
       " 'andbuild',\n",
       " 'andcertification',\n",
       " 'anddata',\n",
       " 'andknowledge',\n",
       " 'andrecruitment',\n",
       " 'android',\n",
       " 'andstrong',\n",
       " 'andstudy',\n",
       " 'andsynthetic',\n",
       " 'anecdotal',\n",
       " 'angel',\n",
       " 'angeles',\n",
       " 'anglais',\n",
       " 'angular',\n",
       " 'angus',\n",
       " 'anheuser',\n",
       " 'animés',\n",
       " 'annie',\n",
       " 'anniversaries',\n",
       " 'anniversary',\n",
       " 'annotations',\n",
       " 'annual',\n",
       " 'annually',\n",
       " 'annuels',\n",
       " 'annum',\n",
       " 'année',\n",
       " 'anomalies',\n",
       " 'anova',\n",
       " 'ans',\n",
       " 'answer',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'anti',\n",
       " 'anticipate',\n",
       " 'anticipated',\n",
       " 'anticipates',\n",
       " 'anticipating',\n",
       " 'anticipation',\n",
       " 'anusha',\n",
       " 'anytime',\n",
       " 'aob',\n",
       " 'aoda',\n",
       " 'aon',\n",
       " 'apac',\n",
       " 'apache',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apartmentratings',\n",
       " 'apb',\n",
       " 'aperçu',\n",
       " 'apex',\n",
       " 'api',\n",
       " 'apis',\n",
       " 'app',\n",
       " 'apparatus',\n",
       " 'appareils',\n",
       " 'apparel',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'appear',\n",
       " 'appetite',\n",
       " 'applauded',\n",
       " 'appliances',\n",
       " 'applicability',\n",
       " 'applicable',\n",
       " 'applicant',\n",
       " 'applicants',\n",
       " 'application',\n",
       " 'applications',\n",
       " 'applicationsimplementation',\n",
       " 'applicationsknowledge',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'applique',\n",
       " 'appliquer',\n",
       " 'appliquées',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appointment',\n",
       " 'appraisal',\n",
       " 'appraisals',\n",
       " 'appraise',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciation',\n",
       " 'apprenons',\n",
       " 'apprentissage',\n",
       " 'apprise',\n",
       " 'approach',\n",
       " 'approachable',\n",
       " 'approaches',\n",
       " 'approachesin',\n",
       " 'approachidentification',\n",
       " 'approaching',\n",
       " 'approfondis',\n",
       " 'appropriate',\n",
       " 'appropriateensure',\n",
       " 'appropriately',\n",
       " 'approval',\n",
       " 'approvaldiscover',\n",
       " 'approvals',\n",
       " 'approve',\n",
       " 'approved',\n",
       " 'approving',\n",
       " 'approvisionnement',\n",
       " 'approvisionnementcapacité',\n",
       " 'approx',\n",
       " 'approximately',\n",
       " 'apps',\n",
       " 'apptio',\n",
       " 'april',\n",
       " 'aptitude',\n",
       " 'aptitudeivr',\n",
       " 'aptitudes',\n",
       " 'ar',\n",
       " 'aramark',\n",
       " 'arcgis',\n",
       " 'architect',\n",
       " 'architectes',\n",
       " 'architecting',\n",
       " 'architects',\n",
       " 'architectural',\n",
       " 'architecture',\n",
       " 'architectures',\n",
       " 'archives',\n",
       " 'archiving',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'areasdemonstrate',\n",
       " 'areasstructure',\n",
       " 'aren',\n",
       " 'arethe',\n",
       " 'argent',\n",
       " 'argentmc',\n",
       " 'arguments',\n",
       " 'arima',\n",
       " 'arise',\n",
       " 'arising',\n",
       " 'arm',\n",
       " 'armes',\n",
       " 'armk',\n",
       " 'arrange',\n",
       " 'arrangement',\n",
       " 'arrangements',\n",
       " 'arranging',\n",
       " 'array',\n",
       " 'arrival',\n",
       " 'arrivals',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrivée',\n",
       " 'arrivées',\n",
       " 'art',\n",
       " 'artefacts',\n",
       " 'articles',\n",
       " 'articulate',\n",
       " 'articulating',\n",
       " 'articulation',\n",
       " 'artifacts',\n",
       " 'artifactsauthor',\n",
       " 'artificial',\n",
       " 'artisans',\n",
       " 'artist',\n",
       " 'artistic',\n",
       " 'artists',\n",
       " 'arts',\n",
       " 'as400',\n",
       " 'asap',\n",
       " 'asapfor',\n",
       " 'asapour',\n",
       " 'asexual',\n",
       " 'asia',\n",
       " 'aside',\n",
       " 'asie',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'askkeep',\n",
       " 'asks',\n",
       " 'askswork',\n",
       " 'asktalentacquisition',\n",
       " 'asl',\n",
       " 'asp',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'asphalt',\n",
       " 'aspirations',\n",
       " 'aspires',\n",
       " 'assante',\n",
       " 'assemble',\n",
       " 'assembles',\n",
       " 'assembly',\n",
       " 'assess',\n",
       " 'assessed',\n",
       " 'assesses',\n",
       " 'assessible',\n",
       " 'assessing',\n",
       " 'assessment',\n",
       " 'assessments',\n",
       " 'asset',\n",
       " 'asset3',\n",
       " 'assetapplication',\n",
       " 'assetbackground',\n",
       " 'assetc',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 10256)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvec_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               tfidf\n",
      "data        1.008909\n",
      "experience  1.064095\n",
      "work        1.097752\n",
      "business    1.105114\n",
      "skills      1.115015\n",
      "team        1.137658\n",
      "management  1.242170\n",
      "analysis    1.259265\n",
      "years       1.259265\n",
      "analyst     1.327642\n"
     ]
    }
   ],
   "source": [
    "# Observe TFIDF Weights\n",
    "\n",
    "tfidf = dict(zip(tvec.get_feature_names(), tvec.idf_))\n",
    "tfidf = pd.DataFrame.from_dict(weights, orient='index')\n",
    "tfidf.columns = ['tfidf']\n",
    "\n",
    "# Lowest TFIDF Scores\n",
    "low_tfidf = tfidf.sort_values(by=['tfidf'], ascending=True).head(10)\n",
    "print(low_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       tfidf\n",
      "managementassist     6.41832\n",
      "dell                 6.41832\n",
      "deletion             6.41832\n",
      "impeccably           6.41832\n",
      "delicious            6.41832\n",
      "softwarework         6.41832\n",
      "softwarestrong       6.41832\n",
      "deliverablescreate   6.41832\n",
      "deliverablespresent  6.41832\n",
      "softwares            6.41832\n"
     ]
    }
   ],
   "source": [
    "# Highest TFIDF Scores\n",
    "high_tfidf = tfidf.sort_values(by=['tfidf'], ascending=False).head(10)\n",
    "print(high_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results, using TF-IDF to look for important features relevent to data analyst jobs is not very effective for unigrams.\n",
    "\n",
    "There are also features that do not have a proper space between two words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Text Pre-processing Pipeline Function</h3>\n",
    "\n",
    "See DSDJ Feature Engineering pt 2 for a train & test version of the Tfidf vectorizer function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that cleans and performs a TFIDF transformation to text data\n",
    "tfidf = TfidfVectorizer(stop_words='english', lowercase=True)\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def tfidf_pipeline(txt):\n",
    "    txt = txt.apply(porter.stem) # Apply Stemming\n",
    "    x = tfidf.fit_transform(txt) # Apply Vectorizer, Stopword Removal, & Lowercasing\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtext_TFIDF = tfidf_pipeline(jobText['Job Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = jobText.shape\n",
    "preprocessed = jobtext_TFIDF.shape\n",
    "\n",
    "print(\"Original raw data df shape: \" + str(original))\n",
    "print(\"Preprocessed data shape: \" + str(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobText_TFIDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word frequency : how many words per post.\n",
    "# Text cleaning : lower casing, extra white-space removal, lemmatization\n",
    "\n",
    "# Determine most common words that occur in the job descriptions. \n",
    "# Predetermine a list of expected lookup terms for dictionary of skills\n",
    "\n",
    "# BOW - Create a list of dictionaries containing word counts for each job posting\n",
    "\n",
    "# Table with skill, count, percentage\n",
    "\n",
    "# Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Words2Vec - similar words are closer together in a sentence\n",
    "\n",
    "# Topic modelling - where skills is considered a topic\n",
    "\n",
    "# NER with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-jobmarket",
   "language": "python",
   "name": "nlp-jobmarket"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
