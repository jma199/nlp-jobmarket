{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Part 3 : Modeling of Pre-processed Text Data</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import Packages</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table, select\n",
    "\n",
    "engine = create_engine(\"sqlite:///joblist.sqlite\")\n",
    "metadata = MetaData()\n",
    "data = Table('data', metadata, autoload=True, autoload_with=engine)\n",
    "stmt = select([data.columns.jobdescription, data.columns.label])\n",
    "connection = engine.connect()\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "df_data = pd.DataFrame(results)\n",
    "df_data.columns = results[0].keys()\n",
    "df_data['jobdescription'] = df_data['jobdescription'].astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load Pre-Processing Steps</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords = ['bachelor', 'degree', 'work', 'equal', 'opportunity', 'employer', 'objectives', 'ontario', 'canada', 'disability', 'strong', 'including', 'ensure', 'understanding', 'related']\n",
    "\n",
    "# Initialize TFIDF Vectorizer\n",
    "tvec = TfidfVectorizer(analyzer = 'word',  \n",
    "                       stop_words = ENGLISH_STOP_WORDS.union(custom_stopwords), \n",
    "                       lowercase= True, \n",
    "                       min_df=2)\n",
    "\n",
    "def tfidf_pipeline(txt):\n",
    "    x = tvec.fit_transform(txt) # Apply Vectorizer, Stopword Removal, & Lowercasing\n",
    "    return x \n",
    "\n",
    "tvec2 = TfidfVectorizer(analyzer = 'word', \n",
    "                       stop_words = ENGLISH_STOP_WORDS.union(custom_stopwords), \n",
    "                       lowercase= True, \n",
    "                       ngram_range=(2,3), \n",
    "                       min_df=4)\n",
    "\n",
    "def tfidf2_pipeline(txt):\n",
    "    x = tvec2.fit_transform(txt) # Apply Vectorizer, Stopword Removal, Lowercasing, & select Bi-/Tri-grams\n",
    "    return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create Train & Test Sets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training and testing data sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_data['jobdescription'],df_data['label'],test_size=0.20, random_state=123, stratify=df_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "574    Role Description:\n",
       "The Messaging Specialist wil...\n",
       "597    Req Id: 278054\n",
       "At Bell, we do more than build ...\n",
       "177    Job description: Skills: Â· Total of 10 years i...\n",
       "228    Are you a kid at heart looking to build a care...\n",
       "318    SENIOR ANALYST, DATA TEAM (Temporary Full-Time...\n",
       "                             ...                        \n",
       "309    BUSINESS INTELLIGENCE ANALYST  RESPONSIBILITIE...\n",
       "78     Category: Business Analysis (functional and te...\n",
       "207    Requisition ID: 97894  Join the Global Communi...\n",
       "219    As a leading mobile games developer, Jam City ...\n",
       "116    Job Title: Data Analyst Job Description:  Job ...\n",
       "Name: jobdescription, Length: 500, dtype: string"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BUSINESS INTELLIGENCE ANALYST  RESPONSIBILITIES Our analyst will be contributing to preparing budgets, forecasts, revenue and expense analysis and business trend analysis. You will provide senior management with financial and business trend reporting used for planning, strategic and tactical decision making. You will also be responsible for the development and maintenance of numerous reports that will point to either data anomalies, business trends or simply over/underspending. The areas covered may include financials, work requests, utilities, capital planning, project management, real estate transactions and others. You will need to analyze the data, make recommendations as appropriate and present the findings.  Experienced building reports using Power BI with live feed from Data Warehouse and be able to write complex queries within SQL Act as Business analyst to comprehend the new requirement for building the new reports Identify tactical and strategic opportunities, gaps, and financial risks through collaboration with cross-functional teams Assist as required with accruals, periodic forecasts and the annual budget/strategic plan preparation, consolidation and analysis, including oversight of budgeting software and liaison with functional resources Assist with capital project and resource allocation reviews, including statistical/financial modeling of assumptive scenarios in support of key business decision-making Contribute to compilation and analysis of financial and operational data required for quarterly Key Performance Indicator (KPI) reporting Preparation and review of departmental expense analysis, focusing on key variances, cost drivers and explanations, including liaison with various functional leaders; Evaluates and investigates financial and operational reporting of high dollar or high profile transactions Special ad-hoc projects and other functions as required by manager or client  QUALIFICATIONS  Power BI, SQL, Python, Macros, PowerPivot and/or Tableau are Mandatory Financial acumen, analytical ability Strong basic accounting skills/understanding Excellent verbal and written communication skills Good organizational skills Self-starter who will innovate, look for problems and corresponding solutions Logical thinker with good common sense BA or BS required 3-5 years relevant experience'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[309]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply pre-processing\n",
    "# Unigrams\n",
    "x_train_TFIDF = tfidf_pipeline(x_train)\n",
    "x_test_TFIDF = tfidf_pipeline(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply pre-processing\n",
    "# Bi- & tri-grams\n",
    "x_train_TFIDF2 = tfidf2_pipeline(x_train)\n",
    "x_test_TFIDF2 = tfidf2_pipeline(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set shape:  (500,)\n",
      "Preprocessed training set for unigrams:  (500, 6536)\n",
      "Preprocessed training set for n-grams: : (500, 12727)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original training set shape: \", x_train.shape)\n",
    "print(\"Preprocessed training set for unigrams: \", x_train_TFIDF.shape)\n",
    "print(\"Preprocessed training set for n-grams: \", x_train_TFIDF2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_test:  (125,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Modeling</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit Random Forest Classifier model\n",
    "rfc = RandomForestClassifier(n_estimators=100, class_weight='balanced')\n",
    "rfc_model = rfc.fit(x_train_TFIDF,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cross-Validation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of cross validation is:  0.852\n"
     ]
    }
   ],
   "source": [
    "# Apply 10-fold cross-validation\n",
    "rfc_result = cross_val_score(rfc_model, x_train_TFIDF, y_train, cv=10, scoring='accuracy')\n",
    "print(\"The mean of cross validation is: \", rfc_result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluation on Test Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 6536 and input n_features is 3213 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cbbce01e472c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predict y values using x train values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_TFIDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m precision, recall, fscore, support = score(y_test, \n\u001b[1;32m      4\u001b[0m                                             \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                             \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dataenv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \"\"\"\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dataenv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dataenv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dataenv/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             raise ValueError(\"Number of features of the model must \"\n\u001b[0m\u001b[1;32m    397\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 6536 and input n_features is 3213 "
     ]
    }
   ],
   "source": [
    "# Predict y values using x train values\n",
    "y_pred = rfc_model.predict(x_test_TFIDF)\n",
    "precision, recall, fscore, support = score(y_test, \n",
    "                                            y_pred, \n",
    "                                            pos_label=1, \n",
    "                                            average ='binary')\n",
    "\n",
    "print(\"Classification Report: \\nPrecision: {}, \\nRecall: {}, \\nF-score: {}, \\nAccuracy: {}\".format(round(precision,3),round(recall,3),round(fscore,3),round((y_pred==y_test).sum()/len(y_test),3)))\n",
    "\n",
    "\n",
    "# ValueError: Number of features of the model must match the input. \n",
    "# Model n_features is 6536 (x_train_TFIDF shape) and input n_features is 3213 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('dataenv': conda)",
   "language": "python",
   "name": "python385jvsc74a57bd013f2b1e521b8f6e58ac5f308ce6e9ec48daaa5d3d12011623b022ddafac4d33a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
