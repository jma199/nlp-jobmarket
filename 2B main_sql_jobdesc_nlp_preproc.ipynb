{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Part 2 : Pre-Processing of Job Description Text</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Import Packages</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# If you haven't already done so, execute:\n",
    "#import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Load data from sqlite database</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data']\n",
      "['jobtitle', 'company', 'location', 'salary', 'jobdescription', 'label']\n",
      "Table('data', MetaData(bind=None), Column('jobtitle', VARCHAR(length=100), table=<data>), Column('company', VARCHAR(length=100), table=<data>), Column('location', VARCHAR(length=25), table=<data>), Column('salary', INTEGER(), table=<data>), Column('jobdescription', TEXT(), table=<data>), Column('label', INTEGER(), table=<data>), schema=None)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table\n",
    "\n",
    "# Query SQL db to get analyst job descriptions first\n",
    "\n",
    "# Create connection to db\n",
    "engine = create_engine(\"sqlite:///joblist.sqlite\")\n",
    "print(engine.table_names())\n",
    "\n",
    "# Load in data table\n",
    "metadata = MetaData()\n",
    "data = Table('data', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "print(data.columns.keys())\n",
    "print(repr(metadata.tables['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jobdescription', 'label']\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import select\n",
    "\n",
    "# Build query\n",
    "stmt = select([data.columns.jobdescription, data.columns.label])\n",
    "stmt = stmt.where(data.columns.label == '0') # 0 = analysts\n",
    "\n",
    "# Create connection to engine\n",
    "connection = engine.connect()\n",
    "\n",
    "# Execute query\n",
    "results = connection.execute(stmt).fetchall()\n",
    "print(results[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows in db\n",
    "\n",
    "from sqlalchemy import func\n",
    "\n",
    "stmt_count = select([func.count(data.columns.jobdescription)])\n",
    "results_count = connection.execute(stmt_count).scalar()\n",
    "print(results_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      jobdescription  label\n",
      "0  Position Title:Pricing Analyst Position Type: ...      0\n",
      "1  Title: Senior Data Analyst - Telephony Manager...      0\n",
      "2  We are looking for a talented Fuel Cell Data E...      0\n",
      "3  CAREER OPPORTUNITY SENIOR METER DATA ANALYST L...      0\n",
      "4  The Data Engineer reports directly to the Dire...      0\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe from SQLAlchemy ResultSet\n",
    "df_data = pd.DataFrame(results)\n",
    "\n",
    "# Give columns proper heading\n",
    "df_data.columns = results[0].keys()\n",
    "print(df_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 450 entries, 0 to 449\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   jobdescription  450 non-null    object\n",
      " 1   label           450 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 450 entries, 0 to 449\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   jobdescription  450 non-null    string\n",
      " 1   label           450 non-null    int64 \n",
      "dtypes: int64(1), string(1)\n",
      "memory usage: 7.2 KB\n"
     ]
    }
   ],
   "source": [
    "df_data['jobdescription'] = df_data['jobdescription'].astype('string')\n",
    "df_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Text Analysis of Job Description</h2>\n",
    "\n",
    "<h3>Pre-processing Pipeline</h3>\n",
    "\n",
    "For each job description, we will tokenize, stem, remove stop words, and lowercase each word.\n",
    "\n",
    "The following is an example using 1 job description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select an example job description from df_data\n",
    "\n",
    "text = df_data['jobdescription'][7]\n",
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471\n"
     ]
    }
   ],
   "source": [
    "# Tokenize example text\n",
    "# Maybe add len(token) to dataframe and plot\n",
    "\n",
    "text_token = word_tokenize(str(text))\n",
    "print(len(text_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(', 'Preferred', ')', 'Work', 'remotely', ':', 'Temporarily', 'due', 'to', 'COVID-19COVID-19', 'precaution', '(', 's', ')', ':', 'Remote', 'interview', 'processPersonal', 'protective', 'equipment', 'provided', 'or', 'requiredPlastic', 'shield', 'at', 'work', 'stationsSocial', 'distancing', 'guidelines', 'in', 'placeVirtual', 'meetingsSanitizing', ',', 'disinfecting', ',', 'or', 'cleaning', 'procedures', 'in', 'place']\n"
     ]
    }
   ],
   "source": [
    "print(text_token[-40:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(', 'prefer', ')', 'work', 'remot', ':', 'temporarili', 'due', 'to', 'covid-19covid-19', 'precaut', '(', 's', ')', ':', 'remot', 'interview', 'processperson', 'protect', 'equip', 'provid', 'or', 'requiredplast', 'shield', 'at', 'work', 'stationssoci', 'distanc', 'guidelin', 'in', 'placevirtu', 'meetingssanit', ',', 'disinfect', ',', 'or', 'clean', 'procedur', 'in', 'place']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "text_stemmed = [stemmer.stem(w) for w in text_token]\n",
    "print(text_stemmed[-40:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Text Pre-processing Pipeline</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the job postings currently available will be considered the \"test\" set and will not be split. Any predictions will be made on new postings scraped at a later date.\n",
    "\n",
    "Here, we will try 2 different vectorizers: CountVectorizer and TF-IDF.\n",
    "\n",
    "The pre-processing pipeline will include the following steps:\n",
    "\n",
    "- Tokenization\n",
    "- Stopword removal\n",
    "- Lower casing\n",
    "- Stemming\n",
    "- Apply transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Count Vectorizer</h2>\n",
    "\n",
    "The CountVectorizer function returns an encoded vector with an integer count for each word.\n",
    "\n",
    "We will use CountVectorizer to identify skills that are commonly found in job descriptions. These skills would therefore have a higher count across the corpus compared to other (i) lesser used or company-specific skills and (ii) non-important words.\n",
    "\n",
    "Here, we will tokenize only words, use the built-in stop words list, and keep only tokens that appear in at least 2 dfs (document frequencies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ab', 'abide', 'abilities', 'ability', 'abinbev', 'able', 'aboriginal', 'aboriginals', 'abreast', 'abroad']\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(analyzer='word', token_pattern = r\"[a-zA-Z]+\", stop_words = 'english', lowercase = True, min_df=2)\n",
    "count_vector = cv.fit_transform(df_data['jobdescription'])\n",
    "\n",
    "print(cv.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ab  abide  abilities  ability  abinbev  able  aboriginal  aboriginals  \\\n",
      "0   0      0          0        8        0     0           0            0   \n",
      "1   0      0          1        2        0     1           0            0   \n",
      "2   0      0          0        0        0     0           0            0   \n",
      "3   0      0          0        1        0     0           0            0   \n",
      "4   0      0          0        2        0     1           0            0   \n",
      "\n",
      "   abreast  abroad  ...  yoga  yonge  york  young  yrs  zendesk  zero  zone  \\\n",
      "0        0       0  ...     0      0     0      0    0        0     0     0   \n",
      "1        0       0  ...     0      0     0      0    0        0     0     0   \n",
      "2        0       0  ...     0      0     0      0    0        0     0     0   \n",
      "3        0       0  ...     0      0     0      0    0        0     0     0   \n",
      "4        0       0  ...     0      0     0      0    0        0     0     0   \n",
      "\n",
      "   zones  zoom  \n",
      "0      0     0  \n",
      "1      0     0  \n",
      "2      0     0  \n",
      "3      0     0  \n",
      "4      0     0  \n",
      "\n",
      "[5 rows x 6285 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe out of CV sparse array\n",
    "counts = pd.DataFrame(count_vector.toarray(), columns = cv.get_feature_names())\n",
    "print(counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9594777689383894\n"
     ]
    }
   ],
   "source": [
    "# calculate sparsity\n",
    "sparsity = 1.0 - np.count_nonzero(counts) / counts.size\n",
    "print(sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pss', 'bonne', 'reexigencesun', 'edl', 'staging', 'collaborator', 'flt', 'bancware', 'surveiller', 'testament', 'alchemer', 'acumenapplication', 'discountsextended', 'pain', 'morningstar', 'citytv', 'merchandisework', 'chairman', 'leveltechnical', 'summarythe', 'trox', 'transmission', 'profitableupdate', 'imaginary', 'andbuild', 'unable', 'sveiller', 'setsresponsible', 'analysisresponsible', 'fra', 'totaling', 'disponibilit', 'teamsinvestigate', 'pacer', 'quantity', 'experiencegood', 'excels', 'wal', 'absolute', 'concurrently', 'datalogging', 'arrangement', 'probl', 'programmed', 'fro', 'marvel', 'educationventure', 'conseils', 'ibms', 'vues', 'propels', 'powerquery', 'natalie', 'digitize', 'mac', 'exhibiting', 'clocks', 'jurisdictional', 'ligne', 'organizationactively', 'pharmaceuticals', 'instructing', 'sisense', 'viz', 'supportlabour', 'practicesrequired', 'solutionsmaintain', 'experiencestrong', 'solutionscontinually', 'rationnels', 'finalist', 'wearing', 'prendre', 'prayer', 'meltdown', 'unlawful', 'consolidations', 'lee', 'smoothly', 'assetpassion', 'compliment', 'needsability', 'recover', 'stakeholdersdevelop', 'pioneers', 'configurable', 'shiftholidaysweekendsexperience', 'dsps', 'crafting', 'wineries', 'errorsdata', 'acss', 'snapshot', 'ususing', 'niveau', 'quadrel', 'validations', 'inactivation', 'paymentsrun', 'dc', 'engineeringexcellent', 'journal', 'workplacesby', 'vbaexceptional', 'paternity', 'weighs', 'conservation', 'sybase', 'succession', 'laboratories', 'actionprovides', 'metal', 'empathize', 'daxexperience', 'commodities', 'innovativeeducation', 'pyxfue', 'acc', 'judgements', 'analysisexamine', 'proceduresable', 'directory', 'hot', 'rendement', 'trial', 'recoveries', 'hbase', 'mode', 'aspires', 'undergo', 'rooftop', 'ficierez', 'tuesday', 'restore', 'persevering', 'sills', 'vector', 'genuine', 'predicable', 'trail', 'realization', 'ploiement', 'ftp', 'listings', 'nfa', 'aptitudeivr', 'skillsbe', 'locationsto', 'austin', 'concern', 'screeningsvirtual', 'merging', 'fenergo', 'motor', 'mifid', 'causalit', 'snap', 'bearing', 'dataindependently', 'analyticssubmitting', 'experiencepost', 'variant', 'vison', 'matures', 'frequencies', 'entrep', 'slf', 'directives', 'eventsdental', 'federally', 'descriptionthe', 'shut', 'stuff', 'connectivitytest', 'misrepresentation', 'publichealthontario', 'exchanged', 'abilitiesexcellent', 'predictions', 'analysisnice', 'needednice', 'supportresearch', 'revamp', 'winfrey', 'dund', 'responsibilitiesgenerate', 'trustee', 'poor', 'datesadvanced', 'cop', 'parer', 'interac', 'hourskey', 'obvious', 'ledger', 'wyman', 'inclusively', 'gestation', 'challengesanalyzing', 'preferredreference', 'completes', 'certainly', 'im', 'skillsextremely', 'cmp', 'recognizable', 'caribbean', 'restraintspossess', 'sdtm', 'symbol', 'aggqc', 'ngos', 'spreadsheetsself', 'sfdc', 'mentaires', 'concerne', 'basement', 'automatique', 'scotland', 'cowboy', 'cdh', 'dull', 'complementing', 'simplified', 'rewrite', 'endroit', 'magasins', 'court', 'skillsflexibility', 'fss', 'cannabis', 'meta', 'ar', 'revolutionary', 'privileged', 'clientsg', 'fluently', 'impression', 'degreeminimum', 'qualificationsnote', 'nationally', 'death', 'multitasker', 'depict', 'respecting', 'container', 'superiors', 'extracted', 'gameloft', 'ubiquitous', 'pushedcreate', 'appliqu', 'technicians', 'endlesspossibilities', 'engines', 'anecdotal', 'weekapplication', 'sensible', 'bipost', 'caused', 'connective', 'alberta', 'descriptionwith', 'parameter', 'improvised', 'safa', 'appropriateensure', 'tfsa', 'editorial', 'surstocks', 'rework', 'bigquery', 'parkway', 'ghg', 'whatrecognized', 'arriv', 'eventsschedule', 'lump', 'upc', 'cut', 'optimiser', 'assetself', 'environmentaccess', 'fda', 'tbm', 'mississaugajob', 'evolves', 'texts', 'evestmentcommunicate', 'toolstesting', 'december', 'systemdevelop', 'requirementsset', 'cdr', 'constituents', 'realistic', 'beta', 'peu', 'remediated', 'intersect', 'acute', 'customersperforms', 'configures', 'expands', 'layout', 'yelp', 'dependable', 'foresi', 'experienceproject', 'remplissagevalider', 'requiredmust', 'complyworks', 'exacting', 'reportsprovide', 'datarecommend', 'neuroendocrine', 'flowcharting', 'convictions', 'ministers', 'rx', 'responsesgenerate', 'ppt', 'cambridge', 'racing', 'pandas', 'tendermaintain', 'pets', 'programpaid', 'woodbridge', 'compr', 'bookjob', 'analyste', 'optimozwr', 'envelope', 'idr', 'toyota', 'furthering', 'prescriptive', 'dutiesreview', 'kj', 'skillsbanking', 'apptio', 'agenda', 'norm', 'therapists', 'recurring', 'reportingresponsible', 'imported', 'computations', 'demanded', 'sommaire', 'rdms', 'environmentmay', 'witness', 'header', 'visum', 'reviewsrecommend', 'onexperience', 'exceeded', 'consultancy', 'collating', 'warsaw', 'dispatchers', 'sarcoma', 'habits', 'baseparticiper', 'keyboard', 'rosen', 'galit', 'ecjymoxtu', 'heirs', 'rayon', 'gui', 'johnvince', 'assetshandle', 'growthoffice', 'liability', 'intuit', 'offence', 'codestore', 'iphone', 'causality', 'likeensure', 'licensees', 'deletion', 'sonnet', 'exercising', 'fastidiousness', 'epics', 'buried', 'ps', 'touchpoint', 'persys', 'wholesaler', 'procura', 'uncompromised', 'runs', 'miipe', 'experienceundergraduate', 'commentaries', 'facilityrole', 'audition', 'experienceworkday', 'datafamiliarity', 'ntn', 'yu', 'bl', 'transitioning', 'jointhegame', 'tpl', 'supportoversee', 'mighty', 'gsm', 'verifies', 'mentally', 'procedurecomply', 'joseph', 'postgresqlproficiency', 'menu', 'obiee', 'gartner', 'standpoint', 'toperform', 'waterstone', 'polar', 'roaming', 'similarly', 'pledge', 'treaties', 'meetingsparticipate', 'integritymanage', 'smartest', 'prospectspotentially', 'pretty', 'hfds', 'reinsurance', 'trackingexternal', 'honda', 'disqualification', 'telmar', 'reforms', 'certifying', 'clientswork', 'jugement', 'augment', 'dresscommuter', 'exemption', 'syracuse', 'contests', 'customize', 'cnn', 'winnipegabout', 'requirementsbachelor', 'taux', 'schedulework', 'hue', 'sport', 'maturing', 'attractions', 'pioneered', 'motivator', 'hwy', 'sao', 'confidently', 'mainstreetresearch', 'cutover', 'carlsbad', 'howprovide', 'assurancewhy', 'tpm', 'roads', 'ferrari', 'activations', 'cohorts', 'benefitsdental', 'attainment', 'unknowns', 'politiques', 'drawn', 'livraison', 'sydney', 'beloved', 'trainer', 'vc', 'snps', 'mixes', 'observations', 'expensive', 'planssupport', 'ram', 'immunology', 'heure', 'refugees', 'excess', 'suit', 'managerdivision', 'runbooks', 'fieldknowledge', 'documentatio', 'cusp', 'rsm', 'unduly', 'crock', 'offtuition', 'numbersstrong', 'boast', 'professions', 'insightsassist', 'lgd', 'portfolioensure', 'decide', 'strategydrive', 'timeabout', 'departmentmaintain', 'highways', 'doubleclick', 'ontarioduties', 'movements', 'reinforcing', 'allocated', 'softwarework', 'fridays', 'jit', 'unmet', 'extractions', 'dice', 'personas', 'wordexperience', 'rebates', 'arrive', 'vueexaminer', 'originmerchant', 'responsibilitiespreparing', 'aiding', 'slide', 'autonomouslymathematically', 'unilateral', 'stattools', 'postgressql', 'tackles', 'opportunityreference', 'lottery', 'pickup', 'consequential', 'wire', 'milwaukee', 'mawer', 'originates', 'procedureswork', 'experienceproficiency', 'connaissances', 'extenstionthis', 'choses', 'dipl', 'assurer', 'skillsanalytical', 'assumes', 'balancework', 'gestionnaires', 'translations', 'dictionarieswork', 'pourquoi', 'assetc', 'bon', 'slight', 'mortem', 'procedurescertified', 'rockstar', 'gtsno', 'sdmu', 'ntt', 'lp', 'mcr', 'erectile', 'furnished', 'fitnessmonday', 'eu', 'kam', 'receives', 'commit', 'essence', 'knack', 'implementationpartner', 'employerwe', 'ib', 'yearsexperience', 'mmi', 'positionthis', 'bobj', 'operationsreports', 'edition', 'planextended', 'transitional', 'webmasters', 'np', 'trise', 'reuters', 'learnerproactive', 'decked', 'sds', 'scheduleanalyse', 'citylitics', 'formatting', 'dataworking', 'instrumentation', 'disney', 'gic', 'underperforming', 'thereon', 'assister', 'divestiture', 'followedproject', 'copybook', 'fran', 'probably', 'fc', 'performancea', 'hull', 'orthodontic', 'bizxcel', 'busiest', 'appear', 'perfecting', 'isarta', 'lights', 'souring', 'rolereporting', 'console', 'npo', 'dyson', 'infogram', 'indices', 'trimestrielles', 'experiencesyou', 'dots', 'tlf', 'australian', 'planningproficiency', 'synth', 'rrsps', 'cw', 'rev', 'replica', 'android', 'parkingstore', 'connex', 'accessiblecareers', 'hba', 'ordersprovide', 'ration', 'downsview', 'diplomatie', 'appreciated', 'mosaicjobs', 'scheduleon', 'trucks', 'prospectsmaintain', 'regulationsassign', 'electronics', 'identityiq', 'whythe', 'montrer', 'imports', 'acknowledged', 'variants', 'algorithmes', 'insurers', 'responsiveness', 'vce', 'origination', 'stata', 'problemsthe', 'dataiku', 'cfo', 'restructurings', 'indm', 'consumptionreview', 'housing', 'sustain', 'standardsstrong', 'detaildemonstrated', 'complying', 'materially', 'cries', 'outbreak', 'lineages', 'queriesdemonstrated', 'trans', 'accruent', 'devicesidentify', 'narios', 'imbalances', 'confectionary', 'discharged', 'qualityprepare', 'marchandises', 'mountain', 'publishes', 'smash', 'overseas', 'bti', 'nea', 'polished', 'restraints', 'texas', 'solides', 'iteratively', 'interpreted', 'biotech', 'requestswork', 'graduating', 'deserve', 'departmentsupport', 'skillssolid', 'segmented', 'scrummaster', 'grocery', 'telles', 'frenchreference', 'quel', 'rounds', 'forecastclarity', 'parking', 'lioration', 'draws', 'nut', 'projectsability', 'scopes', 'devop', 'maching', 'commerciales', 'unforgettable', 'invaluable', 'databrick', 'edwards', 'bettercareer', 'equifax', 'approvisionnement', 'rolethe', 'registerspreparation', 'invests', 'habitat', 'intersex', 'tradoffs', 'recently', 'stanley', 'emme', 'packed', 'collaborations', 'trademarks', 'pumping', 'cmto', 'reliablemanage', 'reportproduce', 'mater', 'newwidgets', 'analysisvery', 'financially', 'balancegeneral', 'exhaustive', 'crisis', 'practitioner', 'winner', 'canned', 'cummins', 'opgt', 'prem', 'cancellations', 'replaced', 'ratesresolve', 'qualificationsuniversity', 'latitude', 'gusto', 'whmis', 'ceos', 'brbusinesscanada', 'problemsjob', 'monthsapplication', 'ppif', 'lateral', 'nuries', 'occurrence', 'mappinganalyzing', 'optimizationexecute', 'wonscore', 'environmentdemonstrated', 'sbd', 'makeup', 'treasurer', 'viral', 'transcad', 'dermatology', 'programmation', 'inviting', 'haveion', 'calypso', 'riskgenerate', 'sitesupport', 'assessible', 'park', 'assumptive', 'errorsmaintain', 'cicd', 'desjardins', 'mitigates', 'requirementsshare', 'propensity', 'recap', 'projectsconstruct', 'meritocracy', 'responsibilitiesas', 'irc', 'transitions', 'ollaborate', 'agriculture', 'expansiongather', 'caia', 'videos', 'countless', 'societal', 'television', 'nt', 'interruptions', 'outgoing', 'correlate', 'impartiales', 'pathogens', 'taste', 'lisation', 'emarque', 'intra', 'resilience', 'grants', 'averages', 'calibration', 'problemsprevious', 'stringent', 'analystposition', 'dataensure', 'cha', 'wpp', 'attentive', 'indirectly', 'dataon', 'confirmed', 'classrooms', 'truck', 'intermediated', 'processthe', 'atp', 'intmd', 'truths', 'powerday', 'fluctuating', 'establishments', 'rejected', 'characterized', 'apartmentratings', 'turtle', 'kept', 'nv', 'lytx', 'corner', 'revitalize', 'groupm', 'fg', 'iris', 'cemeteries', 'virtualization', 'operationsstatus', 'spreadsheetsconduct', 'charities', 'sandboxes', 'backbone', 'bird', 'requiredhighly', 'retains', 'authoring', 'wholesalers', 'reforecasting', 'dialog', 'atout', 'clientspotentially', 'fieldcpa', 'environmentthis', 'grs', 'transcript', 'prescription', 'knock', 'nextlaw', 'shoprite', 'jurisdiction', 'responsibilitiesengage', 'conveying', 'dimp', 'prepack', 'queen', 'usersdemonstrated', 'sunrise', 'projectsassist', 'governmental', 'graphsmust', 'classified', 'improvementexperience', 'softwarestrong', 'secondment', 'serversprovide', 'cadence', 'cleint', 'locates', 'constitutes', 'walk', 'teamwear', 'canadareports', 'pieces', 'skillsproficient', 'responsibilitiesprovides', 'conversationdocumentationuser', 'cheap', 'logique', 'indexing', 'refreshes', 'recordsjob', 'moerae', 'hs', 'lorex', 'alithya', 'containment', 'facets', 'credits', 'solutionsstrong', 'tenu', 'toolsjob', 'fiscal', 'subsidized', 'accuracydrive', 'collate', 'regimes', 'sponsored', 'consiste', 'justice', 'postgress', 'genuity', 'covenants', 'caredevelop', 'internship', 'ipb', 'contractors', 'prm', 'solvingexcellent', 'vendorsfacilitate', 'defensible', 'layman', 'ubuntu', 'csa', 'prevail', 'influencer', 'fuse', 'timereports', 'chatham', 'wordhigh', 'mobilize', 'consolidating', 'extending', 'importe', 'deteriorating', 'diagramsdemonstrated', 'performancerecommend', 'allianz', 'prenez', 'explores', 'twelfth', 'deflection', 'layperson', 'hubon', 'drug', 'skillsproven', 'broadcasts', 'isle', 'rank', 'adam', 'prioritizationstrong', 'edr', 'terrific', 'exigences', 'weekdays', 'rodanenergy', 'dues', 'engineerssupport', 'gold', 'teamaccounting', 'werum', 'analytique', 'jays', 'sanctioned', 'cab', 'taires', 'brs', 'cbc', 'estimatesfollow', 'floater', 'cope', 'lizzo', 'max', 'aft', 'minh', 'ratio', 'gymon', 'folks', 'leaseplan', 'journals', 'docusign', 'stretching', 'trouvez', 'profitably', 'errorsreview', 'modellingsolid', 'observe', 'apartment', 'outs', 'hcg', 'skillsself', 'reimer', 'creeds', 'contentious', 'knowing', 'digitizes', 'sensitivities', 'comps', 'investor', 'parametric', 'salescreate', 'outhire', 'simplifiers', 'chaos', 'consistencies', 'ajax', 'riser', 'faced', 'alm', 'parmida', 'haveexperience', 'literacy', 'suggested', 'ecqvbop', 'preferredshould', 'fournissant', 'embodying', 'overhead', 'knowledgeextensive', 'soient', 'ended', 'resourcing', 'utilisant', 'modes', 'discrepancy', 'objectivesthe', 'trendsdesired', 'reportsadditional', 'conjoint', 'powerpointmust', 'hone', 'administered', 'assetapplication', 'slt', 'fingerprints', 'mexico', 'marginalized', 'enriching', 'cyberark', 'soap', 'thomas', 'mannerensure', 'chainminimum', 'mirrors', 'requirementsextract', 'responded', 'payschedule', 'contractexperience', 'clarifying', 'avanc', 'bioinformaticians', 'mon', 'worthiness', 'tdd', 'nestle', 'strategiesown', 'talentacquisition', 'dog', 'bacterial', 'preferre', 'uken', 'wording', 'hsb', 'simultaneouslyflexibility', 'forwards', 'kimberly', 'osisoft', 'croissante', 'ho', 'tablir', 'anddata', 'incompatibility', 'permanentcurrent', 'clusters', 'auditable', 'moat', 'andsynthetic', 'clothing', 'road', 'opex', 'delving', 'compromise', 'shiftlanguage', 'corporatelocation', 'inaccuracy', 'reportscollaborate', 'dataadvanced', 'sec', 'vogue', 'scenes', 'replacements', 'biologists', 'doctor', 'logging', 'familiarize', 'rp', 'marriage', 'subfunction', 'situated', 'operability', 'adf', 'macroshould', 'scj', 'comprehensively', 'catalyze', 'approvisionnementcapacit', 'culling', 'allegations', 'chargebee', 'queue', 'hearing', 'belvika', 'tied', 'ats', 'mantra', 'tableauo', 'dashboardsexperience', 'sant', 'automatically', 'dynamix', 'pratiques', 'broadway', 'switching', 'offwellness', 'layer', 'transmit', 'eventual', 'escalates', 'tbats', 'biologics', 'defuse', 'surgical', 'bayshore', 'white', 'uk', 'personalize', 'formidables', 'environmentexcellent', 'chair', 'betterment', 'unceded', 'unsurpassed', 'activitiesportfolio', 'softwares', 'fetch', 'grandes', 'rbio', 'sortie', 'researcher', 'older', 'vetting', 'additions', 'cogent', 'baccalaur', 'underpinned', 'prizes', 'clientsmake', 'messagingreference', 'senter', 'nourish', 'clientsdemonstrated', 'immensely', 'devising', 'strategiescollaborates', 'rifs', 'religions', 'transferrable', 'emea', 'sharingwork', 'reportsmodifies', 'balancecareer', 'atteints', 'valuedprevious', 'camera', 'lender', 'accountant', 'dd', 'equipping', 'concurrentielle', 'vey', 'audienceability', 'newpower', 'admin', 'wrangle', 'concernant', 'functionswork', 'conform', 'unboxed', 'accomplishes', 'donor', 'torontofilmschool', 'operationally', 'ido', 'quadrants', 'ticket', 'terminations', 'spa', 'staying', 'insightsyou', 'bonuscomprehensive', 'langages', 'approachidentification', 'ead', 'reconnue', 'dive', 'workstreams', 'benckiser', 'bas', 'cipm', 'nrl', 'averaging', 'expliquer', 'lhins', 'selena', 'jewellery', 'patios', 'reportingprocess', 'courantes', 'grad', 'meilleurs', 'vbajob', 'incluant', 'pi', 'knowledgeadvanced', 'messy', 'unconditionally', 'allcantrust', 'repeated', 'holder', 'dynamiques', 'setp', 'planninguse', 'rup', 'amsterdam', 'loads', 'fsd', 'giques', 'forth', 'dia', 'intersecting', 'killi', 'voc', 'esp', 'recoup', 'commonalities', 'developmentinteract', 'solveability', 'professionnel', 'mannerable', 'unmatched', 'ncr', 'yearmaternity', 'dsi', 'visualisation', 'expandable', 'enjoyment', 'automatis', 'maptitude', 'asexual', 'experienceminimum', 'specimens', 'peripherals', 'interagir', 'broadest', 'sequel', 'softwarehigh', 'histories', 'sparking', 'deadlinesability', 'agissant', 'achievers', 'anniversary', 'candid', 'mosaic', 'creek', 'converted', 'assetcreative', 'estates', 'deficiencies', 'codeadvanced', 'environmentwork', 'static', 'contractgreat', 'robbie', 'plantwork', 'wholedress', 'juggling', 'tissent', 'goeasy', 'systemsexperience', 'warrants', 'processe', 'technologysolid', 'flexing', 'hdpp', 'construed', 'activityupdate', 'datamanage', 'strategyyou', 'examiner', 'ranks', 'assistant', 'ias', 'nutritious', 'penetration', 'cd', 'ecba', 'experienceprogramming', 'tradingknowledge', 'mannerconducting', 'browsing', 'guru', 'powercenter', 'taskexcellent', 'esop', 'burn', 'costreorganize', 'refinement', 'hql', 'emotional', 'critiques', 'keyword', 'sustains', 'cadres', 'pov', 'intuition', 'emir', 'analysisit', 'commute', 'tenets', 'educators', 'occupying', 'bitbucket', 'revue', 'enthusiasmflexible', 'weigh', 'bia', 'consists', 'askkeep', 'authenticated', 'solicitation', 'tangerine', 'extensions', 'oprah', 'prototype', 'acquerrez', 'idq', 'forums', 'remotelywork', 'capacityexperience', 'mb', 'abused', 'outlets', 'imperatives', 'discrepanciescreate', 'sift', 'fetched', 'detailproficient', 'skillsdomain', 'sox', 'crmimplement', 'wallet', 'reits', 'orange', 'editor', 'centos', 'agencyconduct', 'auditors', 'maison', 'visualizing', 'premiere', 'bottlenecks', 'chi', 'encouraging', 'coworker', 'exposed', 'analyticsadvance', 'gomez', 'mmc', 'accident', 'island', 'kowledge', 'recordkeeping', 'cooling', 'entrepreneurship', 'knowledgemust', 'continuellement', 'deliverablescreate', 'indsales', 'ides', 'contains', 'postulants', 'implementationdelivery', 'nifi', 'predecessor', 'impose', 'adjustment', 'businessworking', 'aimez', 'diarizes', 'marketview', 'jts', 'merch', 'toolset', 'saptimely', 'nbca', 'largescale', 'anticipation', 'longest', 'react', 'accuracya', 'systemsin', 'requirementscollaborate', 'aper', 'medicine', 'sasms', 'relaxed', 'ventes', 'trademark', 'ist', 'spiritual', 'transparent', 'ussir', 'tackling', 'optimistic', 'angus', 'modifies', 'dock', 'socially', 'brien', 'flesh', 'leasing', 'european', 'innovatively', 'costdevelopment', 'oats', 'managersdrive', 'reinforce', 'skillsjob', 'scican', 'reap', 'patching', 'rises', 'farms', 'scickit', 'notices', 'teleworking', 'pmbok', 'vivendi', 'torrance', 'identifier', 'datafamiliar', 'capitalizationprovide', 'january', 'openview', 'cbi', 'abnormal', 'offsite', 'processby', 'rbs', 'households', 'connectedness', 'confirmationprojects', 'aeconone', 'utilisation', 'thodes', 'bba', 'processesresearch', 'apparel', 'bpo', 'vocabulary', 'sailpoint', 'lopr', 'snapit', 'rms', 'cobol', 'weaknesses', 'sqlexperience', 'focusedcontact', 'superintendents', 'storylines', 'progressupdate', 'methodologycustomer', 'apex', 'stakeholdersflexible', 'lodging', 'apprise', 'optimizationprovide', 'developingfinancial', 'neededexperience', 'templatesperform', 'appraisals', 'shit', 'formulasexperience', 'percentage', 'marketingchemtrade', 'libraries', 'tout', 'dominates', 'cours', 'sparx', 'fastfrate', 'valuers', 'srs', 'shoppers', 'incentives', 'excelbilingual', 'accelerant', 'individuality', 'moneris', 'moxam', 'personaization', 'formuler', 'raises', 'sourced', 'mirror', 'checkout', 'requirementsdata', 'lost', 'systemsinvestigate', 'progressed', 'accountabilitieswork', 'fippa', 'regulates', 'datar', 'quota', 'brine', 'asphalt', 'strat', 'versus', 'virtue', 'ontariothe', 'buyers', 'mutations', 'assignmentscompleted', 'listensure', 'unearth', 'concur', 'operationsconduct', 'milestone', 'standardise', 'incomplete', 'underpins', 'forecastingstrong', 'shipments', 'analystduration', 'ssrsemployment', 'hasbro', 'districts', 'walking', 'vertically', 'interfacedevelop', 'planninglead', 'customization', 'topline', 'checkouts', 'uniforms', 'remuneration', 'missisauga', 'asylees', 'audio', 'aggregated', 'menaces', 'precautionary', 'tabling', 'valuationable', 'mandated', 'lookout', 'velopper', 'armk', 'requiredsetup', 'offercompensation', 'delve', 'oppression', 'burndown', 'trc', 'projectable', 'upfront', 'waver', 'pad', 'pse', 'doat', 'pbi', 'numeric', 'las', 'insigful', 'reengineering', 'universities', 'reps', 'suiteactively', 'recipient', 'turned', 'peering', 'circulating', 'tableaufamiliar', 'aramark', 'moved', 'energypreferred', 'acii', 'advert', 'donated', 'nuexzu', 'exig', 'kkr', 'saturday', 'reportpromotional', 'matiques', 'journalists', 'plushigh', 'competences', 'therefor', 'oliver', 'gulzar', 'accuracywe', 'millionaire', 'huron', 'supporter', 'complexes', 'onnent', 'layouts', 'lexus', 'compare', 'deduction', 'dir', 'rising', 'introductory', 'dfd', 'intestate', 'aecon', 'pixels', 'edt', 'fidessa', 'threat', 'environmentbased', 'huddles', 'neededpossible', 'expose', 'quantify', 'bolted', 'trips', 'unrestricted', 'handbooks', 'arrivals', 'asapour', 'projected', 'physically', 'viya', 'solutionsexperience', 'indicatorsanalyze', 'aside', 'datarama', 'experienceproduct', 'needcollege', 'contributors', 'paint', 'reportsanalyze', 'kingston', 'reflecting', 'ecosys', 'offwork', 'cutovers', 'analysisrun', 'bills', 'containersperform', 'campuses', 'coursework', 'tells', 'ecc', 'assistssupport', 'laying', 'adsp', 'vfa', 'unisystech', 'documentationcreate', 'mensuel', 'smooth', 'singapore', 'dry', 'sftp', 'coursesminimum', 'loaders', 'sba', 'element', 'detailing', 'mississauaga', 'initiativesassist', 'amidst', 'lookups', 'bringprevious', 'wysiwygsexperience', 'pressurestrong', 'preferredexpert', 'articulation', 'homeequity', 'baby', 'shellscript', 'perceives', 'degreeexperience', 'planters', 'manila', 'statutes', 'annotations', 'idc', 'interfacesdesired', 'maintenanceimplement', 'cane', 'adesa', 'optimizationproficient', 'colours', 'handon', 'keras', 'revolutionize', 'refurbishment', 'docker', 'ranges', 'tele', 'centricitynumeris', 'paramount', 'cessaires', 'envisioned', 'pluslocation', 'wm', 'schedulelife', 'dni', 'soutient', 'easyhome', 'river', 'timeadditional', 'consolidatenice', 'constante', 'citizenships', 'counting', 'philosophies', 'released', 'tensorflow', 'charge', 'comprendre', 'fico', 'starterindependentgood', 'creditor', 'kingdoms', 'signing', 'sanitation', 'dimension', 'analysisability', 'principaux', 'devotion', 'skillsjava', 'materialsqualifications', 'rsagroup', 'broadcast', 'usersyou', 'hdfs', 'proportions', 'dufferin', 'separates', 'midtown', 'overallyou', 'wwps', 'uit', 'concentrates', 'outliers', 'timeschedule', 'neededparticipate', 'intergovernmental', 'keynote', 'standardization', 'queriesjob', 'deviation', 'indispensable', 'loftcs', 'stampexperience', 'mejuri', 'emissions', 'gd', 'datause', 'matlabmust', 'swarming', 'lbs', 'practicesidentify', 'seconday', 'saisonni', 'beaut', 'mria', 'confirms', 'mpower', 'grandma', 'incapable', 'cars', 'favor', 'knowledgeknowledge', 'ridership', 'equivalentminimum', 'inspiration', 'developertasks', 'iron', 'supermarkets', 'famous', 'trafficking', 'stems', 'metabolic', 'soti', 'ind', 'feedsdetermine', 'raisings', 'excellences', 'semi', 'ancestries', 'recherches', 'ideate', 'bmc', 'performancedeveloping', 'homegrown', 'recognitions', 'tours', 'skillsyou', 'adults', 'tiny', 'oem', 'insurancelife', 'lease', 'fits', 'reckitt', 'productengage', 'simcorp', 'responsibilitiesthe', 'checking', 'adapts', 'remotelywe', 'decisioning', 'brunswick', 'appraisal', 'brg', 'fostered', 'parkingwork', 'skillsa', 'manipulations', 'timeframes', 'giants', 'consid', 'deriving', 'practitioners', 'categorygenerate', 'veiller', 'conglomerates', 'behaviorconduct', 'bcbs', 'conservationists', 'catastrophe', 'teamdevelop', 'rtb', 'qlicksense', 'floors', 'approaching', 'actualizing', 'servicesadvanced', 'flora', 'williams', 'semantic', 'gc', 'fmcg', 'banni', 'charges', 'discontinuationsmaintain', 'eyes', 'hydrogenics', 'productively', 'dialogue', 'accurateaudit', 'bcomm', 'effectuer', 'detected', 'pratique', 'nationale', 'genuinely', 'minute', 'accompanying', 'happened', 'dossier', 'expire', 'sachs', 'timedepartment', 'reconciled', 'walkthrough', 'edtech', 'pulled', 'delicious', 'cooking', 'vwo', 'brief', 'mannerresults', 'breathe', 'agr', 'requestspartner', 'sponsorship', 'clicdata', 'capabilitiesdetail', 'cns', 'deadlinesenvironment', 'qbrs', 'digest', 'instill', 'arguments', 'forecasted', 'ei', 'analyststructure', 'khosla', 'doingdaily', 'profitabilityanalyzing', 'preserve', 'calcooverview', 'benchers', 'signoffs', 'slow', 'advantages', 'colleges', 'billed', 'systemscanadian', 'biztalk', 'nielsenims', 'handoffs', 'ads', 'permitted', 'solomon', 'positives', 'scotia', 'cmec', 'isan', 'confections', 'requirementsstrong', 'sectorplease', 'laptops', 'visions', 'ehsq', 'dissolved', 'fridaylicence', 'sending', 'pridepass', 'rnn', 'computerperks', 'payout', 'heartfelt', 'supervised', 'fhab', 'disprove', 'adjacent', 'acritas', 'represented', 'refurbish', 'inefficiencies', 'avid', 'robinson', 'actuals', 'prove', 'caif', 'environmentbs', 'requirementaptitude', 'necessaryability', 'ministries', 'reshaping', 'diagraming', 'soucier', 'georgia', 'priced', 'loft', 'optimumtm', 'documentedensure', 'comprises', 'shaped', 'pd', 'conditiondesired', 'publier', 'webhooks', 'statista', 'comfy', 'kick', 'andknowledge', 'plentiful', 'analysisextensive', 'henkel', 'ceaseless', 'millennials', 'hcm', 'rtgs', 'homebase', 'tower', 'valuesintegrity', 'encryption', 'baskets', 'shorts', 'settling', 'ent', 'operatesproviding', 'solutionsprovide', 'norms', 'thoughtful', 'jiras', 'resourcefulable', 'tom', 'doesour', 'reassignment', 'clicks', 'unitsqualifications', 'impossible', 'optimizer', 'packageemployee', 'impeccably', 'prodigy', 'outre', 'approve', 'schedulepaid', 'mckinsey', 'haut', 'processtemperature', 'complaints', 'jr', 'cnrc', 'factories', 'asseteffective', 'medcan', 'joe', 'consultantssupport', 'promotionnelles', 'discussing', 'recherchons', 'eam', 'lstm', 'genome', 'pho', 'ecomm', 'goalsyou', 'officeability', 'necessarywhat', 'rtp', 'resultsprepare', 'biknowledge', 'subsidies', 'plansprocure', 'enrich', 'flowupgrade', 'winback', 'wildly', 'sagemaker', 'vertical', 'estimation', 'aged', 'impactmake', 'rfi', 'lay', 'skillsdemonstrate', 'culturelle', 'successfulfour', 'decker', 'metabase', 'waves', 'entamant', 'nauxvmkz', 'responsibilitiescreate', 'timeconduct', 'aic', 'fundamentally', 'depot', 'qualificationsposition', 'emphasize', 'concord', 'gbci', 'malta', 'artifactsauthor', 'minimuma', 'testingif', 'onfacebook', 'gulier', 'pivottables', 'experiencereference', 'resell', 'marsh', 'applauded', 'responsibilitiescollect', 'processesassists', 'odette', 'mclennan', 'criteriainterface', 'canadiens', 'undergrad', 'kinds', 'sconducts', 'gateways', 'dures', 'refugee', 'differentiation', 'concentration', 'backfill', 'enjoyable', 'uno', 'realities', 'requirementsthe', 'seniors', 'accuracydevelop', 'supportassist', 'validationensure', 'universal', 'salesanalyze', 'stakeholdersproven', 'donations', 'vulnerability', 'chops', 'stooping', 'progressively', 'cafeteria', 'earthrangers', 'opens', 'premiums', 'compliancevalidate', 'accuracyanalyze', 'pythonprofessional', 'andstudy', 'myriad', 'analystpermanent', 'informative', 'ranking', 'duca', 'repayment', 'arima', 'sovereignty', 'woodstock', 'anglais', 'summarization', 'explanation', 'initiativesdevelops', 'deploys', 'polices', 'flowswork', 'hierarchical', 'guilt', 'dysfunction', 'circuits', 'shortlisting', 'acne', 'kitchener', 'leadershipjob', 'gam', 'accessexceptional', 'cpm', 'alr', 'logisticsstrong', 'logistical', 'adverse', 'admiral', 'overviewal', 'oiprd', 'timey', 'creep', 'havestrong', 'outcomesresearch', 'financeupdating', 'accomplished', 'edmonton', 'areasstructure', 'careerssupply', 'marginsprior', 'tableauexperience', 'mgmt', 'niveaux', 'reverse', 'steering', 'terminal', 'jump', 'parse', 'rsa', 'earned', 'numpy', 'fieldfive', 'sheetswork', 'lgbtqia', 'colliers', 'officeexpert', 'shiftnight', 'wos', 'looked', 'persevere', 'csia', 'biplease', 'leaves', 'accomplishment', 'faxes', 'rmx', 'closings', 'contractbenefits', 'mindshareworld', 'saigon', 'tagging', 'descriptionfor', 'openstack', 'needsuse', 'movers', 'postmedia', 'processesability', 'infobay', 'skillsproficiency', 'hiv', 'awesomely', 'mf', 'mecanjob', 'dataanalyze', 'extendicare', 'dungeon', 'worksite', 'methologies', 'submissionscoordination', 'lego', 'operationsjob', 'conditioned', 'typing', 'inventoryprepares', 'projectscreate', 'mediacom', 'mindshares', 'architecting', 'unused', 'experiencing', 'examen', 'kincentric', 'companydevelop', 'stroke', 'analystexperienced', 'excellente', 'ssa', 'charg', 'tsc', 'fleetcor', 'formally', 'databasesexperience', 'duites', 'timeconsolidate', 'engineered', 'authentiques', 'meridiancareers', 'muslim', 'perceived', 'horizontally', 'prepaid', 'accuracystrong', 'discovers', 'resortsuite', 'occupiers', 'mitigations', 'emm', 'categorized', 'allocations', 'specificationyou', 'cdm', 'cuter', 'digitalthe', 'quest', 'sparq', 'downloadable', 'courselove', 'pharmaciens', 'setsexperience', 'yorkville', 'gallagher', 'mariadb', 'customise', 'daycare', 'cartage', 'rolled', 'renseignements', 'articulating', 'skillscontract', 'stats', 'ratiosmonitor', 'newest', 'cmf', 'directing', 'vets', 'prioritiesproblem', 'rounded', 'excite', 'tour', 'solutionsprepare', 'environmentsyou', 'acquiring', 'ontarian', 'vqnw', 'incorporates', 'simplest', 'compatible', 'multitaskknowledge', 'unshakable', 'permanently', 'andstrong', 'dropship', 'oralhigh', 'visuals', 'finalized', 'nuclear', 'birth', 'youth', 'automations', 'bpa', 'preformed', 'interdependent', 'databricks', 'atleast', 'frills', 'wilket', 'applique', 'provenance', 'collecte', 'annum', 'voicemail', 'efficace', 'volunteerism', 'nti', 'triumphs', 'solutiontest', 'africa', 'responsibilitiesanalyze', 'ltdjob', 'transsexual', 'leadershipconduct', 'accuracygenerates', 'particulier', 'parkingvision', 'meetingslead', 'weight', 'qlickview', 'mise', 'befits', 'scriptsexperience', 'lucidchart', 'functionalitiesstrong', 'detailsbusiness', 'unsupervised', 'innate', 'conducive', 'dead', 'detective', 'elicits', 'cleanses', 'combinations', 'easyfinancial', 'rolling', 'goldman', 'dentons', 'unrated', 'fournisseursanalyser', 'tlfs', 'glossaries', 'jeans', 'vscode', 'terminals', 'skillsprocess', 'houreducation', 'sia', 'msc', 'interfacesreview', 'rfpio', 'alertdriving', 'scikit', 'pied', 'allowed', 'pivots', 'pega', 'woodbine', 'chef', 'reportscreation', 'exceldetail', 'askswork', 'supportthe', 'similaire', 'subsequently', 'developmentnice', 'autonome', 'greenfield', 'cision', 'logistiques', 'decisionsdevelop', 'embraced', 'geomax', 'blackbelt', 'experis', 'valuationphysically', 'snippets', 'indexes', 'ss', 'diversityinc', 'databaseuse', 'erwin', 'developerposition', 'compares', 'aptitudes', 'abundance', 'amend', 'shining', 'fearlessly', 'tails', 'shells', 'nrd', 'blockchain', 'hospitality', 'embarked', 'dcm', 'biopharmaceutical', 'fieldwe', 'nam', 'offshore', 'unison', 'inspection', 'delegating', 'conjointe', 'dressflexible', 'pricingparticipates', 'euro', 'requiredexcellent', 'plusability', 'broadliner', 'isd', 'prizm', 'supplies', 'yorkvilleu', 'supervisionextremely', 'lansing', 'historian', 'assetproject', 'assante', 'suppliersexcellent', 'countermeasures', 'fearlessness', 'racks', 'courier', 'insurer', 'broadridge', 'lod', 'velocity', 'igc', 'mener', 'moneytm', 'litigants', 'basics', 'remediating', 'latin', 'valeurs', 'deux', 'rfq', 'ago', 'hackathons', 'tightly', 'emballage', 'wave', 'requirementsprovide', 'chart', 'pillars', 'bpw', 'interactivity', 'necessity', 'cube', 'manipulates', 'jazzhr', 'communityjob', 'horse', 'insuring', 'commission', 'lowering', 'merchant', 'exporting', 'plastic', 'micromanaging', 'findur', 'debate', 'mitigated', 'hailed', 'cloudera', 'solutionscommunicating', 'rational', 'impala', 'vsc', 'sl', 'tristar', 'uf', 'dfo', 'requirementsresponsibilities', 'trillions', 'positivity', 'mpawork', 'teamsproject', 'satellite', 'crd', 'ach', 'pizza', 'bilinguisme', 'nonprofit', 'offstore', 'throughs', 'carpenter', 'ion', 'aob', 'sanofi', 'vigilant', 'conventions', 'lifts', 'tendances', 'upfield', 'environmentstrong', 'programcasual', 'potatoes', 'assembly', 'lifting', 'valuationassist', 'economical', 'confirming', 'dismissal', 'environnement', 'revision', 'resistance', 'clientsparticipate', 'insured', 'phipa', 'inventaire', 'offprofit', 'overrunsmanage', 'expectationseliminate', 'drayage', 'developmental', 'prodigygame', 'cyber', 'mixed', 'peaks', 'smile', 'underspending', 'habit', 'onesa', 'keyboarding', 'pla', 'prim', 'hrsharedservices', 'actors', 'annie', 'arising', 'merge', 'dvp', 'ma', 'racial', 'renforcer', 'homeland', 'efficacy', 'ebay', 'homeequitybank', 'tasksexcellent', 'likelihood', 'journalism', 'string', 'eft', 'photoshop', 'replay', 'fieldwork', 'sharp', 'resolves', 'suffer', 'attributesexecuting', 'foresee', 'disruption', 'assuming', 'peanuts', 'drop', 'pms', 'iterating', 'disclose', 'periodicals', 'skillsdemonstrated', 'projectsattention', 'ksas', 'sizmek', 'analysisrespond', 'allocationresponsable', 'bruce', 'absent', 'newsmedia', 'claiming', 'analystshift', 'cpp', 'ambiance', 'ideation', 'policiesworking', 'pushed', 'jointly', 'endorsed', 'evaluations', 'courseware', 'discoverer', 'andcertification', 'weld', 'skillswhat', 'stakeholdersmanaging', 'venterra', 'abilityexperience', 'eagle', 'vaccine', 'suppl', 'thursday', 'loose', 'massenet', 'curate', 'centennialcollege', 'differ', 'necessities', 'upcompetent', 'receptive', 'problemsapply', 'monkey', 'atdd', 'govern', 'usersrequirements', 'mta', 'brockville', 'redefined', 'advances', 'eudcation', 'pricingthe', 'spoke', 'flags', 'manipulated', 'profound', 'apb', 'manufacture', 'analystexperience', 'bn', 'jeopardy', 'offline', 'ecosystemsqualifications', 'teamprofessional', 'extras', 'clarification', 'feminine', 'productsconfigure', 'softwareexperience', 'backfilling', 'mutually', 'environmentability', 'mun', 'infrastructurecontinuously', 'cater', 'caitlyn', 'teach', 'dfast', 'writes', 'aircraft', 'minors', 'debit', 'constitute', 'productscreate', 'rer', 'analytiques', 'layers', 'transformed', 'salsify', 'stephanie', 'eventswork', 'statistique', 'truckmate', 'advocating', 'geh', 'serviced', 'hazards', 'stakeholderssupport', 'linkage', 'inspector', 'suffering', 'subscriptions', 'applicationsimplementation', 'consumable', 'burden', 'height', 'checklist', 'projectsexperienced', 'systemically', 'sobeys', 'complied', 'liens', 'complexe', 'regulator', 'virtualized', 'finalists', 'unify', 'inclement', 'handbook', 'tsshp', 'feesemployee', 'motivates', 'risksproduct', 'template', 'kn', 'tagsschedule', 'sein', 'refines', 'transportationdevelop', 'dell', 'shortage', 'simplifications', 'bannerrequirementsuniversity', 'plenty', 'pile', 'possibilit', 'contribuer', 'sparticiper', 'toujours', 'issuance', 'requestsanalyzing', 'standup', 'adwords', 'madd', 'indicator', 'traits', 'camt', 'classifications', 'requiredinvestigate', 'lynx', 'images', 'strongest', 'orderly', 'appliquer', 'crossover', 'celonis', 'tenure', 'calco', 'scian', 'cbes', 'knowledgelog', 'wheel', 'aa', 'statistiques', 'robustly', 'discounted', 'manageable', 'breakdowns', 'mumbai', 'window', 'repeat', 'furthers', 'enforcing', 'sows', 'illumination', 'gradspermanent', 'excelicare', 'stakeholdersassisting', 'sean', 'scans', 'ontariostatus', 'arranging', 'upcoming', 'proofed', 'bellcanada', 'airline', 'purposeful', 'ibi', 'nuts', 'philanthropic', 'mfa', 'surface', 'contraction', 'incluses', 'wall', 'helped', 'networksplease', 'expedited', 'kafka', 'rama', 'relationshipsreviewal', 'wondering', 'mesure', 'conseiller', 'luxembourg', 'telematics', 'gleaned', 'socializing', 'safetyassist', 'industrycompetitive', 'terminant', 'tribute', 'monthsexpected', 'upparticipate', 'completely', 'rotating', 'attributionjob', 'pragmatism', 'niveaud', 'hubspotcollege', 'conversant', 'sounding', 'libre', 'barriered', 'municipalities', 'paymentprovide', 'alumni', 'lominger', 'powerpointstrong', 'kirk', 'hension', 'broadcaster', 'peace', 'supervis', 'wage', 'guy', 'tasksexperience', 'worldwe', 'packagesability', 'ambassador', 'infuse', 'boring', 'fierce', 'screener', 'filming', 'sourcesbuild', 'managemento', 'anytime', 'enabler', 'ts', 'dorval', 'finch', 'calendrier', 'eastern', 'locaux', 'decisiveness', 'testingcontribute', 'counterparty', 'recognised', 'assignedknowledge', 'solutionsmeeting', 'heterogeneous', 'prohibit', 'tandem', 'assetexceptional', 'oneself', 'millennium', 'bases', 'rep', 'af', 'al', 'muscle', 'packing', 'rmts', 'sharpen', 'highlights', 'decisionmakers', 'homeowners', 'sandbox', 'commonly', 'tracker', 'visioknowledge', 'reductions', 'geomatics', 'timefollow', 'dermalogica', 'thoughts', 'justifications', 'idjango', 'ooad', 'supervising', 'poverty', 'disclosure', 'companycompetitive', 'toolkits', 'counsel', 'workable', 'datacreate', 'fte', 'teamimplementing', 'bradley', 'contingent', 'experiencesbachelor', 'disconnected', 'combo', 'achievements', 'swimlanes', 'resonates', 'tfsas', 'shuttle', 'summarizes', 'rav', 'initiativemust', 'strings', 'securely', 'borrower', 'viewed', 'analystlocation', 'epidemiology', 'acknowledge', 'allowances', 'charged', 'chefs', 'genomic', 'iq', 'reconciles', 'careful', 'names', 'degreecompletion', 'purification', 'mattel', 'bain', 'hsf', 'rpp', 'triaging', 'democratize', 'anniversaries', 'accesses', 'knowledgeyou', 'petline', 'phantomcreate', 'informationhigh', 'frenchadvanced', 'forrester', 'hoursemployee', 'soit', 'seven', 'oneexperience', 'featuring', 'traderev', 'datarobot', 'reinvestment', 'assetknowledge', 'sylvan', 'gfrt', 'declaration', 'installed', 'appraise', 'boarded', 'july', 'automates', 'paperwork', 'customs', 'featured', 'yo', 'commits', 'logiciels', 'rsp', 'comprising', 'guidanceconfident', 'sexually', 'france', 'allocate', 'navigating', 'fatca', 'lands', 'assetif', 'foss', 'possessing', 'charm', 'enquiry', 'cadre', 'chronicx', 'expressing', 'stakeholdersgeneration', 'augmenter', 'personalizing', 'collibra', 'quantitatively', 'sfts', 'controlling', 'precious', 'charles', 'cdisc', 'provstate', 'documentationensure', 'coachknowledge', 'trusts', 'ambit', 'nerdy', 'underwriter', 'deferred', 'organizationmanage', 'rstudio', 'freshco', 'vegas', 'tabbing', 'entrusted', 'solutionsprepares', 'bookmarks', 'entertains', 'fulfills', 'workshopsbridging', 'boldcommerce', 'butant', 'jd', 'glimpse', 'cbihealthgroup', 'syndiqu', 'proxy', 'cva', 'criticality', 'teachers', 'skype', 'shiny', 'objectifs', 'ecom', 'caseload', 'travelling', 'uniqueness', 'ping', 'nx', 'allocating', 'lanes', 'occasionally', 'plumbing', 'begins', 'unrivalled', 'wasted', 'bending', 'mongodb', 'sid', 'fcu', 'repay', 'mannereducation', 'sps', 'vera', 'chocolate', 'workers', 'ye', 'teamcontributing', 'underrepresented', 'mbaadvanced', 'hunters', 'reviewal', 'shutting', 'esheet', 'businessmanage', 'majority', 'cockpit', 'mindshare', 'redefines', 'labour', 'experiencewe', 'exploits', 'round', 'tweak', 'tts', 'analystgeneral', 'postgresql', 'deserving', 'applicationsknowledge', 'complicators', 'symbols', 'innomar', 'absence', 'eco', 'ethnicities', 'perpetual', 'removing', 'bored', 'tick', 'actionedi', 'toys', 'excellentes', 'simplifying', 'entitlements', 'obtains', 'welcomed', 'managementadvanced', 'externes', 'deeks', 'forecastassess', 'revised', 'fhir', 'amerisourcebergen', 'flying', 'humanity', 'managementmake', 'processplease', 'nameinterview', 'dmo', 'wf', 'juggle', 'functionoperationsfeatured', 'assessed', 'kt', 'calm', 'secured', 'pioneering', 'deliverablespresent', 'reimbursementvision', 'quirky', 'agcs', 'bidemonstrates', 'cannibalization', 'abilene', 'deeper', 'harmony', 'complement', 'visas', 'computation', 'produced', 'parents', 'loops', 'moderately', 'grades', 'discoveries', 'organizedexperience', 'plusdegree', 'powerdesigner', 'anticipating', 'mandates', 'rationnelles', 'consolidates', 'dealings', 'blueprinting', 'implementationperform', 'false', 'aupr', 'examples', 'concevoir', 'auction', 'metjob', 'jrp', 'batch', 'platinum', 'trendscheck', 'nbcc', 'wordpress', 'approving', 'scriptingpower', 'accessexperience', 'requirementsuniversity', 'sportsnet', 'ipaas', 'pong', 'callcovid', 'preserved', 'phi', 'omnichannel', 'adds', 'benefitssubsidized', 'pharmaprix', 'david', 'asks', 'nuance', 'rationalize', 'stakeholdersexcellent', 'cohesive', 'overruns', 'sovereign', 'planification', 'cadenced', 'implementationsolid', 'var', 'alation', 'ressemble', 'realty', 'hunter', 'tissue', 'mobis', 'grab', 'disrupting', 'resultant', 'canaccord', 'parks', 'orientedhave', 'ecological', 'fieldsuperior', 'luxury', 'dpsp', 'projectsfamiliar', 'datal', 'maybe', 'bsrx', 'operative', 'atlanta', 'extends', 'thier', 'ccar', 'msrb', 'spare', 'lgc', 'tasksqualificationscompleted', 'fri', 'cbre', 'bud', 'financereview', 'statistician', 'frd', 'tolerate', 'emptively', 'personalization', 'ross', 'qfc', 'pertinentes', 'rated', 'dismemberment', 'hallmark', 'discountssocial', 'veriforce', 'contractcompany', 'preferablysisense', 'pos', 'cix', 'goodsensure', 'uw', 'mindsharecanada', 'admire', 'guests', 'commences', 'cbsa', 'orientatedstrong', 'accidental', 'stacks', 'giveaways', 'degreeknowledge', 'experiencecomprehensive', 'universitaire', 'configured', 'nationalities', 'uniquely', 'consommation', 'cmtothis', 'pressureworks', 'seau', 'improvementrequirements', 'homelessness', 'quelles', 'vaccinate', 'pervade', 'tenacious', 'stationed', 'statuses', 'unclear', 'forecastoverstock', 'tabulation', 'tolls', 'synapse', 'mrfp', 'decisionscreativity', 'miscellaneous', 'highvelocity', 'systemsexceptional', 'scarce', 'bar', 'detailgreat', 'digitalization', 'industrymeda', 'assetperson', 'kar', 'plusworking', 'refined', 'containing', 'analystdapasoft', 'coached', 'fielding', 'yields', 'hero', 'slice', 'isoxml', 'solutioncreate', 'retailing', 'mensuellement', 'emerged', 'reportingextensive', 'ghost', 'prestige', 'engagementyou', 'muslims', 'explorer', 'hydrogen', 'armes', 'synchronize', 'biocomputing', 'monthspart', 'responsibilitiesensure', 'relationshipsexcellent', 'tmmc', 'brds', 'js', 'situational', 'breed', 'iam', 'imbursement', 'comprehensiveness', 'artisans', 'hello', 'npi', 'rexdale', 'exemplify', 'fridayovertimework', 'ownersability', 'bayview', 'quickness', 'installment', 'mercer', 'corrects', 'statistic', 'datorama', 'perils', 'csat', 'fractions', 'subcategory', 'halal', 'preferredoperational', 'margot', 'hague', 'arethe', 'symbole', 'positons', 'inventorying', 'interconnected', 'indicate', 'knows', 'packagecompany', 'shepherds', 'affili', 'matchstore', 'analyticsdemonstrably', 'mt', 'underwriters', 'dysoncanada', 'jewelry', 'sexes', 'satisfying', 'prompt', 'batchers', 'mg', 'extensionstory', 'ondivision', 'intercom', 'supersedes', 'stellar', 'masco', 'mixers', 'offrez', 'tradeoffs', 'experienceprevious', 'chainaccountable', 'entrenched', 'toolssolid', 'analyticsresponsibilities', 'experimentation', 'panels', 'globales', 'requirementsfacilitate', 'learningadditional', 'counsellor', 'guernsey', 'thomson', 'affiliate', 'intermediary', 'filing', 'crowding', 'novice', 'irs', 'ed', 'premium', 'bent', 'tolerance', 'recommendationsenhanced', 'advent', 'principales', 'liveable', 'varies', 'tmw', 'ouvert', 'cascading', 'speck', 'ntexamen', 'breakfast', 'provincially', 'pet', 'megaphone', 'ironed', 'entr', 'testable', 'minimized', 'placesanitizing', 'intranet', 'mccain', 'environmentally', 'disputes', 'packers', 'feedsrequirements', 'combat', 'obstacles', 'sensitives', 'techniquesperform', 'responsibilitiesresponsible', 'valuablestrong', 'volcker', 'immerses', 'managementassist', 'stationinterested', 'universe', 'developmentstructure', 'drm', 'continuit', 'listener', 'wages', 'continuity', 'cdp', 'allocationresponsible', 'anusha', 'accords', 'alsafa', 'theatre', 'enrichment', 'familiarized', 'playbooks', 'allstate', 'walks', 'rb', 'korean', 'confirmation', 'gr', 'titulaire', 'cosmetics', 'heatmap', 'vocational', 'informationprepare', 'rangers', 'centennial', 'southern', 'objectivesability', 'tons', 'majorjob', 'participer', 'allinforequity', 'gls', 'gauge', 'sincerity', 'floating', 'sourcesprovide', 'responsibilitiessystem', 'proceed', 'matchschedule', 'flex', 'diver', 'mapswritten', 'targetsyou', 'hourbenefits', 'fpml', 'policyholders', 'pasteur', 'developmentsprovide', 'simulations', 'diction', 'mediums', 'lsa', 'lifecycleperform', 'pads', 'cute', 'optional', 'solutionsconduct', 'neoc', 'destinations', 'fae', 'deduplication', 'vernacular', 'infographic', 'whiz', 'grateful', 'exclusion', 'perfection', 'iiq', 'cleared', 'woman', 'lso', 'perkopolis', 'requirementsknowledge', 'puppies', 'analysisstrong', 'newassets', 'goodhandsadvice', 'recalls', 'performant', 'agir', 'visitor', 'opis', 'submittalsbuilding', 'anova', 'foremost', 'fed', 'routinely', 'described', 'recurrent', 'accomplishing', 'readable', 'wednesday'}\n"
     ]
    }
   ],
   "source": [
    "print(cv.stop_words_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Count Vectorizer for Bigrams</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2 = CountVectorizer(analyzer='word', n_gram=(2,2))\n",
    "count_vector2 = cv2.fit_transform(df_data['jobdescription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts2 = pd.DataFrame(count_vector2.toarray(), columns = cv2.get_feature_names())\n",
    "counts2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Count Vectorizer with Stemming Function</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the source code, \"if analyzer is used, only the decoder argument is used, as the analyzer is intended to replace the preprocessor, tokenizer, and ngrams steps.\"\n",
    "\n",
    "Here, we will use a custom function for the analyzer parameter instead of using 'word'. This results in the token_pattern parameter to be ignored (as per the documentation). This is also true for stop_words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build custom stemmer to use with CountVectorizer\n",
    "# Used stack overflow post as guide\n",
    "# https://stackoverflow.com/questions/36182502/add-stemming-support-to-countvectorizer-sklearn\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "#analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "class CountVectorizerStemmed(CountVectorizer):\n",
    "    def custom_analyzer(self):\n",
    "        analyzer = super(CountVectorizerStemmed, self).build_analyzer()\n",
    "        return lambda text: ([stemmer.stem(w) for w in analyzer(text)])\n",
    "\n",
    "cv_stem = CountVectorizerStemmed(stop_words = 'english', \n",
    "                                 lowercase = True, \n",
    "                                 min_df=2,\n",
    "                                token_pattern = r\"[a-zA-Z]+\")\n",
    "vector_stem = cv_stem.fit_transform(df_data['jobdescription'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including token_pattern parameter here did result in the removal of numbers from features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 6285)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_stem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ab', 'abide', 'abilities', 'ability', 'abinbev', 'able', 'aboriginal', 'aboriginals', 'abreast', 'abroad', 'abstract', 'abuse', 'academic', 'accelerate', 'accelerated', 'accelerating', 'acceleration', 'accelerator', 'accent', 'accept']\n"
     ]
    }
   ],
   "source": [
    "print(cv_stem.get_feature_names()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>abide</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>abinbev</th>\n",
       "      <th>able</th>\n",
       "      <th>aboriginal</th>\n",
       "      <th>aboriginals</th>\n",
       "      <th>abreast</th>\n",
       "      <th>abroad</th>\n",
       "      <th>...</th>\n",
       "      <th>yoga</th>\n",
       "      <th>yonge</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>yrs</th>\n",
       "      <th>zendesk</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ab  abide  abilities  ability  abinbev  able  aboriginal  aboriginals  \\\n",
       "0   0      0          0        8        0     0           0            0   \n",
       "1   0      0          1        2        0     1           0            0   \n",
       "2   0      0          0        0        0     0           0            0   \n",
       "3   0      0          0        1        0     0           0            0   \n",
       "4   0      0          0        2        0     1           0            0   \n",
       "\n",
       "   abreast  abroad  ...  yoga  yonge  york  young  yrs  zendesk  zero  zone  \\\n",
       "0        0       0  ...     0      0     0      0    0        0     0     0   \n",
       "1        0       0  ...     0      0     0      0    0        0     0     0   \n",
       "2        0       0  ...     0      0     0      0    0        0     0     0   \n",
       "3        0       0  ...     0      0     0      0    0        0     0     0   \n",
       "4        0       0  ...     0      0     0      0    0        0     0     0   \n",
       "\n",
       "   zones  zoom  \n",
       "0      0     0  \n",
       "1      0     0  \n",
       "2      0     0  \n",
       "3      0     0  \n",
       "4      0     0  \n",
       "\n",
       "[5 rows x 6285 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_stem = pd.DataFrame(vector_stem.toarray(), columns = cv_stem.get_feature_names())\n",
    "counts_stem.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that this did not result in the stemming of any of the tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "token_pattern = re.search(r\"[a-zA-Z]+\")    \n",
    "\n",
    "# list of punctuation\n",
    "punc = string.punctuation    \n",
    "\n",
    "#try combining stopwords and punctuation together\n",
    "user_defined_stop_words = ['st','rd','hong','kong']     \n",
    "i = nltk.corpus.stopwords.words('english')\n",
    "j = list(string.punctuation) + user_defined_stop_words\n",
    "\n",
    "stopwords = set(i).union(j)\n",
    "\n",
    "# or try this\n",
    "stop_words=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '00am', '00pm', '01', '012', '0159', '01job', '02', '03', '04', '05', '055', '06', '078', '08', '082', '083', '09', '10']\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "# Try using a function\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "cv_stem2 = CountVectorizer(analyzer=stemmed_words, \n",
    "                           stop_words = 'english', \n",
    "                           lowercase = True, \n",
    "                           min_df=2,\n",
    "                           token_pattern = r\"[a-zA-Z]+\")\n",
    "count_vector2 = cv_stem2.fit_transform(df_data['jobdescription'])\n",
    "\n",
    "print(cv_stem2.get_feature_names()[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above is noticeably slow due to the lambda function.\n",
    "Including token_pattern parameter here did not result in only word features (numbers are still there)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00am</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>012</th>\n",
       "      <th>0159</th>\n",
       "      <th>01job</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>...</th>\n",
       "      <th>étanchéité</th>\n",
       "      <th>étape</th>\n",
       "      <th>étendu</th>\n",
       "      <th>étranger</th>\n",
       "      <th>été</th>\n",
       "      <th>éventail</th>\n",
       "      <th>évolut</th>\n",
       "      <th>ête</th>\n",
       "      <th>être</th>\n",
       "      <th>œuvr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4494 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  00am  00pm  01  012  0159  01job  02  03  ...  étanchéité  étape  \\\n",
       "0   0    1     0     0   0    0     0      0   0   0  ...           0      0   \n",
       "1   0    0     0     0   0    0     0      0   0   0  ...           0      0   \n",
       "2   0    0     0     0   0    0     0      0   0   0  ...           0      0   \n",
       "3   0    0     0     0   0    0     0      0   0   0  ...           0      0   \n",
       "4   0    0     0     0   0    0     0      0   0   0  ...           0      0   \n",
       "\n",
       "   étendu  étranger  été  éventail  évolut  ête  être  œuvr  \n",
       "0       0         0    0         0       0    0     0     0  \n",
       "1       0         0    0         0       0    0     0     0  \n",
       "2       0         0    0         0       0    0     0     0  \n",
       "3       0         0    0         0       0    0     0     0  \n",
       "4       0         0    0         0       0    0     0     0  \n",
       "\n",
       "[5 rows x 4494 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_stem2 = pd.DataFrame(count_vector2.toarray(), columns = cv_stem2.get_feature_names())\n",
    "counts_stem2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>TFIDF Vectorizer</h2>\n",
    "\n",
    "TFIDF converts the job description text into a matrix of TF-IDF features. The TF-IDF Vectorizer function from the sklearn.feature_extraction module performs multiple steps including tokenization, stopword removal, and lower casing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>1. Text Normalization: Stemming Words</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-56c02fe6530c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mporter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jobdescription'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jobdescription'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "porter = PorterStemmer()\n",
    "df_data['jobdescription'][7] = df_data['jobdescription'][7].apply(porter.stem())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'canadian orthodontic partners has an exciting new opportunity, looking for a talented new analyst to join our standards team! reporting to the national manager of cop standards, the business analyst will gather and interpret data to develop actionable steps to improve processes, optimizing operational performance and acquisition due diligence and transitions.what we offer: competitive annual salary + quarterly bonuscomprehensive benefits package including : medical, dental, vision, and orthodontic coverage for employees and their families.paid vacation time.educational reimbursement program.real career growth opportunities.key responsibilities: lead the collection of acquisition due diligence data.collect all required initial dd information from selling doctor based on standard question listensure information is complete and prepared for decisions making by the team, highlighting risks or issues to expedite the decision making.complete a first pass of the dd analysis.as the project coordinator, coordinate all dd tasks to make sure they are completed on timefollow up with responsible parties in a timely mannerensure standard process is followedproject coordinator for dd and transition. coordinate all dd tasks to ensure appropriate planning delivers dd and transition outcomes on time and with visibility to risks.follow up with all responsible parties in a timey manner to ensure tasks are completed or visibility to missing the deliverables is achieved.produce consistent, regular performance reports for dd and transition performance.lead a consistent approach that allows others to know what to expect.maintain and manage scorecards and decision support tools for clinic network operations.regularly (monthly or quarterly) pull data from our practice management systems to produce performance scorecards, planning workbooks and decision tools.analyze the data to support efficient decision making and action planning.present completed tools and findings and recommended steps take to the operational leadership or executive team.maintain tracking sheets, workbooks and tools (google sheet/ excel) that leaders use daily for data analysis, project performance, audit results etc.requirements: minimum 2 years working as a standards analyst or in a similar field/capacity.excellent communication skills both verbal and written.ability to build and maintain strong working relationships with internal and external teams.strong organizational skills, with the ability to manage multiple projects at once .proficient in ms excel or google sheets, word, visio, power point, and able to learn new technologies quickly.very detail oriented.ability to manipulate and analyze datafamiliarity with project management methodology or project coordination work.job types: full-time, permanentbenefits:dental caredisability insuranceemployee assistance programextended health carelife insurancepaid time offtuition reimbursementvision carework from homeschedule:8 hour shiftmonday to fridayexperience:business analyst: 2 years (preferred)work remotely:temporarily due to covid-19covid-19 precaution(s):remote interview processpersonal protective equipment provided or requiredplastic shield at work stationssocial distancing guidelines in placevirtual meetingssanitizing, disinfecting, or cleaning procedures in plac'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['jobdescription'][7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2. Initialize Stopword Removal & Lowercasing</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TFIDF Vectorizer\n",
    "tvec = TfidfVectorizer(analyzer = 'word', token_pattern = r\"[a-zA-Z]+\", stop_words = 'english', lowercase= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3. Apply TF-IDF</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns matrix of tf-idf features\n",
    "tvec_token = tvec.fit_transform(df_data['jobdescription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '000026rp',\n",
       " '000ft',\n",
       " '000m3',\n",
       " '0090',\n",
       " '00am',\n",
       " '00pm',\n",
       " '01',\n",
       " '012',\n",
       " '013job',\n",
       " '0159',\n",
       " '01expected',\n",
       " '01job',\n",
       " '02',\n",
       " '0272',\n",
       " '02job',\n",
       " '03',\n",
       " '03job',\n",
       " '04',\n",
       " '04job',\n",
       " '05',\n",
       " '055',\n",
       " '0553',\n",
       " '05job',\n",
       " '06',\n",
       " '0661',\n",
       " '078',\n",
       " '08',\n",
       " '0815',\n",
       " '082',\n",
       " '083',\n",
       " '08expected',\n",
       " '09',\n",
       " '0g7',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '100ft',\n",
       " '100mm',\n",
       " '100s',\n",
       " '10112323contract',\n",
       " '104',\n",
       " '1045',\n",
       " '1075',\n",
       " '1090',\n",
       " '10b',\n",
       " '10mb',\n",
       " '11',\n",
       " '110',\n",
       " '112',\n",
       " '113886',\n",
       " '114',\n",
       " '1145',\n",
       " '115',\n",
       " '116',\n",
       " '11685job',\n",
       " '119',\n",
       " '12',\n",
       " '120',\n",
       " '1200',\n",
       " '1236',\n",
       " '126',\n",
       " '128',\n",
       " '12th',\n",
       " '13',\n",
       " '130',\n",
       " '1300',\n",
       " '13021',\n",
       " '137',\n",
       " '13th',\n",
       " '14',\n",
       " '14001',\n",
       " '144',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '153',\n",
       " '154',\n",
       " '155',\n",
       " '15611job',\n",
       " '1563',\n",
       " '15724',\n",
       " '15725contract',\n",
       " '15775contract',\n",
       " '15job',\n",
       " '16',\n",
       " '160367',\n",
       " '161182',\n",
       " '161615',\n",
       " '1654',\n",
       " '16607',\n",
       " '16764',\n",
       " '16job',\n",
       " '17',\n",
       " '170',\n",
       " '172',\n",
       " '173',\n",
       " '176',\n",
       " '178',\n",
       " '18',\n",
       " '180',\n",
       " '1830s',\n",
       " '1846',\n",
       " '1871',\n",
       " '1881',\n",
       " '189',\n",
       " '19',\n",
       " '1914',\n",
       " '1918',\n",
       " '194',\n",
       " '1950',\n",
       " '1953',\n",
       " '1954',\n",
       " '1960',\n",
       " '1970',\n",
       " '1974',\n",
       " '1978',\n",
       " '1985',\n",
       " '1986',\n",
       " '1994',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '19covid',\n",
       " '19education',\n",
       " '19expected',\n",
       " '1a',\n",
       " '1publish',\n",
       " '1st',\n",
       " '1w5',\n",
       " '1x',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2001',\n",
       " '20022',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2008',\n",
       " '2011',\n",
       " '2012',\n",
       " '2014',\n",
       " '2015',\n",
       " '2016',\n",
       " '2017',\n",
       " '2018',\n",
       " '2019',\n",
       " '2020',\n",
       " '2021',\n",
       " '2021we',\n",
       " '2022',\n",
       " '2035',\n",
       " '205',\n",
       " '207',\n",
       " '20th',\n",
       " '21',\n",
       " '210068',\n",
       " '210085',\n",
       " '2105902884w',\n",
       " '2105903113w',\n",
       " '2105904277w',\n",
       " '210781',\n",
       " '213043',\n",
       " '213703',\n",
       " '213872',\n",
       " '214444',\n",
       " '214708',\n",
       " '217514',\n",
       " '21st',\n",
       " '22',\n",
       " '23',\n",
       " '231',\n",
       " '234',\n",
       " '238',\n",
       " '239',\n",
       " '23job',\n",
       " '24',\n",
       " '243',\n",
       " '24job',\n",
       " '25',\n",
       " '250',\n",
       " '26',\n",
       " '268',\n",
       " '270',\n",
       " '2700',\n",
       " '275',\n",
       " '276151',\n",
       " '277191',\n",
       " '277656',\n",
       " '277772',\n",
       " '28',\n",
       " '28941',\n",
       " '28b',\n",
       " '2h7job',\n",
       " '2m',\n",
       " '2v9',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '303',\n",
       " '308',\n",
       " '30am',\n",
       " '30pm',\n",
       " '31',\n",
       " '31st',\n",
       " '32',\n",
       " '320',\n",
       " '326556',\n",
       " '33',\n",
       " '330056',\n",
       " '332217',\n",
       " '333',\n",
       " '34401',\n",
       " '35',\n",
       " '350',\n",
       " '36',\n",
       " '364',\n",
       " '365',\n",
       " '37',\n",
       " '38',\n",
       " '381',\n",
       " '3c4',\n",
       " '3e',\n",
       " '3mf',\n",
       " '3pl',\n",
       " '3rd',\n",
       " '40',\n",
       " '400',\n",
       " '4000',\n",
       " '401',\n",
       " '401k',\n",
       " '409',\n",
       " '41',\n",
       " '41442',\n",
       " '416',\n",
       " '42',\n",
       " '4331',\n",
       " '438',\n",
       " '44',\n",
       " '4429',\n",
       " '45',\n",
       " '450',\n",
       " '450h',\n",
       " '466',\n",
       " '467',\n",
       " '47',\n",
       " '4747',\n",
       " '476',\n",
       " '4778',\n",
       " '49',\n",
       " '490',\n",
       " '4hana',\n",
       " '4p8',\n",
       " '4th',\n",
       " '4w8',\n",
       " '50',\n",
       " '500',\n",
       " '50mm',\n",
       " '52',\n",
       " '520',\n",
       " '5255',\n",
       " '5300',\n",
       " '5330',\n",
       " '55',\n",
       " '550',\n",
       " '55000',\n",
       " '554',\n",
       " '5559',\n",
       " '56',\n",
       " '5700',\n",
       " '58',\n",
       " '5837',\n",
       " '59',\n",
       " '590',\n",
       " '59pm',\n",
       " '5b',\n",
       " '5l7',\n",
       " '5reimbursement',\n",
       " '60',\n",
       " '600',\n",
       " '61',\n",
       " '62',\n",
       " '622',\n",
       " '63',\n",
       " '634',\n",
       " '65',\n",
       " '650',\n",
       " '66',\n",
       " '661',\n",
       " '67',\n",
       " '68',\n",
       " '69',\n",
       " '6ft',\n",
       " '6th',\n",
       " '70',\n",
       " '700',\n",
       " '7120',\n",
       " '730',\n",
       " '7304',\n",
       " '75',\n",
       " '750',\n",
       " '76',\n",
       " '7695',\n",
       " '77',\n",
       " '7710',\n",
       " '777',\n",
       " '78',\n",
       " '79',\n",
       " '7th',\n",
       " '80',\n",
       " '800',\n",
       " '8002',\n",
       " '80190525',\n",
       " '805',\n",
       " '81',\n",
       " '82',\n",
       " '85',\n",
       " '86',\n",
       " '866',\n",
       " '867',\n",
       " '87',\n",
       " '871966',\n",
       " '872',\n",
       " '872687',\n",
       " '888',\n",
       " '89',\n",
       " '8th',\n",
       " '90',\n",
       " '900',\n",
       " '905',\n",
       " '92145',\n",
       " '94',\n",
       " '943',\n",
       " '945',\n",
       " '9501',\n",
       " '952',\n",
       " '958',\n",
       " '96',\n",
       " '96272',\n",
       " '96898',\n",
       " '96905',\n",
       " '97',\n",
       " '97205',\n",
       " '97584',\n",
       " '97603',\n",
       " '97604',\n",
       " '97894',\n",
       " '979',\n",
       " '98',\n",
       " '99',\n",
       " '9bn',\n",
       " '________________________________________________________________________postmedia',\n",
       " '_requisition',\n",
       " 'aa',\n",
       " 'ab',\n",
       " 'abide',\n",
       " 'abilene',\n",
       " 'abilities',\n",
       " 'abilitiesexcellent',\n",
       " 'ability',\n",
       " 'abilityexperience',\n",
       " 'abinbev',\n",
       " 'able',\n",
       " 'abnormal',\n",
       " 'aboriginal',\n",
       " 'aboriginals',\n",
       " 'abreast',\n",
       " 'abroad',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'abstract',\n",
       " 'abundance',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'academic',\n",
       " 'accelerant',\n",
       " 'accelerate',\n",
       " 'accelerated',\n",
       " 'accelerating',\n",
       " 'acceleration',\n",
       " 'accelerator',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accesses',\n",
       " 'accessexceptional',\n",
       " 'accessexperience',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accessiblecareers',\n",
       " 'accessing',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accolades',\n",
       " 'accommodate',\n",
       " 'accommodating',\n",
       " 'accommodation',\n",
       " 'accommodations',\n",
       " 'accommodement',\n",
       " 'accommodements',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'accomplishing',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accordance',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accords',\n",
       " 'account',\n",
       " 'accountabilities',\n",
       " 'accountabilitieswork',\n",
       " 'accountability',\n",
       " 'accountable',\n",
       " 'accountant',\n",
       " 'accounting',\n",
       " 'accounts',\n",
       " 'accreditations',\n",
       " 'accredited',\n",
       " 'accruals',\n",
       " 'accruent',\n",
       " 'accumulation',\n",
       " 'accuracy',\n",
       " 'accuracya',\n",
       " 'accuracyanalyze',\n",
       " 'accuracydevelop',\n",
       " 'accuracydrive',\n",
       " 'accuracygenerates',\n",
       " 'accuracystrong',\n",
       " 'accuracywe',\n",
       " 'accurate',\n",
       " 'accurateaudit',\n",
       " 'accurately',\n",
       " 'accès',\n",
       " 'ach',\n",
       " 'achat',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achievers',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'acii',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledgement',\n",
       " 'acknowledges',\n",
       " 'acl',\n",
       " 'acl123',\n",
       " 'acne',\n",
       " 'acquerrez',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquiring',\n",
       " 'acquisition',\n",
       " 'acquisitions',\n",
       " 'acquérir',\n",
       " 'acritas',\n",
       " 'acss',\n",
       " 'act',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actionable',\n",
       " 'actioned',\n",
       " 'actionedi',\n",
       " 'actionprovides',\n",
       " 'actions',\n",
       " 'activate',\n",
       " 'activation',\n",
       " 'activations',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activities',\n",
       " 'activitiesportfolio',\n",
       " 'activity',\n",
       " 'activityupdate',\n",
       " 'activités',\n",
       " 'activitésparticiper',\n",
       " 'actors',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actualizing',\n",
       " 'actuals',\n",
       " 'actuarial',\n",
       " 'actuelle',\n",
       " 'acumen',\n",
       " 'acumenapplication',\n",
       " 'acute',\n",
       " 'ad',\n",
       " 'ad1',\n",
       " 'adam',\n",
       " 'adapt',\n",
       " 'adaptability',\n",
       " 'adaptable',\n",
       " 'adaptation',\n",
       " 'adapting',\n",
       " 'adapts',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addendum',\n",
       " 'addiction',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additions',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'adept',\n",
       " 'adequacy',\n",
       " 'adequate',\n",
       " 'adesa',\n",
       " 'adf',\n",
       " 'adhere',\n",
       " 'adhered',\n",
       " 'adherence',\n",
       " 'adheres',\n",
       " 'adhering',\n",
       " 'adhesives',\n",
       " 'adhoc',\n",
       " 'adhésifs',\n",
       " 'adjacent',\n",
       " 'adjust',\n",
       " 'adjusted',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'admin',\n",
       " 'administer',\n",
       " 'administered',\n",
       " 'administering',\n",
       " 'administers',\n",
       " 'administration',\n",
       " 'administrative',\n",
       " 'administrator',\n",
       " 'administrators',\n",
       " 'admiral',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admission',\n",
       " 'adobe',\n",
       " 'adopt',\n",
       " 'adopter',\n",
       " 'adopting',\n",
       " 'adoption',\n",
       " 'adp',\n",
       " 'adresse',\n",
       " 'ads',\n",
       " 'adsp',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancement',\n",
       " 'advances',\n",
       " 'advancing',\n",
       " 'advantag',\n",
       " 'advantage',\n",
       " 'advantaged',\n",
       " 'advantagedatabase',\n",
       " 'advantageous',\n",
       " 'advantages',\n",
       " 'advent',\n",
       " 'adverse',\n",
       " 'advert',\n",
       " 'advertiser',\n",
       " 'advertisers',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'advising',\n",
       " 'advisor',\n",
       " 'advisors',\n",
       " 'advisory',\n",
       " 'advocate',\n",
       " 'advocates',\n",
       " 'advocating',\n",
       " 'adwords',\n",
       " 'ae',\n",
       " 'aecon',\n",
       " 'aeconone',\n",
       " 'aerospace',\n",
       " 'aerotek',\n",
       " 'af1',\n",
       " 'affaire',\n",
       " 'affaires',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affects',\n",
       " 'affiliate',\n",
       " 'affiliated',\n",
       " 'affiliates',\n",
       " 'affiliation',\n",
       " 'affiliés',\n",
       " 'affirmative',\n",
       " 'affordable',\n",
       " 'afin',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'aft',\n",
       " 'agcs',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agencies',\n",
       " 'agency',\n",
       " 'agencyconduct',\n",
       " 'agenda',\n",
       " 'agendas',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'aggqc',\n",
       " 'aggregate',\n",
       " 'aggregated',\n",
       " 'aggregates',\n",
       " 'aggregation',\n",
       " 'agile',\n",
       " 'agility',\n",
       " 'agir',\n",
       " 'agissant',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'agreements',\n",
       " 'agricultural',\n",
       " 'agriculture',\n",
       " 'agréé',\n",
       " 'ahead',\n",
       " 'ai',\n",
       " 'aic',\n",
       " 'aid',\n",
       " 'aider',\n",
       " 'aiderons',\n",
       " 'aidez',\n",
       " 'aiding',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aimez',\n",
       " 'ainsi',\n",
       " 'air',\n",
       " 'airb',\n",
       " 'aircraft',\n",
       " 'aires',\n",
       " 'airline',\n",
       " 'airports',\n",
       " 'ais',\n",
       " 'ajax',\n",
       " 'ajgb4doo5f',\n",
       " 'ajout',\n",
       " 'al',\n",
       " 'alation',\n",
       " 'alberta',\n",
       " 'alc',\n",
       " 'alchemer',\n",
       " 'alectra',\n",
       " 'alert',\n",
       " 'alertdriving',\n",
       " 'alerts',\n",
       " 'algorithm',\n",
       " 'algorithmes',\n",
       " 'algorithms',\n",
       " 'align',\n",
       " 'aligned',\n",
       " 'aligning',\n",
       " 'alignment',\n",
       " 'aligns',\n",
       " 'alike',\n",
       " 'alimentaire',\n",
       " 'alimentaires',\n",
       " 'aliments',\n",
       " 'alithya',\n",
       " 'allcantrust',\n",
       " 'allegations',\n",
       " 'allegis',\n",
       " 'allianz',\n",
       " 'allinforequity',\n",
       " 'allocate',\n",
       " 'allocated',\n",
       " 'allocating',\n",
       " 'allocation',\n",
       " 'allocationresponsable',\n",
       " 'allocationresponsible',\n",
       " 'allocations',\n",
       " 'allow',\n",
       " 'allowance',\n",
       " 'allowances',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'allstate',\n",
       " 'alm',\n",
       " 'alocation',\n",
       " 'alongside',\n",
       " 'alr',\n",
       " 'alsafa',\n",
       " 'alternate',\n",
       " 'alternative',\n",
       " 'alternatives',\n",
       " 'alteryx',\n",
       " 'alumni',\n",
       " 'alzheimer',\n",
       " 'amazing',\n",
       " 'amazon',\n",
       " 'ambassador',\n",
       " 'ambiance',\n",
       " 'ambiguities',\n",
       " 'ambiguity',\n",
       " 'ambiguous',\n",
       " 'ambit',\n",
       " 'ambition',\n",
       " 'ambitions',\n",
       " 'ambitious',\n",
       " 'amend',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americas',\n",
       " 'amerisourcebergen',\n",
       " 'amidst',\n",
       " 'aml',\n",
       " 'amounts',\n",
       " 'amplitude',\n",
       " 'amsterdam',\n",
       " 'amélioration',\n",
       " 'améliorer',\n",
       " 'amérique',\n",
       " 'analyse',\n",
       " 'analyser',\n",
       " 'analyses',\n",
       " 'analysi',\n",
       " 'analysing',\n",
       " 'analysis',\n",
       " 'analysis1',\n",
       " 'analysisability',\n",
       " 'analysisapplication',\n",
       " 'analysisexamine',\n",
       " 'analysisexperience',\n",
       " 'analysisextensive',\n",
       " 'analysisit',\n",
       " 'analysisknowledge',\n",
       " 'analysisnice',\n",
       " 'analysisrespond',\n",
       " 'analysisresponsible',\n",
       " 'analysisrun',\n",
       " 'analysisstrong',\n",
       " 'analysisvery',\n",
       " 'analyst',\n",
       " 'analystdapasoft',\n",
       " 'analystduration',\n",
       " 'analyste',\n",
       " 'analystexperience',\n",
       " 'analystexperienced',\n",
       " 'analystgeneral',\n",
       " 'analystlocation',\n",
       " 'analystmicrostrategy',\n",
       " 'analystpermanent',\n",
       " 'analystposition',\n",
       " 'analysts',\n",
       " 'analystshift',\n",
       " 'analyststructure',\n",
       " 'analysttoronto',\n",
       " 'analystwfh',\n",
       " 'analytic',\n",
       " 'analytical',\n",
       " 'analytically',\n",
       " 'analytics',\n",
       " 'analyticsadvance',\n",
       " 'analyticsdemonstrably',\n",
       " 'analyticsresponsibilities',\n",
       " 'analyticssubmitting',\n",
       " 'analytique',\n",
       " 'analytiques',\n",
       " 'analyze',\n",
       " 'analyzed',\n",
       " 'analyzes',\n",
       " 'analyzing',\n",
       " 'ancestries',\n",
       " 'ancestry',\n",
       " 'anchored',\n",
       " 'anchors',\n",
       " 'andbuild',\n",
       " 'andcertification',\n",
       " 'anddata',\n",
       " 'andknowledge',\n",
       " 'andrecruitment',\n",
       " 'android',\n",
       " 'andstrong',\n",
       " 'andstudy',\n",
       " 'andsynthetic',\n",
       " 'anecdotal',\n",
       " 'angel',\n",
       " 'angeles',\n",
       " 'anglais',\n",
       " 'angular',\n",
       " 'angus',\n",
       " 'anheuser',\n",
       " 'animés',\n",
       " 'annie',\n",
       " 'anniversaries',\n",
       " 'anniversary',\n",
       " 'annotations',\n",
       " 'annual',\n",
       " 'annually',\n",
       " 'annuels',\n",
       " 'annum',\n",
       " 'année',\n",
       " 'anomalies',\n",
       " 'anova',\n",
       " 'ans',\n",
       " 'answer',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'anti',\n",
       " 'anticipate',\n",
       " 'anticipated',\n",
       " 'anticipates',\n",
       " 'anticipating',\n",
       " 'anticipation',\n",
       " 'anusha',\n",
       " 'anytime',\n",
       " 'aob',\n",
       " 'aoda',\n",
       " 'aon',\n",
       " 'apac',\n",
       " 'apache',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apartmentratings',\n",
       " 'apb',\n",
       " 'aperçu',\n",
       " 'apex',\n",
       " 'api',\n",
       " 'apis',\n",
       " 'app',\n",
       " 'apparatus',\n",
       " 'appareils',\n",
       " 'apparel',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'appear',\n",
       " 'appetite',\n",
       " 'applauded',\n",
       " 'appliances',\n",
       " 'applicability',\n",
       " 'applicable',\n",
       " 'applicant',\n",
       " 'applicants',\n",
       " 'application',\n",
       " 'applications',\n",
       " 'applicationsimplementation',\n",
       " 'applicationsknowledge',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'applique',\n",
       " 'appliquer',\n",
       " 'appliquées',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appointment',\n",
       " 'appraisal',\n",
       " 'appraisals',\n",
       " 'appraise',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciation',\n",
       " 'apprenons',\n",
       " 'apprentissage',\n",
       " 'apprise',\n",
       " 'approach',\n",
       " 'approachable',\n",
       " 'approaches',\n",
       " 'approachesin',\n",
       " 'approachidentification',\n",
       " 'approaching',\n",
       " 'approfondis',\n",
       " 'appropriate',\n",
       " 'appropriateensure',\n",
       " 'appropriately',\n",
       " 'approval',\n",
       " 'approvaldiscover',\n",
       " 'approvals',\n",
       " 'approve',\n",
       " 'approved',\n",
       " 'approving',\n",
       " 'approvisionnement',\n",
       " 'approvisionnementcapacité',\n",
       " 'approx',\n",
       " 'approximately',\n",
       " 'apps',\n",
       " 'apptio',\n",
       " 'april',\n",
       " 'aptitude',\n",
       " 'aptitudeivr',\n",
       " 'aptitudes',\n",
       " 'ar',\n",
       " 'aramark',\n",
       " 'arcgis',\n",
       " 'architect',\n",
       " 'architectes',\n",
       " 'architecting',\n",
       " 'architects',\n",
       " 'architectural',\n",
       " 'architecture',\n",
       " 'architectures',\n",
       " 'archives',\n",
       " 'archiving',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'areasdemonstrate',\n",
       " 'areasstructure',\n",
       " 'aren',\n",
       " 'arethe',\n",
       " 'argent',\n",
       " 'argentmc',\n",
       " 'arguments',\n",
       " 'arima',\n",
       " 'arise',\n",
       " 'arising',\n",
       " 'arm',\n",
       " 'armes',\n",
       " 'armk',\n",
       " 'arrange',\n",
       " 'arrangement',\n",
       " 'arrangements',\n",
       " 'arranging',\n",
       " 'array',\n",
       " 'arrival',\n",
       " 'arrivals',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrivée',\n",
       " 'arrivées',\n",
       " 'art',\n",
       " 'artefacts',\n",
       " 'articles',\n",
       " 'articulate',\n",
       " 'articulating',\n",
       " 'articulation',\n",
       " 'artifacts',\n",
       " 'artifactsauthor',\n",
       " 'artificial',\n",
       " 'artisans',\n",
       " 'artist',\n",
       " 'artistic',\n",
       " 'artists',\n",
       " 'arts',\n",
       " 'as400',\n",
       " 'asap',\n",
       " 'asapfor',\n",
       " 'asapour',\n",
       " 'asexual',\n",
       " 'asia',\n",
       " 'aside',\n",
       " 'asie',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'askkeep',\n",
       " 'asks',\n",
       " 'askswork',\n",
       " 'asktalentacquisition',\n",
       " 'asl',\n",
       " 'asp',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'asphalt',\n",
       " 'aspirations',\n",
       " 'aspires',\n",
       " 'assante',\n",
       " 'assemble',\n",
       " 'assembles',\n",
       " 'assembly',\n",
       " 'assess',\n",
       " 'assessed',\n",
       " 'assesses',\n",
       " 'assessible',\n",
       " 'assessing',\n",
       " 'assessment',\n",
       " 'assessments',\n",
       " 'asset',\n",
       " 'asset3',\n",
       " 'assetapplication',\n",
       " 'assetbackground',\n",
       " 'assetc',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 10256)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tvec_token.shape without token_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               tfidf\n",
      "data        1.008909\n",
      "experience  1.064095\n",
      "work        1.097752\n",
      "business    1.105114\n",
      "skills      1.115015\n",
      "team        1.137658\n",
      "management  1.242170\n",
      "analysis    1.259265\n",
      "years       1.259265\n",
      "analyst     1.327642\n"
     ]
    }
   ],
   "source": [
    "# Observe TFIDF Weights\n",
    "\n",
    "tfidf = dict(zip(tvec.get_feature_names(), tvec.idf_))\n",
    "tfidf = pd.DataFrame.from_dict(weights, orient='index')\n",
    "tfidf.columns = ['tfidf']\n",
    "\n",
    "# Lowest TFIDF Scores\n",
    "low_tfidf = tfidf.sort_values(by=['tfidf'], ascending=True).head(10)\n",
    "print(low_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       tfidf\n",
      "managementassist     6.41832\n",
      "dell                 6.41832\n",
      "deletion             6.41832\n",
      "impeccably           6.41832\n",
      "delicious            6.41832\n",
      "softwarework         6.41832\n",
      "softwarestrong       6.41832\n",
      "deliverablescreate   6.41832\n",
      "deliverablespresent  6.41832\n",
      "softwares            6.41832\n"
     ]
    }
   ],
   "source": [
    "# Highest TFIDF Scores\n",
    "high_tfidf = tfidf.sort_values(by=['tfidf'], ascending=False).head(10)\n",
    "print(high_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results, using TF-IDF to look for important features relevent to data analyst jobs is not very effective for unigrams.\n",
    "\n",
    "There are also features that do not have a proper space between two words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Text Pre-processing Pipeline Function</h3>\n",
    "\n",
    "See DSDJ Feature Engineering pt 2 for a train & test version of the Tfidf vectorizer function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that cleans and performs a TFIDF transformation to text data\n",
    "tfidf = TfidfVectorizer(stop_words='english', lowercase=True)\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def tfidf_pipeline(txt):\n",
    "    txt = txt.apply(porter.stem) # Apply Stemming\n",
    "    x = tfidf.fit_transform(txt) # Apply Vectorizer, Stopword Removal, & Lowercasing\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtext_TFIDF = tfidf_pipeline(jobText['Job Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = jobText.shape\n",
    "preprocessed = jobtext_TFIDF.shape\n",
    "\n",
    "print(\"Original raw data df shape: \" + str(original))\n",
    "print(\"Preprocessed data shape: \" + str(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobText_TFIDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word frequency : how many words per post.\n",
    "# Text cleaning : lower casing, extra white-space removal, lemmatization\n",
    "\n",
    "# Determine most common words that occur in the job descriptions. \n",
    "# Predetermine a list of expected lookup terms for dictionary of skills\n",
    "\n",
    "# BOW - Create a list of dictionaries containing word counts for each job posting\n",
    "\n",
    "# Table with skill, count, percentage\n",
    "\n",
    "# Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Words2Vec - similar words are closer together in a sentence\n",
    "\n",
    "# Topic modelling - where skills is considered a topic\n",
    "\n",
    "# NER with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-jobmarket",
   "language": "python",
   "name": "nlp-jobmarket"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
