{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<h1>Job Market Trends</h1>\n",
    "<h2>Extract, Transform, and Load Data</h2>\n",
    "\n",
    "Data Analyst vs Data Scientist job"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "source": [
    "<h2>Part 1: Access data files within a Directory</h2>\n",
    "\n",
    "The job postings are stored as files within a directory, so we will create a function to iterate through files in a directory to be able to open each one."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first check that we are in the correct directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a list of the files in the working directory\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "directory = \"Data Analyst Feb 16\"\n",
    "fileList = []\n",
    "\n",
    "# Iterate through each file in directory and make a list of each filename\n",
    "for file in os.listdir(directory):\n",
    "        if file.endswith(\".txt\"):\n",
    "            # add each filename to list\n",
    "            fileList.append(file)\n",
    "            print(fileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that fileList was populated. Sort list.\n",
    "fileList_sorted = sorted(fileList)\n",
    "print(fileList_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_data(directory):\n",
    "    '''Open file containing html of job description and prepare soup object.'''\n",
    "    fileList = []\n",
    "    soupList = []\n",
    "    # Iterate through each file in directory\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".txt\"):\n",
    "            # add each filename to list\n",
    "            fileList.append(file)\n",
    "            print(fileList)\n",
    "            # open and load html\n",
    "            with codecs.open(directory + \"/\"+ file, 'r', \"utf-8\") as f:\n",
    "                job_html = f.read()\n",
    "                job_soup = BeautifulSoup(job_html, \"html.parser\")\n",
    "                soupList.append(job_soup)\n",
    "    return soupList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soupList = get_raw_data(\"test_folder\")\n",
    "#print(soupList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure all items are in list\n",
    "len(soupList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soupList[1] prints the second item in the soupList list"
   ]
  },
  {
   "source": [
    "Great. We are able to open each of the .txt files that are in our directory of interest."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h2>Part 2 : Opening and extracting information from files</h2>\n",
    "\n",
    "First, we will use two test files to test to make sure we can pull out the information we want. This is because some companies have ratings available and some do not. This changes the html code slightly and caused some problems. Below is the result from one of the two test files."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\"Data Analyst Feb 16/Untitled 14-22-33.txt\"\n",
    "\n",
    "\"Data Analyst Feb 16/Untitled 14-36-26.txt\" -- TROX\n",
    "\n",
    "14-41-46 -- KILLI\n",
    "\n",
    "14-45-32 -- Citi worked\n",
    "\n",
    "14-25-49 -- CIBC worked\n",
    "\n",
    "14-19-29 -- TalentSphere, all worked incl salary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with codecs.open(\"Data Analyst Feb 16/Untitled 14-19-29.txt\", 'r', \"utf-8\") as f:\n",
    "    job_html = f.read()\n",
    "job_soup = BeautifulSoup(job_html, \"html.parser\")\n",
    "\n",
    "#print(job_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Financial Data Analyst\n"
     ]
    }
   ],
   "source": [
    "job_title = job_soup.find(\"h1\").text.strip()\n",
    "print(job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NavigableString' object has no attribute 'text'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-cd2fc971ca94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#company = job_soup.find(\"div\", class_=\"jobsearch-CompanyReview--heading\").text.strip()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#company = job_soup.find(\"div\", class_=\"jobsearch-DesktopStickyContainer\").next_element.text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcompany\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_soup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"div\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"jobsearch-InlineCompanyRating\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompany\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    740\u001b[0m             raise AttributeError(\n\u001b[1;32m    741\u001b[0m                 \"'%s' object has no attribute '%s'\" % (\n\u001b[0;32m--> 742\u001b[0;31m                     self.__class__.__name__, attr))\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moutput_ready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minimal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NavigableString' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "#company = job_soup.find(\"div\", class_=\"jobsearch-CompanyReview--heading\").text.strip()\n",
    "#company = job_soup.find(\"div\", class_=\"jobsearch-DesktopStickyContainer\").next_element.text\n",
    "company = job_soup.find(\"div\", class_=\"jobsearch-InlineCompanyRating\").next_element.text\n",
    "print(company)"
   ]
  },
  {
   "source": [
    "The above code was good for only some of the job listings (many of which seem to have a hyperlink).\n",
    "Try to find another way to extract company information from the job descriptions where NaN appeared."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\nTalentSphere Staffing Solutions\n\n\n14 reviews\n"
     ]
    }
   ],
   "source": [
    "# Sometimes includes the number of reviews\n",
    "company = job_soup.find(\"div\", class_=\"jobsearch-InlineCompanyRating\").text\n",
    "print(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "try 2:  TalentSphere Staffing Solutions\ntry 3:  TalentSphere Staffing Solutions\ntry 4:  TalentSphere Staffing Solutions\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    company = job_soup.find(\"div\", class_=\"jobsearch-InlineCompanyRating\").next_element.text.strip()\n",
    "    print('try 1: ', company)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    company = job_soup.find(\"div\", class_=\"jobsearch-CompanyReview--heading\").text.strip()\n",
    "    print('try 2: ', company)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    company = job_soup.find(\"div\", class_=\"jobsearch-InlineCompanyRating\").next_element.next_element.text.strip()\n",
    "    print('try 3: ', company)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# some times contains number of reviews\n",
    "try:\n",
    "    job_location = job_soup.find(\"div\", class_ = \"jobsearch-InlineCompanyRating\").text\n",
    "    print('try 4: ', company)\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<div>Toronto, ON</div>\n"
     ]
    }
   ],
   "source": [
    "# using .next_element give AttributeError: 'NavigableString' object has no attribute 'text'\n",
    "# job_location = job_soup.find(\"div\", class_ = \"jobsearch-InlineCompanyRating\").next_element.text\n",
    "\n",
    "for sibling in job_soup.find(\"div\", class_ = \"jobsearch-InlineCompanyRating\").next_siblings:\n",
    "    print(repr(sibling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-a9477a366011>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjob_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_soup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"div\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"jobsearch-InlineCompanyRating\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_sibling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_sibling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "job_location = job_soup.find(\"div\", class_ = \"jobsearch-InlineCompanyRating\").next_sibling.next_sibling.text.strip()\n",
    "print(job_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "location try\nToronto, ON\n"
     ]
    }
   ],
   "source": [
    "# Use try-except blocks differently\n",
    "\n",
    "try:\n",
    "    job_location = job_soup.find(\"div\", class_ = \"jobsearch-InlineCompanyRating\").next_sibling.text.strip()\n",
    "    print('location try')\n",
    "    print(job_location)\n",
    "except:\n",
    "    try:\n",
    "        job_location = job_soup.find(\"div\", class_ = \"jobsearch-InlineCompanyRating\").next_sibling.next_sibling.text.strip()\n",
    "        print('location except -- ', job_location)\n",
    "    except:\n",
    "        job_location = 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    job_salary = job_soup.find(\"span\", class_=\"icl-u-xs-mr--xs\").text.strip()\n",
    "except AttributeError:\n",
    "    job_salary = \"NaN\"\n",
    "print(job_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_summary = job_soup.find(\"div\", class_=\"jobsearch-jobDescriptionText\").text.strip()\n",
    "print(job_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_record = (job_title, company, job_location, job_salary, job_summary)\n",
    "print(job_record)"
   ]
  },
  {
   "source": [
    "<h2>Part 3 : Put it all together</h2>\n",
    "\n",
    "Put all the steps together so that we can easily extract job information from each text file and keep a record of which files we have opened."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works!\n",
    "import os\n",
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "def get_raw_data(directory):\n",
    "    '''Open file containing html of job description and prepare soup object.'''\n",
    "    fileList = []\n",
    "    soupList = []\n",
    "    # Iterate through each file in directory\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".txt\"):\n",
    "            # add each filename to list\n",
    "            fileList.append(file)\n",
    "            #print(fileList)\n",
    "            # open and load html\n",
    "            with codecs.open(directory + \"/\"+ file, 'r', \"utf-8\") as f:\n",
    "                job_html = f.read()\n",
    "                job_soup = BeautifulSoup(job_html, \"html.parser\")\n",
    "                soupList.append(job_soup)\n",
    "    print(\"soup_list is done.\")\n",
    "    return soupList\n",
    "\n",
    "# From the loaded text, extract job information using beautiful soup\n",
    "def get_job_record(job_soup):\n",
    "    '''Create a record of information for one job.'''\n",
    "    # Title\n",
    "    try:\n",
    "        job_title = job_soup.find('h1').text.strip()\n",
    "    except:\n",
    "        job_title = \"NaN\"\n",
    "    \n",
    "    # Company\n",
    "    try:\n",
    "        company = job_soup.find(\"div\", class_=\"jobsearch-InlineCompanyRating\").next_element.next_element.text.strip()\n",
    "    except:    \n",
    "        try:\n",
    "            company = job_soup.find(\"div\", class_=\"jobsearch-InlineCompanyRating\").text.strip()\n",
    "        except:\n",
    "            company = \"NaN\"\n",
    "\n",
    "    # Location\n",
    "    try:\n",
    "        job_location = job_soup.find(\"div\", class_ = \"jobsearch-InlineCompanyRating\").next_sibling.text.strip()\n",
    "    except:\n",
    "        try:\n",
    "            job_location = job_soup.find(\"div\", class_ = \"jobsearch-InlineCompanyRating\").next_sibling.next_sibling.text.strip()\n",
    "        except:\n",
    "            job_location = 'NaN'\n",
    "\n",
    "    # Job Summary\n",
    "    try:\n",
    "        job_summary = job_soup.find(\"div\", class_=\"jobsearch-jobDescriptionText\").text.strip()\n",
    "    except:\n",
    "        job_summary = \"NaN\"\n",
    "\n",
    "    # Not all postings have a salary available\n",
    "    try:\n",
    "        job_salary = job_soup.find(\"span\", class_=\"icl-u-xs-mr--xs\").text.strip()\n",
    "    except AttributeError:\n",
    "        job_salary = \"NaN\"\n",
    "    \n",
    "    job_record = (job_title, company, job_location, job_salary, job_summary)\n",
    "    return job_record\n",
    "\n",
    "def main_etl(directory):\n",
    "    '''This function loads text data, extracts pertinent job information, and saves data in a csv file.'''\n",
    "    #while True:\n",
    "    soupList = get_raw_data(directory)\n",
    "        \n",
    "        # add each job record to a list\n",
    "    job_records = []\n",
    "    for job_soup in soupList:\n",
    "        job_record = get_job_record(job_soup)\n",
    "        job_records.append(job_record)\n",
    "        print(\"Added to job_records list. Length of job_records is: \", len(job_records))\n",
    "\n",
    "    # add job records to csv by row\n",
    "    with open('results.csv', 'w', newline = '', encoding = 'utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Job Title', 'Company', 'Location', 'Salary', 'Job Description'])\n",
    "        writer.writerows(job_records)"
   ]
  },
  {
   "source": [
    "Let's test out the functionality on another folder containing files with job description in html format."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "source": [
    "dataAnalyst = main_etl(\"Data Analyst Feb 16\")"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 103,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "soup_list is done.\n",
      "Added to job_records list. Length of job_records is:  1\n",
      "Added to job_records list. Length of job_records is:  2\n",
      "Added to job_records list. Length of job_records is:  3\n",
      "Added to job_records list. Length of job_records is:  4\n",
      "Added to job_records list. Length of job_records is:  5\n",
      "Added to job_records list. Length of job_records is:  6\n",
      "Added to job_records list. Length of job_records is:  7\n",
      "Added to job_records list. Length of job_records is:  8\n",
      "Added to job_records list. Length of job_records is:  9\n",
      "Added to job_records list. Length of job_records is:  10\n",
      "Added to job_records list. Length of job_records is:  11\n",
      "Added to job_records list. Length of job_records is:  12\n",
      "Added to job_records list. Length of job_records is:  13\n",
      "Added to job_records list. Length of job_records is:  14\n",
      "Added to job_records list. Length of job_records is:  15\n",
      "Added to job_records list. Length of job_records is:  16\n",
      "Added to job_records list. Length of job_records is:  17\n",
      "Added to job_records list. Length of job_records is:  18\n",
      "Added to job_records list. Length of job_records is:  19\n",
      "Added to job_records list. Length of job_records is:  20\n",
      "Added to job_records list. Length of job_records is:  21\n",
      "Added to job_records list. Length of job_records is:  22\n",
      "Added to job_records list. Length of job_records is:  23\n",
      "Added to job_records list. Length of job_records is:  24\n",
      "Added to job_records list. Length of job_records is:  25\n",
      "Added to job_records list. Length of job_records is:  26\n",
      "Added to job_records list. Length of job_records is:  27\n",
      "Added to job_records list. Length of job_records is:  28\n",
      "Added to job_records list. Length of job_records is:  29\n",
      "Added to job_records list. Length of job_records is:  30\n",
      "Added to job_records list. Length of job_records is:  31\n",
      "Added to job_records list. Length of job_records is:  32\n",
      "Added to job_records list. Length of job_records is:  33\n",
      "Added to job_records list. Length of job_records is:  34\n",
      "Added to job_records list. Length of job_records is:  35\n",
      "Added to job_records list. Length of job_records is:  36\n",
      "Added to job_records list. Length of job_records is:  37\n",
      "Added to job_records list. Length of job_records is:  38\n",
      "Added to job_records list. Length of job_records is:  39\n",
      "Added to job_records list. Length of job_records is:  40\n",
      "Added to job_records list. Length of job_records is:  41\n",
      "Added to job_records list. Length of job_records is:  42\n",
      "Added to job_records list. Length of job_records is:  43\n",
      "Added to job_records list. Length of job_records is:  44\n",
      "Added to job_records list. Length of job_records is:  45\n",
      "Added to job_records list. Length of job_records is:  46\n",
      "Added to job_records list. Length of job_records is:  47\n",
      "Added to job_records list. Length of job_records is:  48\n",
      "Added to job_records list. Length of job_records is:  49\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}