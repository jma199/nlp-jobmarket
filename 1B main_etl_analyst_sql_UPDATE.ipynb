{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Job Market Trends</h1>\n",
    "<h2>Extract, Transform, and Load Data</h2>\n",
    "\n",
    "Data Analyst vs Data Scientist job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, String, Integer, Text, insert, select, delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 1: Access data files within a Directory</h2>\n",
    "\n",
    "The job postings are stored as files within a directory, so we will create a function to iterate through files in a directory to be able to open each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jennifer/nlp-jobmarket\n",
      "\u001b[31m1A main_etl_analyst_csv.ipynb\u001b[m\u001b[m\r\n",
      "1A main_etl_analyst_csv_UPDATE.ipynb\r\n",
      "\u001b[31m1B main_etl_analyst_sql.ipynb\u001b[m\u001b[m\r\n",
      "1B main_etl_analyst_sql_UPDATE.ipynb\r\n",
      "\u001b[31m1B main_etl_scientist_sql.ipynb\u001b[m\u001b[m\r\n",
      "\u001b[30m\u001b[43m24 Jun popup window\u001b[m\u001b[m\r\n",
      "\u001b[31m2A main_csv_jobdesc_nlp_preproc.ipynb\u001b[m\u001b[m\r\n",
      "2B Stemming code that didn't work.ipynb\r\n",
      "2B main_sql_jobdesc_nlp_preproc.html\r\n",
      "\u001b[31m2B main_sql_jobdesc_nlp_preproc.ipynb\u001b[m\u001b[m\r\n",
      "2B main_sql_jobdesc_nlp_topicmodeling.ipynb\r\n",
      "3B main_sql_nlp_tfidf_modelling.ipynb\r\n",
      "\u001b[1m\u001b[36mData Analyst\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[36mData Scientist\u001b[m\u001b[m\r\n",
      "README.md\r\n",
      "joblist.sqlite\r\n",
      "main_etl_scientist_sql.py\r\n",
      "\u001b[31mmain_jobdesc_eda.ipynb\u001b[m\u001b[m\r\n",
      "results.csv\r\n",
      "\u001b[1m\u001b[36mtest_folder\u001b[m\u001b[m\r\n",
      "\u001b[30m\u001b[43mtest_folder2\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "# print a list of the files in the working directory\n",
    "print(os.getcwd())\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileList = []\n",
    "\n",
    "def get_raw_data(directory):\n",
    "    '''Open file containing html of job description and prepare soup object.'''\n",
    "    #fileList = []\n",
    "    soupList = []\n",
    "    # Iterate through each file in directory\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".txt\"):\n",
    "            # add each filename to list\n",
    "            fileList.append(file)\n",
    "            #print(fileList)\n",
    "            # open and load html\n",
    "            with codecs.open(directory + \"/\"+ file, 'r', \"utf-8\") as f:\n",
    "                job_html = f.read()\n",
    "                job_soup = BeautifulSoup(job_html, \"html.parser\")\n",
    "                soupList.append(job_soup)\n",
    "    return soupList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soupList = get_raw_data(\"test_folder2\")\n",
    "#print(soupList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. We are able to open each of the .txt files that are in our directory of interest."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Let's try an alternate way of reading in files\n",
    "from glob import glob\n",
    "\n",
    "filenames = glob('untitled*.txt')\n",
    "soupList=[]\n",
    "soupList = [BeautifulSoup(jobfile, \"html.parser\") for jobfile in filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 2 : Opening and extracting information from files</h2>\n",
    "\n",
    "First, we will use a test directory with six files to test to make sure we can pull out the information we want. Some companies have ratings available and some do not. This affects how data can be parsed using the various tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Untitled 14-32-14.txt TD Bank\n",
    "- Untitled 14-22-8.txt Canadian Tire $Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract information from one file to test code\n",
    "with codecs.open(\"24 Jun popup window/Untitled 14-22-8.txt\", 'r', \"utf-8\") as f:\n",
    "    job_html = f.read()\n",
    "job_soup = BeautifulSoup(job_html, \"html.parser\")\n",
    "\n",
    "#print(job_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try 2:  Data Scientist\n"
     ]
    }
   ],
   "source": [
    "# Job title\n",
    "\n",
    "try:\n",
    "    job_title = job_soup.find(\"div\", id=\"vjs-jobtitle\").text.strip()\n",
    "    print('Try 1: ', job_title)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    job_title = job_soup.find(\"h1\").text.strip()\n",
    "    print(\"Try 2: \", job_title)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try:  Canadian Tire\n"
     ]
    }
   ],
   "source": [
    "# The company name\n",
    "\n",
    "try:\n",
    "    company = job_soup.find(\"span\", id=\"vjs-cn\").text.strip()\n",
    "    print('try: ', company)\n",
    "except:\n",
    "    print(\"NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toronto, ON\n"
     ]
    }
   ],
   "source": [
    "job_location = job_soup.find(\"span\", id=\"vjs-loc\").text.strip().replace(\"- \", \"\")\n",
    "print(job_location)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# One method doesn't seem to work for all the files in the test directory.\n",
    "# use a try-except block\n",
    "\n",
    "try:\n",
    "    job_location = job_soup.find(\"div\", class_ = \"jobsearch-InlineCompanyRating\").next_sibling.text.strip()\n",
    "    print('try-block worked: ', job_location)\n",
    "except:\n",
    "    try:\n",
    "        job_location = job_soup.find(\"div\", class_ = \"jobsearch-InlineCompanyRating\").next_sibling.next_sibling.text.strip()\n",
    "        print('location except-block -- ', job_location)\n",
    "    except:\n",
    "        job_location = 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full-time,Â Permanent\n"
     ]
    }
   ],
   "source": [
    "# Job salary\n",
    "\n",
    "try:\n",
    "    job_salary = job_soup.find(\"span\", attrs = {\"id\": None, \"class\": None, \"aria-hidden\": None}).text.strip()\n",
    "except AttributeError:\n",
    "    job_salary = \"NaN\"\n",
    "print(job_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CTC Personalization & Customer Analytics team is the central hub for engaging consumers with exciting and inspirational loyalty and product offers through better use of customer data, driving incremental sales and profit. The Promo Analytics and Operations team is accountable for creating a high performance, cross-banner, silo-free source of all customer data enabling quick and efficient customer insights, audience creation, customer journey analyses and advanced customer modelling. The Data Scientist role provides technical leadership in all facets of the project, from selecting key customer features and interactions to ensuring accurate data blending to deriving new customer attributes through descriptive and predictive analytics through a deep understanding of applying the data science lifecycle to customer modelling. The Data Scientist will be the subject matter expert in combining customer-related data sources, collaborating with teams that produce customer insights, deploy unique personalized offers directly to customers and developing other customer data products. The dynamic environment requires individuals with a cross functional background, excellent organizational skills, experience working in an agile project environment, advanced analytical ability, strong communication skills to deal effectively with stakeholders and the ability to work effectively in a team as well as independently. The primary responsibilities of the Data Scientist include: Efficiently and accurately integrate customer data from a variety of organizational systems. Derive customer attributes and intents through novel uses of the data at hand and models to describe and predict customer behaviour, as well as a deep understanding of customer behaviour. Ensure generated insights meet standards of analytical and statistical rigour, highlighting gaps where necessary. Provide mentorship to team members on data, code, and data science best practices. Lead the creation of efficient, cost-effective high-availability pipelines. Work with IT teams to ensure that project needs are met in the next generation of CTC data platforms. Provide ad hoc analytics and recommendations for action as needed. Qualifications: Professional Post-Secondary Education at the Masterâs level, with 2-5 years experience in a business environment. Extensive knowledge of statistics, predictive analytics and data science techniques to improve customer understanding through creative problem solving and modelling. Experience leading analytical projects with iterative improvement in a fast-paced environment. Ability to understand what data means about a customer. Technical Strong familiarity with statistical modeling tools and data science libraries. Python & SQL are required. Experience building dashboards and visualizations in Enterprise-grade BI tools. Good working knowledge of relational and non-relational databases in big data (Hive, BigQuery, SnowFlake) and/or cloud environments (GCP, Azure). Intermediate knowledge of standard desktop tools such as Excel and PowerPoint Interpersonal Provides a positive influence and excels in a fast-paced team environment with the ability to take on leadership responsibilities while embracing and driving innovative solutions that improve the performance of the team. Advanced written and verbal communication skills. Strong interpersonal skills with the ability to embrace and action constructive feedback positively. Exceptional attention to detail. Strong ability to: Work with complex and evolving systems and extensive and varied data. Manage changing/conflicting priorities and make effective decisions quickly. Adapt to rapid and continuous change to project requirements and priorities.  Canadian Tire is an equal opportunity employer. We are committed to a diverse and inclusive workplace for all. We recognize that our future success depends on the perspectives and contributions of all our employees - their diverse backgrounds, abilities and experiences make our business stronger. If you are contacted for a job opportunity, please advise us of any accommodations needed to ensure fair and equitable access throughout the recruitment and selection process. All accommodation information provided will be treated as confidential and used only for the purpose of providing an accessible candidate experience. CTR Marketing Ontario-Toronto Permanent Full-time Job Posting  : Jun 21, 2021, 9:42:38 AM\n"
     ]
    }
   ],
   "source": [
    "job_description = job_soup.find(\"div\", id=\"vjs-desc\").text.strip().replace('\\n', ' ')\n",
    "print(job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4451\n"
     ]
    }
   ],
   "source": [
    "print(len(job_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_title1 label:  1\n",
      "job_title2 label:  0\n"
     ]
    }
   ],
   "source": [
    "def get_label(job_title):\n",
    "    if 'cientist' in job_title:\n",
    "        label = '1'\n",
    "    else:\n",
    "        label = '0' #analyst\n",
    "    return label\n",
    "\n",
    "job_title1 = \"Data Scientist\"\n",
    "job_title2 = \"Data Analyst\"\n",
    "\n",
    "label = get_label(job_title1)\n",
    "print(\"job_title1 label: \", label)\n",
    "\n",
    "label1 = get_label(job_title2)\n",
    "print(\"job_title2 label: \", label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'jobtitle': 'Data Scientist', 'company': 'Canadian Tire', 'location': 'Toronto, ON', 'salary': 'Full-time,\\xa0Permanent', 'jobdescription': 'The CTC Personalization & Customer Analytics team is the central hub for engaging consumers with exciting and inspirational loyalty and product offers through better use of customer data, driving incremental sales and profit. The Promo Analytics and Operations team is accountable for creating a high performance, cross-banner, silo-free source of all customer data enabling quick and efficient customer insights, audience creation, customer journey analyses and advanced customer modelling. The Data Scientist role provides technical leadership in all facets of the project, from selecting key customer features and interactions to ensuring accurate data blending to deriving new customer attributes through descriptive and predictive analytics through a deep understanding of applying the data science lifecycle to customer modelling. The Data Scientist will be the subject matter expert in combining customer-related data sources, collaborating with teams that produce customer insights, deploy unique personalized offers directly to customers and developing other customer data products. The dynamic environment requires individuals with a cross functional background, excellent organizational skills, experience working in an agile project environment, advanced analytical ability, strong communication skills to deal effectively with stakeholders and the ability to work effectively in a team as well as independently. The primary responsibilities of the Data Scientist include: Efficiently and accurately integrate customer data from a variety of organizational systems. Derive customer attributes and intents through novel uses of the data at hand and models to describe and predict customer behaviour, as well as a deep understanding of customer behaviour. Ensure generated insights meet standards of analytical and statistical rigour, highlighting gaps where necessary. Provide mentorship to team members on data, code, and data science best practices. Lead the creation of efficient, cost-effective high-availability pipelines. Work with IT teams to ensure that project needs are met in the next generation of CTC data platforms. Provide ad hoc analytics and recommendations for action as needed. Qualifications: Professional Post-Secondary Education at the Masterâs level, with 2-5 years experience in a business environment. Extensive knowledge of statistics, predictive analytics and data science techniques to improve customer understanding through creative problem solving and modelling. Experience leading analytical projects with iterative improvement in a fast-paced environment. Ability to understand what data means about a customer. Technical Strong familiarity with statistical modeling tools and data science libraries. Python & SQL are required. Experience building dashboards and visualizations in Enterprise-grade BI tools. Good working knowledge of relational and non-relational databases in big data (Hive, BigQuery, SnowFlake) and/or cloud environments (GCP, Azure). Intermediate knowledge of standard desktop tools such as Excel and PowerPoint Interpersonal Provides a positive influence and excels in a fast-paced team environment with the ability to take on leadership responsibilities while embracing and driving innovative solutions that improve the performance of the team. Advanced written and verbal communication skills. Strong interpersonal skills with the ability to embrace and action constructive feedback positively. Exceptional attention to detail. Strong ability to: Work with complex and evolving systems and extensive and varied data. Manage changing/conflicting priorities and make effective decisions quickly. Adapt to rapid and continuous change to project requirements and priorities.  Canadian Tire is an equal opportunity employer. We are committed to a diverse and inclusive workplace for all. We recognize that our future success depends on the perspectives and contributions of all our employees - their diverse backgrounds, abilities and experiences make our business stronger. If you are contacted for a job opportunity, please advise us of any accommodations needed to ensure fair and equitable access throughout the recruitment and selection process. All accommodation information provided will be treated as confidential and used only for the purpose of providing an accessible candidate experience. CTR Marketing Ontario-Toronto Permanent Full-time Job Posting  : Jun 21, 2021, 9:42:38 AM', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "job_record = {'jobtitle': job_title,\n",
    "              'company': company,\n",
    "              'location': job_location,\n",
    "              'salary': job_salary,\n",
    "              'jobdescription': job_description,\n",
    "              'label': 0\n",
    "             }\n",
    "print(job_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To persist the data, we will save the records directly a SQlite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data']\n"
     ]
    }
   ],
   "source": [
    "# Import necessary module\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, String, Integer, Text\n",
    "\n",
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///joblist.sqlite')\n",
    "metadata = MetaData()\n",
    "\n",
    "# Define a new table\n",
    "data = Table('data', metadata,\n",
    "             Column('jobtitle', String(100)),\n",
    "             Column('company', String(100)),\n",
    "             Column('location', String(25)),\n",
    "             Column('salary', Integer()),\n",
    "             Column('jobdescription', Text()),\n",
    "             Column('label', Integer())\n",
    ")\n",
    "\n",
    "# Create table\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Print table details\n",
    "print(engine.table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows added is:  1\n"
     ]
    }
   ],
   "source": [
    "# Import insert and select from sqlalchemy\n",
    "from sqlalchemy import insert, select\n",
    "\n",
    "# Build an insert statement to insert a record into the data table: insert_stmt\n",
    "insert_stmt = insert(data).values(jobtitle= job_title,\n",
    "                                 company= company,\n",
    "                                 location= job_location,\n",
    "                                 salary= job_salary,\n",
    "                                 jobdescription= job_description,\n",
    "                                 label= 0\n",
    "                                 )\n",
    "\n",
    "# Execute the insert statement via the connection: results\n",
    "connection = engine.connect()\n",
    "results = connection.execute(insert_stmt)\n",
    "\n",
    "# Print result rowcount\n",
    "print(\"The number of rows added is: \", results.rowcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Financial Data Analyst', 'TalentSphere Staffing Solutions', 'Toronto, ON', '$50,000 - $60,000 a year', 'Job Title: Financial Data Analyst\\nIndustry Sector: Nor for Profit\\nSalary: $50,000-$60,000 + great benefits, vacation and w/l balance.\\nLocation: To ... (2175 characters truncated) ...  minded, intelligent, fun, dynamic people who love the company they work in and all it stands for! What could be better than that?!\\n\\nTSSHP\\n#LI-TS1', 0)]\n"
     ]
    }
   ],
   "source": [
    "# SELECT the row we just added to db\n",
    "stmt = 'SELECT * from data'\n",
    "results = connection.execute(stmt).fetchall()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following stmt is the same as above\n",
    "# stmt = select([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows is:  1\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import delete\n",
    "\n",
    "# DELETE row from database\n",
    "delete_stmt = delete(data)\n",
    "results = connection.execute(delete_stmt)\n",
    "print(\"The number of rows is: \", results.rowcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of tables: ['data']\n"
     ]
    }
   ],
   "source": [
    "# Check to see that data table in db was properly deleted\n",
    "\n",
    "# Print table details\n",
    "print('List of tables:', engine.table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# SELECT the row we just added to db\n",
    "stmt = 'SELECT * from data'\n",
    "results = connection.execute(stmt).fetchall()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection\n",
    "#connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 3 : Put it all together</h2>\n",
    "\n",
    "Put all the steps together so that we can easily extract job information from each text file and keep a record of which files we have opened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, String, Integer, Text, insert, select, delete\n",
    "\n",
    "def get_raw_data(directory):\n",
    "    '''Open file containing html of job description and prepare soup object.'''\n",
    "    fileList = []\n",
    "    soupList = []\n",
    "    # Iterate through each file in directory\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".txt\"):\n",
    "            # add each filename to list\n",
    "            fileList.append(file)\n",
    "            #print(fileList)\n",
    "            # open and load html\n",
    "            with codecs.open(directory + \"/\"+ file, 'r', \"utf-8\") as f:\n",
    "                job_html = f.read()\n",
    "                job_soup = BeautifulSoup(job_html, \"html.parser\")\n",
    "                soupList.append(job_soup)\n",
    "    print(\"soup_list is done.\")\n",
    "    return soupList\n",
    "\n",
    "# From the loaded text, extract job information using beautiful soup\n",
    "def get_job_record(job_soup):\n",
    "    '''Create a record of information for one job.'''\n",
    "    # Title\n",
    "    try:\n",
    "        job_title = job_soup.find('h1').text.strip()\n",
    "    except:\n",
    "        job_title = \"NaN\"\n",
    "    \n",
    "    # Company\n",
    "    try:\n",
    "        company = job_soup.find(\"div\", class_=\"jobsearch-InlineCompanyRating\").next_element.next_element.text.strip()\n",
    "    except:    \n",
    "        try:\n",
    "            company = job_soup.find(\"div\", class_=\"jobsearch-InlineCompanyRating\").text.strip()\n",
    "        except:\n",
    "            company = \"NaN\"\n",
    "\n",
    "    # Location\n",
    "    try:\n",
    "        job_location = job_soup.find(\"div\", class_ = \"jobsearch-InlineCompanyRating\").next_sibling.text.strip()\n",
    "    except:\n",
    "        try:\n",
    "            job_location = job_soup.find(\"div\", class_ = \"jobsearch-InlineCompanyRating\").next_sibling.next_sibling.text.strip()\n",
    "        except:\n",
    "            job_location = 'NaN'\n",
    "\n",
    "    # Job Description\n",
    "    try:\n",
    "        job_description = job_soup.find(\"div\", class_=\"jobsearch-jobDescriptionText\").text.strip().replace('\\n', ' ')\n",
    "    except:\n",
    "        job_description = \"NaN\"\n",
    "\n",
    "    # Not all postings have a salary available\n",
    "    try:\n",
    "        job_salary = job_soup.find(\"span\", class_=\"icl-u-xs-mr--xs\").text.strip()\n",
    "    except AttributeError:\n",
    "        job_salary = \"NaN\"\n",
    "    \n",
    "    job_record = {'jobtitle': job_title,\n",
    "                                 'company': company,\n",
    "                                 'location': job_location,\n",
    "                                 'salary': job_salary,\n",
    "                                 'jobdescription': job_description,\n",
    "                                 'label': 0\n",
    "                 }\n",
    "\n",
    "    return job_record\n",
    "\n",
    "def main_etl(directory):\n",
    "    '''This function loads text data, extracts pertinent job information, and saves data in a sql database.'''\n",
    "    soupList = get_raw_data(directory)\n",
    "        \n",
    "    # add each job record to a list\n",
    "    # this will create a list of dictionaries, making it easy to insert into a sql table\n",
    "    job_records = []\n",
    "    for job_soup in soupList:\n",
    "        job_record = get_job_record(job_soup)\n",
    "        job_records.append(job_record)\n",
    "        #print(\"Added to job_records list. Length of job_records is: \", len(job_records))\n",
    "\n",
    "    # add job records to sqlite db\n",
    "    # Create engine: engine\n",
    "    engine = create_engine('sqlite:///joblist.sqlite')\n",
    "    metadata = MetaData()\n",
    "\n",
    "    # Define a new table\n",
    "    data = Table('data', metadata,\n",
    "                 Column('jobtitle', String(100)),\n",
    "                 Column('company', String(100)),\n",
    "                 Column('location', String(25)),\n",
    "                 Column('salary', Integer()),\n",
    "                 Column('jobdescription', Text()),\n",
    "                 Column('label', Integer())\n",
    "                )\n",
    "\n",
    "    # Create table\n",
    "    metadata.create_all(engine)\n",
    "\n",
    "    # Print table details\n",
    "    print(engine.table_names())\n",
    "\n",
    "    # Build an insert statement to insert a record into the data table: insert_stmt\n",
    "    insert_stmt = insert(data)\n",
    "\n",
    "    # Execute the insert statement via the connection: results\n",
    "    connection = engine.connect()\n",
    "    results = connection.execute(insert_stmt, job_records)\n",
    "\n",
    "    # Print result rowcount\n",
    "    print(\"The number of rows added is: \", results.rowcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test out the functionality on another folder containing files with job description in html format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jennifer/nlp-jobmarket\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m1A main_etl_analyst_csv.ipynb\u001b[m\u001b[m         README.md\r\n",
      "\u001b[31m1B main_etl_analyst_sql.ipynb\u001b[m\u001b[m         joblist.sqlite\r\n",
      "\u001b[31m1B main_etl_scientist_sql.ipynb\u001b[m\u001b[m       main_etl_scientist_sql.py\r\n",
      "\u001b[31m2A main_csv_jobdesc_nlp_preproc.ipynb\u001b[m\u001b[m \u001b[31mmain_jobdesc_eda.ipynb\u001b[m\u001b[m\r\n",
      "\u001b[31m2B main_sql_jobdesc_nlp_preproc.ipynb\u001b[m\u001b[m results.csv\r\n",
      "\u001b[1m\u001b[36mData Analyst\u001b[m\u001b[m                          \u001b[1m\u001b[36mtest_folder\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[36mData Scientist\u001b[m\u001b[m                        \u001b[30m\u001b[43mtest_folder2\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data']\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, delete, func\n",
    "\n",
    "engine = create_engine('sqlite:///joblist.sqlite')\n",
    "connect = engine.connect()\n",
    "\n",
    "print(engine.table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jobtitle', 'company', 'location', 'salary', 'jobdescription', 'label']\n",
      "Table('data', MetaData(bind=None), Column('jobtitle', VARCHAR(length=100), table=<data>), Column('company', VARCHAR(length=100), table=<data>), Column('location', VARCHAR(length=25), table=<data>), Column('salary', INTEGER(), table=<data>), Column('jobdescription', TEXT(), table=<data>), Column('label', INTEGER(), table=<data>), schema=None)\n"
     ]
    }
   ],
   "source": [
    "# Load in data table\n",
    "metadata = MetaData()\n",
    "\n",
    "data = Table('data', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "print(data.columns.keys())\n",
    "print(repr(metadata.tables['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of rows\n",
    "# Should be 0\n",
    "stmt = select([func.count(data.columns.jobdescription)])\n",
    "connect.execute(stmt).scalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soup_list is done.\n",
      "Added to job_records list. Length of job_records is:  1\n",
      "Added to job_records list. Length of job_records is:  2\n",
      "Added to job_records list. Length of job_records is:  3\n",
      "Added to job_records list. Length of job_records is:  4\n",
      "Added to job_records list. Length of job_records is:  5\n",
      "Added to job_records list. Length of job_records is:  6\n",
      "Added to job_records list. Length of job_records is:  7\n",
      "Added to job_records list. Length of job_records is:  8\n",
      "Added to job_records list. Length of job_records is:  9\n",
      "Added to job_records list. Length of job_records is:  10\n",
      "Added to job_records list. Length of job_records is:  11\n",
      "Added to job_records list. Length of job_records is:  12\n",
      "Added to job_records list. Length of job_records is:  13\n",
      "Added to job_records list. Length of job_records is:  14\n",
      "Added to job_records list. Length of job_records is:  15\n",
      "Added to job_records list. Length of job_records is:  16\n",
      "Added to job_records list. Length of job_records is:  17\n",
      "Added to job_records list. Length of job_records is:  18\n",
      "Added to job_records list. Length of job_records is:  19\n",
      "Added to job_records list. Length of job_records is:  20\n",
      "Added to job_records list. Length of job_records is:  21\n",
      "Added to job_records list. Length of job_records is:  22\n",
      "Added to job_records list. Length of job_records is:  23\n",
      "Added to job_records list. Length of job_records is:  24\n",
      "Added to job_records list. Length of job_records is:  25\n",
      "Added to job_records list. Length of job_records is:  26\n",
      "Added to job_records list. Length of job_records is:  27\n",
      "Added to job_records list. Length of job_records is:  28\n",
      "Added to job_records list. Length of job_records is:  29\n",
      "Added to job_records list. Length of job_records is:  30\n",
      "Added to job_records list. Length of job_records is:  31\n",
      "Added to job_records list. Length of job_records is:  32\n",
      "Added to job_records list. Length of job_records is:  33\n",
      "Added to job_records list. Length of job_records is:  34\n",
      "Added to job_records list. Length of job_records is:  35\n",
      "Added to job_records list. Length of job_records is:  36\n",
      "Added to job_records list. Length of job_records is:  37\n",
      "Added to job_records list. Length of job_records is:  38\n",
      "Added to job_records list. Length of job_records is:  39\n",
      "Added to job_records list. Length of job_records is:  40\n",
      "Added to job_records list. Length of job_records is:  41\n",
      "Added to job_records list. Length of job_records is:  42\n",
      "Added to job_records list. Length of job_records is:  43\n",
      "Added to job_records list. Length of job_records is:  44\n",
      "Added to job_records list. Length of job_records is:  45\n",
      "Added to job_records list. Length of job_records is:  46\n",
      "Added to job_records list. Length of job_records is:  47\n",
      "Added to job_records list. Length of job_records is:  48\n",
      "Added to job_records list. Length of job_records is:  49\n",
      "Added to job_records list. Length of job_records is:  50\n",
      "Added to job_records list. Length of job_records is:  51\n",
      "Added to job_records list. Length of job_records is:  52\n",
      "Added to job_records list. Length of job_records is:  53\n",
      "Added to job_records list. Length of job_records is:  54\n",
      "Added to job_records list. Length of job_records is:  55\n",
      "Added to job_records list. Length of job_records is:  56\n",
      "Added to job_records list. Length of job_records is:  57\n",
      "Added to job_records list. Length of job_records is:  58\n",
      "Added to job_records list. Length of job_records is:  59\n",
      "Added to job_records list. Length of job_records is:  60\n",
      "Added to job_records list. Length of job_records is:  61\n",
      "Added to job_records list. Length of job_records is:  62\n",
      "Added to job_records list. Length of job_records is:  63\n",
      "Added to job_records list. Length of job_records is:  64\n",
      "Added to job_records list. Length of job_records is:  65\n",
      "Added to job_records list. Length of job_records is:  66\n",
      "Added to job_records list. Length of job_records is:  67\n",
      "Added to job_records list. Length of job_records is:  68\n",
      "Added to job_records list. Length of job_records is:  69\n",
      "Added to job_records list. Length of job_records is:  70\n",
      "Added to job_records list. Length of job_records is:  71\n",
      "Added to job_records list. Length of job_records is:  72\n",
      "Added to job_records list. Length of job_records is:  73\n",
      "Added to job_records list. Length of job_records is:  74\n",
      "Added to job_records list. Length of job_records is:  75\n",
      "Added to job_records list. Length of job_records is:  76\n",
      "Added to job_records list. Length of job_records is:  77\n",
      "Added to job_records list. Length of job_records is:  78\n",
      "Added to job_records list. Length of job_records is:  79\n",
      "Added to job_records list. Length of job_records is:  80\n",
      "Added to job_records list. Length of job_records is:  81\n",
      "Added to job_records list. Length of job_records is:  82\n",
      "Added to job_records list. Length of job_records is:  83\n",
      "Added to job_records list. Length of job_records is:  84\n",
      "Added to job_records list. Length of job_records is:  85\n",
      "Added to job_records list. Length of job_records is:  86\n",
      "Added to job_records list. Length of job_records is:  87\n",
      "Added to job_records list. Length of job_records is:  88\n",
      "Added to job_records list. Length of job_records is:  89\n",
      "Added to job_records list. Length of job_records is:  90\n",
      "Added to job_records list. Length of job_records is:  91\n",
      "Added to job_records list. Length of job_records is:  92\n",
      "Added to job_records list. Length of job_records is:  93\n",
      "Added to job_records list. Length of job_records is:  94\n",
      "Added to job_records list. Length of job_records is:  95\n",
      "Added to job_records list. Length of job_records is:  96\n",
      "Added to job_records list. Length of job_records is:  97\n",
      "Added to job_records list. Length of job_records is:  98\n",
      "Added to job_records list. Length of job_records is:  99\n",
      "Added to job_records list. Length of job_records is:  100\n",
      "Added to job_records list. Length of job_records is:  101\n",
      "Added to job_records list. Length of job_records is:  102\n",
      "Added to job_records list. Length of job_records is:  103\n",
      "Added to job_records list. Length of job_records is:  104\n",
      "Added to job_records list. Length of job_records is:  105\n",
      "Added to job_records list. Length of job_records is:  106\n",
      "Added to job_records list. Length of job_records is:  107\n",
      "Added to job_records list. Length of job_records is:  108\n",
      "Added to job_records list. Length of job_records is:  109\n",
      "Added to job_records list. Length of job_records is:  110\n",
      "Added to job_records list. Length of job_records is:  111\n",
      "Added to job_records list. Length of job_records is:  112\n",
      "Added to job_records list. Length of job_records is:  113\n",
      "Added to job_records list. Length of job_records is:  114\n",
      "Added to job_records list. Length of job_records is:  115\n",
      "Added to job_records list. Length of job_records is:  116\n",
      "Added to job_records list. Length of job_records is:  117\n",
      "Added to job_records list. Length of job_records is:  118\n",
      "Added to job_records list. Length of job_records is:  119\n",
      "Added to job_records list. Length of job_records is:  120\n",
      "Added to job_records list. Length of job_records is:  121\n",
      "Added to job_records list. Length of job_records is:  122\n",
      "Added to job_records list. Length of job_records is:  123\n",
      "Added to job_records list. Length of job_records is:  124\n",
      "Added to job_records list. Length of job_records is:  125\n",
      "Added to job_records list. Length of job_records is:  126\n",
      "Added to job_records list. Length of job_records is:  127\n",
      "Added to job_records list. Length of job_records is:  128\n",
      "Added to job_records list. Length of job_records is:  129\n",
      "Added to job_records list. Length of job_records is:  130\n",
      "Added to job_records list. Length of job_records is:  131\n",
      "Added to job_records list. Length of job_records is:  132\n",
      "Added to job_records list. Length of job_records is:  133\n",
      "Added to job_records list. Length of job_records is:  134\n",
      "Added to job_records list. Length of job_records is:  135\n",
      "Added to job_records list. Length of job_records is:  136\n",
      "Added to job_records list. Length of job_records is:  137\n",
      "Added to job_records list. Length of job_records is:  138\n",
      "Added to job_records list. Length of job_records is:  139\n",
      "Added to job_records list. Length of job_records is:  140\n",
      "Added to job_records list. Length of job_records is:  141\n",
      "Added to job_records list. Length of job_records is:  142\n",
      "Added to job_records list. Length of job_records is:  143\n",
      "Added to job_records list. Length of job_records is:  144\n",
      "Added to job_records list. Length of job_records is:  145\n",
      "Added to job_records list. Length of job_records is:  146\n",
      "Added to job_records list. Length of job_records is:  147\n",
      "Added to job_records list. Length of job_records is:  148\n",
      "Added to job_records list. Length of job_records is:  149\n",
      "Added to job_records list. Length of job_records is:  150\n",
      "Added to job_records list. Length of job_records is:  151\n",
      "Added to job_records list. Length of job_records is:  152\n",
      "Added to job_records list. Length of job_records is:  153\n",
      "Added to job_records list. Length of job_records is:  154\n",
      "Added to job_records list. Length of job_records is:  155\n",
      "Added to job_records list. Length of job_records is:  156\n",
      "Added to job_records list. Length of job_records is:  157\n",
      "Added to job_records list. Length of job_records is:  158\n",
      "Added to job_records list. Length of job_records is:  159\n",
      "Added to job_records list. Length of job_records is:  160\n",
      "Added to job_records list. Length of job_records is:  161\n",
      "Added to job_records list. Length of job_records is:  162\n",
      "Added to job_records list. Length of job_records is:  163\n",
      "Added to job_records list. Length of job_records is:  164\n",
      "Added to job_records list. Length of job_records is:  165\n",
      "Added to job_records list. Length of job_records is:  166\n",
      "Added to job_records list. Length of job_records is:  167\n",
      "Added to job_records list. Length of job_records is:  168\n",
      "Added to job_records list. Length of job_records is:  169\n",
      "Added to job_records list. Length of job_records is:  170\n",
      "Added to job_records list. Length of job_records is:  171\n",
      "Added to job_records list. Length of job_records is:  172\n",
      "Added to job_records list. Length of job_records is:  173\n",
      "Added to job_records list. Length of job_records is:  174\n",
      "Added to job_records list. Length of job_records is:  175\n",
      "Added to job_records list. Length of job_records is:  176\n",
      "Added to job_records list. Length of job_records is:  177\n",
      "Added to job_records list. Length of job_records is:  178\n",
      "Added to job_records list. Length of job_records is:  179\n",
      "Added to job_records list. Length of job_records is:  180\n",
      "Added to job_records list. Length of job_records is:  181\n",
      "Added to job_records list. Length of job_records is:  182\n",
      "Added to job_records list. Length of job_records is:  183\n",
      "Added to job_records list. Length of job_records is:  184\n",
      "Added to job_records list. Length of job_records is:  185\n",
      "Added to job_records list. Length of job_records is:  186\n",
      "Added to job_records list. Length of job_records is:  187\n",
      "Added to job_records list. Length of job_records is:  188\n",
      "Added to job_records list. Length of job_records is:  189\n",
      "Added to job_records list. Length of job_records is:  190\n",
      "Added to job_records list. Length of job_records is:  191\n",
      "Added to job_records list. Length of job_records is:  192\n",
      "Added to job_records list. Length of job_records is:  193\n",
      "Added to job_records list. Length of job_records is:  194\n",
      "Added to job_records list. Length of job_records is:  195\n",
      "Added to job_records list. Length of job_records is:  196\n",
      "Added to job_records list. Length of job_records is:  197\n",
      "Added to job_records list. Length of job_records is:  198\n",
      "Added to job_records list. Length of job_records is:  199\n",
      "Added to job_records list. Length of job_records is:  200\n",
      "Added to job_records list. Length of job_records is:  201\n",
      "Added to job_records list. Length of job_records is:  202\n",
      "Added to job_records list. Length of job_records is:  203\n",
      "Added to job_records list. Length of job_records is:  204\n",
      "Added to job_records list. Length of job_records is:  205\n",
      "Added to job_records list. Length of job_records is:  206\n",
      "Added to job_records list. Length of job_records is:  207\n",
      "Added to job_records list. Length of job_records is:  208\n",
      "Added to job_records list. Length of job_records is:  209\n",
      "Added to job_records list. Length of job_records is:  210\n",
      "Added to job_records list. Length of job_records is:  211\n",
      "Added to job_records list. Length of job_records is:  212\n",
      "Added to job_records list. Length of job_records is:  213\n",
      "Added to job_records list. Length of job_records is:  214\n",
      "Added to job_records list. Length of job_records is:  215\n",
      "Added to job_records list. Length of job_records is:  216\n",
      "Added to job_records list. Length of job_records is:  217\n",
      "Added to job_records list. Length of job_records is:  218\n",
      "Added to job_records list. Length of job_records is:  219\n",
      "Added to job_records list. Length of job_records is:  220\n",
      "Added to job_records list. Length of job_records is:  221\n",
      "Added to job_records list. Length of job_records is:  222\n",
      "Added to job_records list. Length of job_records is:  223\n",
      "Added to job_records list. Length of job_records is:  224\n",
      "Added to job_records list. Length of job_records is:  225\n",
      "Added to job_records list. Length of job_records is:  226\n",
      "Added to job_records list. Length of job_records is:  227\n",
      "Added to job_records list. Length of job_records is:  228\n",
      "Added to job_records list. Length of job_records is:  229\n",
      "Added to job_records list. Length of job_records is:  230\n",
      "Added to job_records list. Length of job_records is:  231\n",
      "Added to job_records list. Length of job_records is:  232\n",
      "Added to job_records list. Length of job_records is:  233\n",
      "Added to job_records list. Length of job_records is:  234\n",
      "Added to job_records list. Length of job_records is:  235\n",
      "Added to job_records list. Length of job_records is:  236\n",
      "Added to job_records list. Length of job_records is:  237\n",
      "Added to job_records list. Length of job_records is:  238\n",
      "Added to job_records list. Length of job_records is:  239\n",
      "Added to job_records list. Length of job_records is:  240\n",
      "Added to job_records list. Length of job_records is:  241\n",
      "Added to job_records list. Length of job_records is:  242\n",
      "Added to job_records list. Length of job_records is:  243\n",
      "Added to job_records list. Length of job_records is:  244\n",
      "Added to job_records list. Length of job_records is:  245\n",
      "Added to job_records list. Length of job_records is:  246\n",
      "Added to job_records list. Length of job_records is:  247\n",
      "Added to job_records list. Length of job_records is:  248\n",
      "Added to job_records list. Length of job_records is:  249\n",
      "Added to job_records list. Length of job_records is:  250\n",
      "Added to job_records list. Length of job_records is:  251\n",
      "Added to job_records list. Length of job_records is:  252\n",
      "Added to job_records list. Length of job_records is:  253\n",
      "Added to job_records list. Length of job_records is:  254\n",
      "Added to job_records list. Length of job_records is:  255\n",
      "Added to job_records list. Length of job_records is:  256\n",
      "Added to job_records list. Length of job_records is:  257\n",
      "Added to job_records list. Length of job_records is:  258\n",
      "Added to job_records list. Length of job_records is:  259\n",
      "Added to job_records list. Length of job_records is:  260\n",
      "Added to job_records list. Length of job_records is:  261\n",
      "Added to job_records list. Length of job_records is:  262\n",
      "Added to job_records list. Length of job_records is:  263\n",
      "Added to job_records list. Length of job_records is:  264\n",
      "Added to job_records list. Length of job_records is:  265\n",
      "Added to job_records list. Length of job_records is:  266\n",
      "Added to job_records list. Length of job_records is:  267\n",
      "Added to job_records list. Length of job_records is:  268\n",
      "Added to job_records list. Length of job_records is:  269\n",
      "Added to job_records list. Length of job_records is:  270\n",
      "Added to job_records list. Length of job_records is:  271\n",
      "Added to job_records list. Length of job_records is:  272\n",
      "Added to job_records list. Length of job_records is:  273\n",
      "Added to job_records list. Length of job_records is:  274\n",
      "Added to job_records list. Length of job_records is:  275\n",
      "Added to job_records list. Length of job_records is:  276\n",
      "Added to job_records list. Length of job_records is:  277\n",
      "Added to job_records list. Length of job_records is:  278\n",
      "Added to job_records list. Length of job_records is:  279\n",
      "Added to job_records list. Length of job_records is:  280\n",
      "Added to job_records list. Length of job_records is:  281\n",
      "Added to job_records list. Length of job_records is:  282\n",
      "Added to job_records list. Length of job_records is:  283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to job_records list. Length of job_records is:  284\n",
      "Added to job_records list. Length of job_records is:  285\n",
      "Added to job_records list. Length of job_records is:  286\n",
      "Added to job_records list. Length of job_records is:  287\n",
      "Added to job_records list. Length of job_records is:  288\n",
      "Added to job_records list. Length of job_records is:  289\n",
      "Added to job_records list. Length of job_records is:  290\n",
      "Added to job_records list. Length of job_records is:  291\n",
      "Added to job_records list. Length of job_records is:  292\n",
      "Added to job_records list. Length of job_records is:  293\n",
      "Added to job_records list. Length of job_records is:  294\n",
      "Added to job_records list. Length of job_records is:  295\n",
      "Added to job_records list. Length of job_records is:  296\n",
      "Added to job_records list. Length of job_records is:  297\n",
      "Added to job_records list. Length of job_records is:  298\n",
      "Added to job_records list. Length of job_records is:  299\n",
      "Added to job_records list. Length of job_records is:  300\n",
      "Added to job_records list. Length of job_records is:  301\n",
      "Added to job_records list. Length of job_records is:  302\n",
      "Added to job_records list. Length of job_records is:  303\n",
      "Added to job_records list. Length of job_records is:  304\n",
      "Added to job_records list. Length of job_records is:  305\n",
      "Added to job_records list. Length of job_records is:  306\n",
      "Added to job_records list. Length of job_records is:  307\n",
      "Added to job_records list. Length of job_records is:  308\n",
      "Added to job_records list. Length of job_records is:  309\n",
      "Added to job_records list. Length of job_records is:  310\n",
      "Added to job_records list. Length of job_records is:  311\n",
      "Added to job_records list. Length of job_records is:  312\n",
      "Added to job_records list. Length of job_records is:  313\n",
      "Added to job_records list. Length of job_records is:  314\n",
      "Added to job_records list. Length of job_records is:  315\n",
      "Added to job_records list. Length of job_records is:  316\n",
      "Added to job_records list. Length of job_records is:  317\n",
      "Added to job_records list. Length of job_records is:  318\n",
      "Added to job_records list. Length of job_records is:  319\n",
      "Added to job_records list. Length of job_records is:  320\n",
      "Added to job_records list. Length of job_records is:  321\n",
      "Added to job_records list. Length of job_records is:  322\n",
      "Added to job_records list. Length of job_records is:  323\n",
      "Added to job_records list. Length of job_records is:  324\n",
      "Added to job_records list. Length of job_records is:  325\n",
      "Added to job_records list. Length of job_records is:  326\n",
      "Added to job_records list. Length of job_records is:  327\n",
      "Added to job_records list. Length of job_records is:  328\n",
      "Added to job_records list. Length of job_records is:  329\n",
      "Added to job_records list. Length of job_records is:  330\n",
      "Added to job_records list. Length of job_records is:  331\n",
      "Added to job_records list. Length of job_records is:  332\n",
      "Added to job_records list. Length of job_records is:  333\n",
      "Added to job_records list. Length of job_records is:  334\n",
      "Added to job_records list. Length of job_records is:  335\n",
      "Added to job_records list. Length of job_records is:  336\n",
      "Added to job_records list. Length of job_records is:  337\n",
      "Added to job_records list. Length of job_records is:  338\n",
      "Added to job_records list. Length of job_records is:  339\n",
      "Added to job_records list. Length of job_records is:  340\n",
      "Added to job_records list. Length of job_records is:  341\n",
      "Added to job_records list. Length of job_records is:  342\n",
      "Added to job_records list. Length of job_records is:  343\n",
      "Added to job_records list. Length of job_records is:  344\n",
      "Added to job_records list. Length of job_records is:  345\n",
      "Added to job_records list. Length of job_records is:  346\n",
      "Added to job_records list. Length of job_records is:  347\n",
      "Added to job_records list. Length of job_records is:  348\n",
      "Added to job_records list. Length of job_records is:  349\n",
      "Added to job_records list. Length of job_records is:  350\n",
      "Added to job_records list. Length of job_records is:  351\n",
      "Added to job_records list. Length of job_records is:  352\n",
      "Added to job_records list. Length of job_records is:  353\n",
      "Added to job_records list. Length of job_records is:  354\n",
      "Added to job_records list. Length of job_records is:  355\n",
      "Added to job_records list. Length of job_records is:  356\n",
      "Added to job_records list. Length of job_records is:  357\n",
      "Added to job_records list. Length of job_records is:  358\n",
      "Added to job_records list. Length of job_records is:  359\n",
      "Added to job_records list. Length of job_records is:  360\n",
      "Added to job_records list. Length of job_records is:  361\n",
      "Added to job_records list. Length of job_records is:  362\n",
      "Added to job_records list. Length of job_records is:  363\n",
      "Added to job_records list. Length of job_records is:  364\n",
      "Added to job_records list. Length of job_records is:  365\n",
      "Added to job_records list. Length of job_records is:  366\n",
      "Added to job_records list. Length of job_records is:  367\n",
      "Added to job_records list. Length of job_records is:  368\n",
      "Added to job_records list. Length of job_records is:  369\n",
      "Added to job_records list. Length of job_records is:  370\n",
      "Added to job_records list. Length of job_records is:  371\n",
      "Added to job_records list. Length of job_records is:  372\n",
      "Added to job_records list. Length of job_records is:  373\n",
      "Added to job_records list. Length of job_records is:  374\n",
      "Added to job_records list. Length of job_records is:  375\n",
      "Added to job_records list. Length of job_records is:  376\n",
      "Added to job_records list. Length of job_records is:  377\n",
      "Added to job_records list. Length of job_records is:  378\n",
      "Added to job_records list. Length of job_records is:  379\n",
      "Added to job_records list. Length of job_records is:  380\n",
      "Added to job_records list. Length of job_records is:  381\n",
      "Added to job_records list. Length of job_records is:  382\n",
      "Added to job_records list. Length of job_records is:  383\n",
      "Added to job_records list. Length of job_records is:  384\n",
      "Added to job_records list. Length of job_records is:  385\n",
      "Added to job_records list. Length of job_records is:  386\n",
      "Added to job_records list. Length of job_records is:  387\n",
      "Added to job_records list. Length of job_records is:  388\n",
      "Added to job_records list. Length of job_records is:  389\n",
      "Added to job_records list. Length of job_records is:  390\n",
      "Added to job_records list. Length of job_records is:  391\n",
      "Added to job_records list. Length of job_records is:  392\n",
      "Added to job_records list. Length of job_records is:  393\n",
      "Added to job_records list. Length of job_records is:  394\n",
      "Added to job_records list. Length of job_records is:  395\n",
      "Added to job_records list. Length of job_records is:  396\n",
      "Added to job_records list. Length of job_records is:  397\n",
      "Added to job_records list. Length of job_records is:  398\n",
      "Added to job_records list. Length of job_records is:  399\n",
      "Added to job_records list. Length of job_records is:  400\n",
      "Added to job_records list. Length of job_records is:  401\n",
      "Added to job_records list. Length of job_records is:  402\n",
      "Added to job_records list. Length of job_records is:  403\n",
      "Added to job_records list. Length of job_records is:  404\n",
      "Added to job_records list. Length of job_records is:  405\n",
      "Added to job_records list. Length of job_records is:  406\n",
      "Added to job_records list. Length of job_records is:  407\n",
      "Added to job_records list. Length of job_records is:  408\n",
      "Added to job_records list. Length of job_records is:  409\n",
      "Added to job_records list. Length of job_records is:  410\n",
      "Added to job_records list. Length of job_records is:  411\n",
      "Added to job_records list. Length of job_records is:  412\n",
      "Added to job_records list. Length of job_records is:  413\n",
      "Added to job_records list. Length of job_records is:  414\n",
      "Added to job_records list. Length of job_records is:  415\n",
      "Added to job_records list. Length of job_records is:  416\n",
      "Added to job_records list. Length of job_records is:  417\n",
      "Added to job_records list. Length of job_records is:  418\n",
      "Added to job_records list. Length of job_records is:  419\n",
      "Added to job_records list. Length of job_records is:  420\n",
      "Added to job_records list. Length of job_records is:  421\n",
      "Added to job_records list. Length of job_records is:  422\n",
      "Added to job_records list. Length of job_records is:  423\n",
      "Added to job_records list. Length of job_records is:  424\n",
      "Added to job_records list. Length of job_records is:  425\n",
      "Added to job_records list. Length of job_records is:  426\n",
      "Added to job_records list. Length of job_records is:  427\n",
      "Added to job_records list. Length of job_records is:  428\n",
      "Added to job_records list. Length of job_records is:  429\n",
      "Added to job_records list. Length of job_records is:  430\n",
      "Added to job_records list. Length of job_records is:  431\n",
      "Added to job_records list. Length of job_records is:  432\n",
      "Added to job_records list. Length of job_records is:  433\n",
      "Added to job_records list. Length of job_records is:  434\n",
      "Added to job_records list. Length of job_records is:  435\n",
      "Added to job_records list. Length of job_records is:  436\n",
      "Added to job_records list. Length of job_records is:  437\n",
      "Added to job_records list. Length of job_records is:  438\n",
      "Added to job_records list. Length of job_records is:  439\n",
      "Added to job_records list. Length of job_records is:  440\n",
      "Added to job_records list. Length of job_records is:  441\n",
      "Added to job_records list. Length of job_records is:  442\n",
      "Added to job_records list. Length of job_records is:  443\n",
      "Added to job_records list. Length of job_records is:  444\n",
      "Added to job_records list. Length of job_records is:  445\n",
      "Added to job_records list. Length of job_records is:  446\n",
      "Added to job_records list. Length of job_records is:  447\n",
      "Added to job_records list. Length of job_records is:  448\n",
      "Added to job_records list. Length of job_records is:  449\n",
      "Added to job_records list. Length of job_records is:  450\n",
      "['data']\n",
      "The number of rows added is:  450\n"
     ]
    }
   ],
   "source": [
    "dataAnalyst = main_etl(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m1A main_etl_analyst_csv.ipynb\u001b[m\u001b[m         README.md\r\n",
      "\u001b[31m1B main_etl_analyst_sql.ipynb\u001b[m\u001b[m         joblist.sqlite\r\n",
      "\u001b[31m1B main_etl_scientist_sql.ipynb\u001b[m\u001b[m       main_etl_scientist_sql.py\r\n",
      "\u001b[31m2A main_csv_jobdesc_nlp_preproc.ipynb\u001b[m\u001b[m \u001b[31mmain_jobdesc_eda.ipynb\u001b[m\u001b[m\r\n",
      "\u001b[31m2B main_sql_jobdesc_nlp_preproc.ipynb\u001b[m\u001b[m results.csv\r\n",
      "\u001b[1m\u001b[36mData Analyst\u001b[m\u001b[m                          \u001b[1m\u001b[36mtest_folder\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[36mData Scientist\u001b[m\u001b[m                        \u001b[30m\u001b[43mtest_folder2\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
